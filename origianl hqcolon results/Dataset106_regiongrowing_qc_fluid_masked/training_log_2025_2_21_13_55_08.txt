
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-02-21 13:55:08.425846: do_dummy_2d_data_aug: False 
2025-02-21 13:55:08.426637: Creating new 5-fold cross-validation split... 
2025-02-21 13:55:08.428357: Desired fold for training: 0 
2025-02-21 13:55:08.428391: This split has 232 training and 58 validation cases. 
2025-02-21 13:55:17.323922: Using torch.compile... 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [192, 96, 128], 'median_image_size_in_voxels': [520.0, 297.5, 416.5], 'spacing': [0.8, 0.7421875, 0.7421875], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset106_regiongrowing_qc_fluid_masked', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [0.8, 0.7421875, 0.7421875], 'original_median_shape_after_transp': [520, 310, 427], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 5692.0, 'mean': -904.453125, 'median': -986.0, 'min': -1346.0, 'percentile_00_5': -1024.0, 'percentile_99_5': 1174.0, 'std': 357.4883117675781}}} 
 
2025-02-21 13:55:20.640703: unpacking dataset... 
2025-02-21 13:57:25.510587: unpacking done... 
2025-02-21 13:57:25.512833: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-02-21 13:57:25.556859:  
2025-02-21 13:57:25.556922: Epoch 0 
2025-02-21 13:57:25.557037: Current learning rate: 0.01 
2025-02-21 13:58:42.422898: train_loss -0.6015 
2025-02-21 13:58:42.423063: val_loss -0.6796 
2025-02-21 13:58:42.423101: Pseudo dice [0.8752] 
2025-02-21 13:58:42.423143: Epoch time: 76.87 s 
2025-02-21 13:58:42.423178: Yayy! New best EMA pseudo Dice: 0.8752 
2025-02-21 13:58:43.418243:  
2025-02-21 13:58:43.418415: Epoch 1 
2025-02-21 13:58:43.418495: Current learning rate: 0.00999 
2025-02-21 13:59:15.178950: train_loss -0.7486 
2025-02-21 13:59:15.179136: val_loss -0.8056 
2025-02-21 13:59:15.179174: Pseudo dice [0.9271] 
2025-02-21 13:59:15.179235: Epoch time: 31.76 s 
2025-02-21 13:59:15.179280: Yayy! New best EMA pseudo Dice: 0.8804 
2025-02-21 13:59:16.328961:  
2025-02-21 13:59:16.329203: Epoch 2 
2025-02-21 13:59:16.329326: Current learning rate: 0.00998 
2025-02-21 13:59:48.259334: train_loss -0.7572 
2025-02-21 13:59:48.259478: val_loss -0.7215 
2025-02-21 13:59:48.259517: Pseudo dice [0.8932] 
2025-02-21 13:59:48.259555: Epoch time: 31.93 s 
2025-02-21 13:59:48.259583: Yayy! New best EMA pseudo Dice: 0.8816 
2025-02-21 13:59:49.325590:  
2025-02-21 13:59:49.325767: Epoch 3 
2025-02-21 13:59:49.325855: Current learning rate: 0.00997 
2025-02-21 14:00:21.243456: train_loss -0.7718 
2025-02-21 14:00:21.243583: val_loss -0.8068 
2025-02-21 14:00:21.243620: Pseudo dice [0.9285] 
2025-02-21 14:00:21.243659: Epoch time: 31.92 s 
2025-02-21 14:00:21.243687: Yayy! New best EMA pseudo Dice: 0.8863 
2025-02-21 14:00:22.251378:  
2025-02-21 14:00:22.251591: Epoch 4 
2025-02-21 14:00:22.251644: Current learning rate: 0.00996 
2025-02-21 14:00:54.475592: train_loss -0.7793 
2025-02-21 14:00:54.475867: val_loss -0.7324 
2025-02-21 14:00:54.475920: Pseudo dice [0.907] 
2025-02-21 14:00:54.475958: Epoch time: 32.22 s 
2025-02-21 14:00:54.475987: Yayy! New best EMA pseudo Dice: 0.8884 
2025-02-21 14:00:55.634013:  
2025-02-21 14:00:55.634145: Epoch 5 
2025-02-21 14:00:55.634206: Current learning rate: 0.00995 
2025-02-21 14:01:27.701177: train_loss -0.8049 
2025-02-21 14:01:27.701466: val_loss -0.8424 
2025-02-21 14:01:27.701520: Pseudo dice [0.9438] 
2025-02-21 14:01:27.701564: Epoch time: 32.07 s 
2025-02-21 14:01:27.701593: Yayy! New best EMA pseudo Dice: 0.8939 
2025-02-21 14:01:28.704995:  
2025-02-21 14:01:28.705173: Epoch 6 
2025-02-21 14:01:28.705234: Current learning rate: 0.00995 
2025-02-21 14:02:00.414302: train_loss -0.827 
2025-02-21 14:02:00.414511: val_loss -0.8464 
2025-02-21 14:02:00.414548: Pseudo dice [0.9472] 
2025-02-21 14:02:00.414592: Epoch time: 31.71 s 
2025-02-21 14:02:00.414622: Yayy! New best EMA pseudo Dice: 0.8993 
2025-02-21 14:02:01.441566:  
2025-02-21 14:02:01.441721: Epoch 7 
2025-02-21 14:02:01.441774: Current learning rate: 0.00994 
2025-02-21 14:02:33.256654: train_loss -0.8299 
2025-02-21 14:02:33.256780: val_loss -0.8629 
2025-02-21 14:02:33.256824: Pseudo dice [0.9554] 
2025-02-21 14:02:33.256862: Epoch time: 31.82 s 
2025-02-21 14:02:33.256890: Yayy! New best EMA pseudo Dice: 0.9049 
2025-02-21 14:02:34.295799:  
2025-02-21 14:02:34.295941: Epoch 8 
2025-02-21 14:02:34.296027: Current learning rate: 0.00993 
2025-02-21 14:03:06.037864: train_loss -0.8281 
2025-02-21 14:03:06.037996: val_loss -0.8255 
2025-02-21 14:03:06.038032: Pseudo dice [0.9302] 
2025-02-21 14:03:06.038071: Epoch time: 31.74 s 
2025-02-21 14:03:06.038098: Yayy! New best EMA pseudo Dice: 0.9074 
2025-02-21 14:03:07.063588:  
2025-02-21 14:03:07.063748: Epoch 9 
2025-02-21 14:03:07.063825: Current learning rate: 0.00992 
2025-02-21 14:03:39.141853: train_loss -0.837 
2025-02-21 14:03:39.142094: val_loss -0.8612 
2025-02-21 14:03:39.142139: Pseudo dice [0.952] 
2025-02-21 14:03:39.142179: Epoch time: 32.08 s 
2025-02-21 14:03:39.142207: Yayy! New best EMA pseudo Dice: 0.9119 
2025-02-21 14:03:40.213542:  
2025-02-21 14:03:40.213716: Epoch 10 
2025-02-21 14:03:40.213793: Current learning rate: 0.00991 
2025-02-21 14:04:11.993952: train_loss -0.8405 
2025-02-21 14:04:11.994081: val_loss -0.8734 
2025-02-21 14:04:11.994117: Pseudo dice [0.9566] 
2025-02-21 14:04:11.994154: Epoch time: 31.78 s 
2025-02-21 14:04:11.994183: Yayy! New best EMA pseudo Dice: 0.9163 
2025-02-21 14:04:17.242888:  
2025-02-21 14:04:17.243100: Epoch 11 
2025-02-21 14:04:17.243180: Current learning rate: 0.0099 
2025-02-21 14:04:49.227401: train_loss -0.8326 
2025-02-21 14:04:49.227597: val_loss -0.8731 
2025-02-21 14:04:49.227635: Pseudo dice [0.9533] 
2025-02-21 14:04:49.227674: Epoch time: 31.99 s 
2025-02-21 14:04:49.227702: Yayy! New best EMA pseudo Dice: 0.92 
2025-02-21 14:04:50.263432:  
2025-02-21 14:04:50.263566: Epoch 12 
2025-02-21 14:04:50.263637: Current learning rate: 0.00989 
2025-02-21 14:05:21.844675: train_loss -0.8393 
2025-02-21 14:05:21.844824: val_loss -0.8811 
2025-02-21 14:05:21.844872: Pseudo dice [0.9595] 
2025-02-21 14:05:21.844934: Epoch time: 31.58 s 
2025-02-21 14:05:21.844973: Yayy! New best EMA pseudo Dice: 0.924 
2025-02-21 14:05:22.851178:  
2025-02-21 14:05:22.851372: Epoch 13 
2025-02-21 14:05:22.851428: Current learning rate: 0.00988 
2025-02-21 14:05:54.942725: train_loss -0.8377 
2025-02-21 14:05:54.942881: val_loss -0.8869 
2025-02-21 14:05:54.942925: Pseudo dice [0.9596] 
2025-02-21 14:05:54.942969: Epoch time: 32.09 s 
2025-02-21 14:05:54.942998: Yayy! New best EMA pseudo Dice: 0.9275 
2025-02-21 14:05:56.041403:  
2025-02-21 14:05:56.041504: Epoch 14 
2025-02-21 14:05:56.041550: Current learning rate: 0.00987 
2025-02-21 14:06:27.771481: train_loss -0.8694 
2025-02-21 14:06:27.771668: val_loss -0.8819 
2025-02-21 14:06:27.771706: Pseudo dice [0.9622] 
2025-02-21 14:06:27.771749: Epoch time: 31.73 s 
2025-02-21 14:06:27.771778: Yayy! New best EMA pseudo Dice: 0.931 
2025-02-21 14:06:28.799351:  
2025-02-21 14:06:28.799484: Epoch 15 
2025-02-21 14:06:28.799544: Current learning rate: 0.00986 
2025-02-21 14:07:00.298519: train_loss -0.842 
2025-02-21 14:07:00.298638: val_loss -0.8859 
2025-02-21 14:07:00.298675: Pseudo dice [0.9595] 
2025-02-21 14:07:00.298712: Epoch time: 31.5 s 
2025-02-21 14:07:00.298740: Yayy! New best EMA pseudo Dice: 0.9339 
2025-02-21 14:07:01.349575:  
2025-02-21 14:07:01.349713: Epoch 16 
2025-02-21 14:07:01.349782: Current learning rate: 0.00986 
2025-02-21 14:07:32.805492: train_loss -0.8348 
2025-02-21 14:07:32.805634: val_loss -0.8364 
2025-02-21 14:07:32.805671: Pseudo dice [0.9448] 
2025-02-21 14:07:32.805711: Epoch time: 31.46 s 
2025-02-21 14:07:32.805739: Yayy! New best EMA pseudo Dice: 0.935 
2025-02-21 14:07:33.845504:  
2025-02-21 14:07:33.845667: Epoch 17 
2025-02-21 14:07:33.845724: Current learning rate: 0.00985 
2025-02-21 14:08:05.676953: train_loss -0.852 
2025-02-21 14:08:05.677178: val_loss -0.8947 
2025-02-21 14:08:05.677226: Pseudo dice [0.965] 
2025-02-21 14:08:05.677270: Epoch time: 31.83 s 
2025-02-21 14:08:05.677299: Yayy! New best EMA pseudo Dice: 0.938 
2025-02-21 14:08:06.750836:  
2025-02-21 14:08:06.750997: Epoch 18 
2025-02-21 14:08:06.751091: Current learning rate: 0.00984 
2025-02-21 14:08:38.262088: train_loss -0.8408 
2025-02-21 14:08:38.262316: val_loss -0.839 
2025-02-21 14:08:38.262355: Pseudo dice [0.9347] 
2025-02-21 14:08:38.262401: Epoch time: 31.51 s 
2025-02-21 14:08:38.975542:  
2025-02-21 14:08:38.975710: Epoch 19 
2025-02-21 14:08:38.975765: Current learning rate: 0.00983 
2025-02-21 14:09:10.518986: train_loss -0.8458 
2025-02-21 14:09:10.519143: val_loss -0.8799 
2025-02-21 14:09:10.519183: Pseudo dice [0.9555] 
2025-02-21 14:09:10.519221: Epoch time: 31.54 s 
2025-02-21 14:09:10.519249: Yayy! New best EMA pseudo Dice: 0.9394 
2025-02-21 14:09:11.557986:  
2025-02-21 14:09:11.558171: Epoch 20 
2025-02-21 14:09:11.558241: Current learning rate: 0.00982 
2025-02-21 14:09:43.151155: train_loss -0.8558 
2025-02-21 14:09:43.151304: val_loss -0.8708 
2025-02-21 14:09:43.151343: Pseudo dice [0.9594] 
2025-02-21 14:09:43.151381: Epoch time: 31.59 s 
2025-02-21 14:09:43.151410: Yayy! New best EMA pseudo Dice: 0.9414 
2025-02-21 14:09:44.204067:  
2025-02-21 14:09:44.204223: Epoch 21 
2025-02-21 14:09:44.204271: Current learning rate: 0.00981 
2025-02-21 14:10:15.876487: train_loss -0.8817 
2025-02-21 14:10:15.876769: val_loss -0.9028 
2025-02-21 14:10:15.876818: Pseudo dice [0.9629] 
2025-02-21 14:10:15.876877: Epoch time: 31.67 s 
2025-02-21 14:10:15.876911: Yayy! New best EMA pseudo Dice: 0.9436 
2025-02-21 14:10:16.925650:  
2025-02-21 14:10:16.925820: Epoch 22 
2025-02-21 14:10:16.925907: Current learning rate: 0.0098 
2025-02-21 14:10:48.720785: train_loss -0.8582 
2025-02-21 14:10:48.720916: val_loss -0.9007 
2025-02-21 14:10:48.720952: Pseudo dice [0.9639] 
2025-02-21 14:10:48.720988: Epoch time: 31.8 s 
2025-02-21 14:10:48.721024: Yayy! New best EMA pseudo Dice: 0.9456 
2025-02-21 14:10:49.729267:  
2025-02-21 14:10:49.729417: Epoch 23 
2025-02-21 14:10:49.729460: Current learning rate: 0.00979 
2025-02-21 14:11:21.349020: train_loss -0.8583 
2025-02-21 14:11:21.349202: val_loss -0.8929 
2025-02-21 14:11:21.349238: Pseudo dice [0.9583] 
2025-02-21 14:11:21.349283: Epoch time: 31.62 s 
2025-02-21 14:11:21.349309: Yayy! New best EMA pseudo Dice: 0.9469 
2025-02-21 14:11:22.338358:  
2025-02-21 14:11:22.338530: Epoch 24 
2025-02-21 14:11:22.338600: Current learning rate: 0.00978 
2025-02-21 14:11:53.889076: train_loss -0.8591 
2025-02-21 14:11:53.889212: val_loss -0.8815 
2025-02-21 14:11:53.889249: Pseudo dice [0.9551] 
2025-02-21 14:11:53.889285: Epoch time: 31.55 s 
2025-02-21 14:11:53.889313: Yayy! New best EMA pseudo Dice: 0.9477 
2025-02-21 14:11:54.900290:  
2025-02-21 14:11:54.900477: Epoch 25 
2025-02-21 14:11:54.900522: Current learning rate: 0.00977 
2025-02-21 14:12:26.714606: train_loss -0.8463 
2025-02-21 14:12:26.714785: val_loss -0.9119 
2025-02-21 14:12:26.714828: Pseudo dice [0.9708] 
2025-02-21 14:12:26.714868: Epoch time: 31.81 s 
2025-02-21 14:12:26.714896: Yayy! New best EMA pseudo Dice: 0.95 
2025-02-21 14:12:27.789193:  
2025-02-21 14:12:27.789415: Epoch 26 
2025-02-21 14:12:27.789495: Current learning rate: 0.00977 
2025-02-21 14:12:59.289886: train_loss -0.8752 
2025-02-21 14:12:59.290023: val_loss -0.8965 
2025-02-21 14:12:59.290068: Pseudo dice [0.9636] 
2025-02-21 14:12:59.290110: Epoch time: 31.5 s 
2025-02-21 14:12:59.290138: Yayy! New best EMA pseudo Dice: 0.9514 
2025-02-21 14:13:00.301635:  
2025-02-21 14:13:00.301762: Epoch 27 
2025-02-21 14:13:00.301845: Current learning rate: 0.00976 
2025-02-21 14:13:31.804312: train_loss -0.8602 
2025-02-21 14:13:31.804459: val_loss -0.8863 
2025-02-21 14:13:31.804497: Pseudo dice [0.9603] 
2025-02-21 14:13:31.804537: Epoch time: 31.5 s 
2025-02-21 14:13:31.804566: Yayy! New best EMA pseudo Dice: 0.9523 
2025-02-21 14:13:33.435132:  
2025-02-21 14:13:33.435284: Epoch 28 
2025-02-21 14:13:33.435353: Current learning rate: 0.00975 
2025-02-21 14:14:04.902062: train_loss -0.8486 
2025-02-21 14:14:04.902208: val_loss -0.8544 
2025-02-21 14:14:04.902251: Pseudo dice [0.949] 
2025-02-21 14:14:04.902298: Epoch time: 31.47 s 
2025-02-21 14:14:05.597230:  
2025-02-21 14:14:05.597462: Epoch 29 
2025-02-21 14:14:05.597539: Current learning rate: 0.00974 
2025-02-21 14:14:37.555826: train_loss -0.8843 
2025-02-21 14:14:37.555997: val_loss -0.8974 
2025-02-21 14:14:37.556035: Pseudo dice [0.9662] 
2025-02-21 14:14:37.556075: Epoch time: 31.96 s 
2025-02-21 14:14:37.556103: Yayy! New best EMA pseudo Dice: 0.9534 
2025-02-21 14:14:38.582180:  
2025-02-21 14:14:38.582395: Epoch 30 
2025-02-21 14:14:38.582470: Current learning rate: 0.00973 
2025-02-21 14:15:10.050510: train_loss -0.8753 
2025-02-21 14:15:10.050650: val_loss -0.9055 
2025-02-21 14:15:10.050691: Pseudo dice [0.9656] 
2025-02-21 14:15:10.050727: Epoch time: 31.47 s 
2025-02-21 14:15:10.050756: Yayy! New best EMA pseudo Dice: 0.9546 
2025-02-21 14:15:11.086920:  
2025-02-21 14:15:11.087095: Epoch 31 
2025-02-21 14:15:11.087137: Current learning rate: 0.00972 
2025-02-21 14:15:42.704813: train_loss -0.8672 
2025-02-21 14:15:42.704947: val_loss -0.8938 
2025-02-21 14:15:42.704982: Pseudo dice [0.9628] 
2025-02-21 14:15:42.705018: Epoch time: 31.62 s 
2025-02-21 14:15:42.705047: Yayy! New best EMA pseudo Dice: 0.9554 
2025-02-21 14:15:43.726695:  
2025-02-21 14:15:43.726871: Epoch 32 
2025-02-21 14:15:43.726974: Current learning rate: 0.00971 
2025-02-21 14:16:15.264461: train_loss -0.8798 
2025-02-21 14:16:15.264601: val_loss -0.9296 
2025-02-21 14:16:15.264657: Pseudo dice [0.9751] 
2025-02-21 14:16:15.264745: Epoch time: 31.54 s 
2025-02-21 14:16:15.264792: Yayy! New best EMA pseudo Dice: 0.9574 
2025-02-21 14:16:16.296572:  
2025-02-21 14:16:16.296771: Epoch 33 
2025-02-21 14:16:16.296864: Current learning rate: 0.0097 
2025-02-21 14:16:48.358003: train_loss -0.8941 
2025-02-21 14:16:48.358145: val_loss -0.9083 
2025-02-21 14:16:48.358191: Pseudo dice [0.9666] 
2025-02-21 14:16:48.358239: Epoch time: 32.06 s 
2025-02-21 14:16:48.358315: Yayy! New best EMA pseudo Dice: 0.9583 
2025-02-21 14:16:49.384176:  
2025-02-21 14:16:49.384331: Epoch 34 
2025-02-21 14:16:49.384399: Current learning rate: 0.00969 
2025-02-21 14:17:21.045025: train_loss -0.8609 
2025-02-21 14:17:21.045169: val_loss -0.8996 
2025-02-21 14:17:21.045208: Pseudo dice [0.9625] 
2025-02-21 14:17:21.045247: Epoch time: 31.66 s 
2025-02-21 14:17:21.045276: Yayy! New best EMA pseudo Dice: 0.9587 
2025-02-21 14:17:22.088567:  
2025-02-21 14:17:22.088729: Epoch 35 
2025-02-21 14:17:22.088836: Current learning rate: 0.00968 
2025-02-21 14:17:53.975855: train_loss -0.8693 
2025-02-21 14:17:53.976123: val_loss -0.9092 
2025-02-21 14:17:53.976167: Pseudo dice [0.97] 
2025-02-21 14:17:53.976205: Epoch time: 31.89 s 
2025-02-21 14:17:53.976234: Yayy! New best EMA pseudo Dice: 0.9598 
2025-02-21 14:17:54.986987:  
2025-02-21 14:17:54.987134: Epoch 36 
2025-02-21 14:17:54.987224: Current learning rate: 0.00968 
2025-02-21 14:18:26.823386: train_loss -0.8733 
2025-02-21 14:18:26.823523: val_loss -0.8925 
2025-02-21 14:18:26.823559: Pseudo dice [0.9602] 
2025-02-21 14:18:26.823597: Epoch time: 31.84 s 
2025-02-21 14:18:26.823625: Yayy! New best EMA pseudo Dice: 0.9599 
2025-02-21 14:18:28.025820:  
2025-02-21 14:18:28.025972: Epoch 37 
2025-02-21 14:18:28.026072: Current learning rate: 0.00967 
2025-02-21 14:18:59.806251: train_loss -0.8882 
2025-02-21 14:18:59.806382: val_loss -0.9218 
2025-02-21 14:18:59.806419: Pseudo dice [0.9716] 
2025-02-21 14:18:59.806455: Epoch time: 31.78 s 
2025-02-21 14:18:59.806483: Yayy! New best EMA pseudo Dice: 0.9611 
2025-02-21 14:19:00.847116:  
2025-02-21 14:19:00.847267: Epoch 38 
2025-02-21 14:19:00.847336: Current learning rate: 0.00966 
2025-02-21 14:19:32.564125: train_loss -0.8863 
2025-02-21 14:19:32.564261: val_loss -0.9032 
2025-02-21 14:19:32.564298: Pseudo dice [0.965] 
2025-02-21 14:19:32.564336: Epoch time: 31.72 s 
2025-02-21 14:19:32.564364: Yayy! New best EMA pseudo Dice: 0.9614 
2025-02-21 14:19:33.597177:  
2025-02-21 14:19:33.597368: Epoch 39 
2025-02-21 14:19:33.597413: Current learning rate: 0.00965 
2025-02-21 14:20:05.502441: train_loss -0.8966 
2025-02-21 14:20:05.502599: val_loss -0.9143 
2025-02-21 14:20:05.502644: Pseudo dice [0.9698] 
2025-02-21 14:20:05.502684: Epoch time: 31.91 s 
2025-02-21 14:20:05.502714: Yayy! New best EMA pseudo Dice: 0.9623 
2025-02-21 14:20:06.524706:  
2025-02-21 14:20:06.524878: Epoch 40 
2025-02-21 14:20:06.524930: Current learning rate: 0.00964 
2025-02-21 14:20:38.209654: train_loss -0.8769 
2025-02-21 14:20:38.209793: val_loss -0.8973 
2025-02-21 14:20:38.209837: Pseudo dice [0.9638] 
2025-02-21 14:20:38.209875: Epoch time: 31.69 s 
2025-02-21 14:20:38.209905: Yayy! New best EMA pseudo Dice: 0.9624 
2025-02-21 14:20:39.251301:  
2025-02-21 14:20:39.251415: Epoch 41 
2025-02-21 14:20:39.251520: Current learning rate: 0.00963 
2025-02-21 14:21:11.014996: train_loss -0.8953 
2025-02-21 14:21:11.015239: val_loss -0.9028 
2025-02-21 14:21:11.015288: Pseudo dice [0.9645] 
2025-02-21 14:21:11.015327: Epoch time: 31.76 s 
2025-02-21 14:21:11.015355: Yayy! New best EMA pseudo Dice: 0.9626 
2025-02-21 14:21:12.164466:  
2025-02-21 14:21:12.164653: Epoch 42 
2025-02-21 14:21:12.164763: Current learning rate: 0.00962 
2025-02-21 14:21:44.382418: train_loss -0.8857 
2025-02-21 14:21:44.382653: val_loss -0.8901 
2025-02-21 14:21:44.382695: Pseudo dice [0.9593] 
2025-02-21 14:21:44.382746: Epoch time: 32.22 s 
2025-02-21 14:21:45.056749:  
2025-02-21 14:21:45.056921: Epoch 43 
2025-02-21 14:21:45.056975: Current learning rate: 0.00961 
2025-02-21 14:22:16.662227: train_loss -0.8846 
2025-02-21 14:22:16.662377: val_loss -0.91 
2025-02-21 14:22:16.662414: Pseudo dice [0.9661] 
2025-02-21 14:22:16.662453: Epoch time: 31.61 s 
2025-02-21 14:22:16.662482: Yayy! New best EMA pseudo Dice: 0.9627 
2025-02-21 14:22:17.700028:  
2025-02-21 14:22:17.700203: Epoch 44 
2025-02-21 14:22:17.700286: Current learning rate: 0.0096 
2025-02-21 14:22:49.328579: train_loss -0.8874 
2025-02-21 14:22:49.328804: val_loss -0.9319 
2025-02-21 14:22:49.328858: Pseudo dice [0.9758] 
2025-02-21 14:22:49.328905: Epoch time: 31.63 s 
2025-02-21 14:22:49.328936: Yayy! New best EMA pseudo Dice: 0.964 
2025-02-21 14:22:50.395542:  
2025-02-21 14:22:50.395751: Epoch 45 
2025-02-21 14:22:50.395832: Current learning rate: 0.00959 
2025-02-21 14:23:22.181655: train_loss -0.8977 
2025-02-21 14:23:22.181908: val_loss -0.9272 
2025-02-21 14:23:22.181952: Pseudo dice [0.974] 
2025-02-21 14:23:22.181991: Epoch time: 31.79 s 
2025-02-21 14:23:22.182035: Yayy! New best EMA pseudo Dice: 0.965 
2025-02-21 14:23:24.000222:  
2025-02-21 14:23:24.000363: Epoch 46 
2025-02-21 14:23:24.000415: Current learning rate: 0.00959 
2025-02-21 14:23:55.854596: train_loss -0.8917 
2025-02-21 14:23:55.854725: val_loss -0.9172 
2025-02-21 14:23:55.854762: Pseudo dice [0.9701] 
2025-02-21 14:23:55.854800: Epoch time: 31.86 s 
2025-02-21 14:23:55.854837: Yayy! New best EMA pseudo Dice: 0.9655 
2025-02-21 14:23:57.051009:  
2025-02-21 14:23:57.051179: Epoch 47 
2025-02-21 14:23:57.051242: Current learning rate: 0.00958 
2025-02-21 14:24:29.333200: train_loss -0.8965 
2025-02-21 14:24:29.333365: val_loss -0.9125 
2025-02-21 14:24:29.333417: Pseudo dice [0.9692] 
2025-02-21 14:24:29.333461: Epoch time: 32.28 s 
2025-02-21 14:24:29.333492: Yayy! New best EMA pseudo Dice: 0.9659 
2025-02-21 14:24:30.342907:  
2025-02-21 14:24:30.343086: Epoch 48 
2025-02-21 14:24:30.343132: Current learning rate: 0.00957 
2025-02-21 14:25:01.797947: train_loss -0.8967 
2025-02-21 14:25:01.798087: val_loss -0.9295 
2025-02-21 14:25:01.798127: Pseudo dice [0.9727] 
2025-02-21 14:25:01.798166: Epoch time: 31.46 s 
2025-02-21 14:25:01.798195: Yayy! New best EMA pseudo Dice: 0.9665 
2025-02-21 14:25:02.826446:  
2025-02-21 14:25:02.826617: Epoch 49 
2025-02-21 14:25:02.826720: Current learning rate: 0.00956 
2025-02-21 14:25:34.323331: train_loss -0.9045 
2025-02-21 14:25:34.323466: val_loss -0.8982 
2025-02-21 14:25:34.323503: Pseudo dice [0.9668] 
2025-02-21 14:25:34.323540: Epoch time: 31.5 s 
2025-02-21 14:25:34.531450: Yayy! New best EMA pseudo Dice: 0.9666 
2025-02-21 14:25:35.529022:  
2025-02-21 14:25:35.529218: Epoch 50 
2025-02-21 14:25:35.529263: Current learning rate: 0.00955 
2025-02-21 14:26:06.988376: train_loss -0.8692 
2025-02-21 14:26:06.988518: val_loss -0.9176 
2025-02-21 14:26:06.988557: Pseudo dice [0.9709] 
2025-02-21 14:26:06.988595: Epoch time: 31.46 s 
2025-02-21 14:26:06.988626: Yayy! New best EMA pseudo Dice: 0.967 
2025-02-21 14:26:07.989190:  
2025-02-21 14:26:07.989365: Epoch 51 
2025-02-21 14:26:07.989429: Current learning rate: 0.00954 
2025-02-21 14:26:39.866118: train_loss -0.9112 
2025-02-21 14:26:39.866254: val_loss -0.9032 
2025-02-21 14:26:39.866289: Pseudo dice [0.9653] 
2025-02-21 14:26:39.866326: Epoch time: 31.88 s 
2025-02-21 14:26:40.547271:  
2025-02-21 14:26:40.547405: Epoch 52 
2025-02-21 14:26:40.547467: Current learning rate: 0.00953 
2025-02-21 14:27:12.026279: train_loss -0.9011 
2025-02-21 14:27:12.026417: val_loss -0.9284 
2025-02-21 14:27:12.026453: Pseudo dice [0.9733] 
2025-02-21 14:27:12.026491: Epoch time: 31.48 s 
2025-02-21 14:27:12.026520: Yayy! New best EMA pseudo Dice: 0.9675 
2025-02-21 14:27:13.469570:  
2025-02-21 14:27:13.469732: Epoch 53 
2025-02-21 14:27:13.469803: Current learning rate: 0.00952 
2025-02-21 14:27:44.960757: train_loss -0.8935 
2025-02-21 14:27:44.960882: val_loss -0.9136 
2025-02-21 14:27:44.960918: Pseudo dice [0.9676] 
2025-02-21 14:27:44.960956: Epoch time: 31.49 s 
2025-02-21 14:27:44.960984: Yayy! New best EMA pseudo Dice: 0.9675 
2025-02-21 14:27:45.973755:  
2025-02-21 14:27:45.973941: Epoch 54 
2025-02-21 14:27:45.973998: Current learning rate: 0.00951 
2025-02-21 14:28:17.427450: train_loss -0.8904 
2025-02-21 14:28:17.427611: val_loss -0.8966 
2025-02-21 14:28:17.427649: Pseudo dice [0.9619] 
2025-02-21 14:28:17.427687: Epoch time: 31.45 s 
2025-02-21 14:28:18.107690:  
2025-02-21 14:28:18.107869: Epoch 55 
2025-02-21 14:28:18.107919: Current learning rate: 0.0095 
2025-02-21 14:28:50.142005: train_loss -0.9056 
2025-02-21 14:28:50.142154: val_loss -0.9218 
2025-02-21 14:28:50.142191: Pseudo dice [0.9694] 
2025-02-21 14:28:50.142230: Epoch time: 32.04 s 
2025-02-21 14:28:50.832385:  
2025-02-21 14:28:50.832598: Epoch 56 
2025-02-21 14:28:50.832673: Current learning rate: 0.00949 
2025-02-21 14:29:22.318985: train_loss -0.9036 
2025-02-21 14:29:22.319113: val_loss -0.9396 
2025-02-21 14:29:22.319149: Pseudo dice [0.9789] 
2025-02-21 14:29:22.319184: Epoch time: 31.49 s 
2025-02-21 14:29:22.319211: Yayy! New best EMA pseudo Dice: 0.9684 
2025-02-21 14:29:23.323375:  
2025-02-21 14:29:23.323545: Epoch 57 
2025-02-21 14:29:23.323603: Current learning rate: 0.00949 
2025-02-21 14:29:54.851639: train_loss -0.8912 
2025-02-21 14:29:54.851782: val_loss -0.9205 
2025-02-21 14:29:54.851824: Pseudo dice [0.9702] 
2025-02-21 14:29:54.851865: Epoch time: 31.53 s 
2025-02-21 14:29:54.851894: Yayy! New best EMA pseudo Dice: 0.9685 
2025-02-21 14:29:55.866726:  
2025-02-21 14:29:55.866973: Epoch 58 
2025-02-21 14:29:55.867044: Current learning rate: 0.00948 
2025-02-21 14:30:27.639591: train_loss -0.8923 
2025-02-21 14:30:27.639749: val_loss -0.9171 
2025-02-21 14:30:27.639805: Pseudo dice [0.9669] 
2025-02-21 14:30:27.639878: Epoch time: 31.77 s 
2025-02-21 14:30:28.332204:  
2025-02-21 14:30:28.332386: Epoch 59 
2025-02-21 14:30:28.332441: Current learning rate: 0.00947 
2025-02-21 14:31:00.144037: train_loss -0.8961 
2025-02-21 14:31:00.144180: val_loss -0.936 
2025-02-21 14:31:00.144223: Pseudo dice [0.9754] 
2025-02-21 14:31:00.144266: Epoch time: 31.81 s 
2025-02-21 14:31:00.144299: Yayy! New best EMA pseudo Dice: 0.9691 
2025-02-21 14:31:01.180019:  
2025-02-21 14:31:01.180162: Epoch 60 
2025-02-21 14:31:01.180219: Current learning rate: 0.00946 
2025-02-21 14:31:32.746088: train_loss -0.9083 
2025-02-21 14:31:32.746242: val_loss -0.9244 
2025-02-21 14:31:32.746278: Pseudo dice [0.9742] 
2025-02-21 14:31:32.746315: Epoch time: 31.57 s 
2025-02-21 14:31:32.746342: Yayy! New best EMA pseudo Dice: 0.9696 
2025-02-21 14:31:33.793668:  
2025-02-21 14:31:33.793887: Epoch 61 
2025-02-21 14:31:33.793945: Current learning rate: 0.00945 
2025-02-21 14:32:05.390278: train_loss -0.8988 
2025-02-21 14:32:05.390428: val_loss -0.9062 
2025-02-21 14:32:05.390468: Pseudo dice [0.9612] 
2025-02-21 14:32:05.390507: Epoch time: 31.6 s 
2025-02-21 14:32:06.097400:  
2025-02-21 14:32:06.097578: Epoch 62 
2025-02-21 14:32:06.097676: Current learning rate: 0.00944 
2025-02-21 14:32:37.837800: train_loss -0.9035 
2025-02-21 14:32:37.837983: val_loss -0.9138 
2025-02-21 14:32:37.838025: Pseudo dice [0.9706] 
2025-02-21 14:32:37.838069: Epoch time: 31.74 s 
2025-02-21 14:32:39.420173:  
2025-02-21 14:32:39.420292: Epoch 63 
2025-02-21 14:32:39.420344: Current learning rate: 0.00943 
2025-02-21 14:33:11.072167: train_loss -0.8987 
2025-02-21 14:33:11.072312: val_loss -0.9082 
2025-02-21 14:33:11.072349: Pseudo dice [0.9658] 
2025-02-21 14:33:11.072388: Epoch time: 31.65 s 
2025-02-21 14:33:11.759927:  
2025-02-21 14:33:11.760105: Epoch 64 
2025-02-21 14:33:11.760185: Current learning rate: 0.00942 
2025-02-21 14:33:43.433477: train_loss -0.9041 
2025-02-21 14:33:43.433644: val_loss -0.9199 
2025-02-21 14:33:43.433683: Pseudo dice [0.969] 
2025-02-21 14:33:43.433721: Epoch time: 31.67 s 
2025-02-21 14:33:44.130543:  
2025-02-21 14:33:44.130742: Epoch 65 
2025-02-21 14:33:44.130793: Current learning rate: 0.00941 
2025-02-21 14:34:15.806695: train_loss -0.9282 
2025-02-21 14:34:15.806842: val_loss -0.9472 
2025-02-21 14:34:15.806881: Pseudo dice [0.9802] 
2025-02-21 14:34:15.806920: Epoch time: 31.68 s 
2025-02-21 14:34:15.806947: Yayy! New best EMA pseudo Dice: 0.9698 
2025-02-21 14:34:16.846660:  
2025-02-21 14:34:16.846812: Epoch 66 
2025-02-21 14:34:16.846866: Current learning rate: 0.0094 
2025-02-21 14:34:48.849226: train_loss -0.9202 
2025-02-21 14:34:48.849349: val_loss -0.911 
2025-02-21 14:34:48.849386: Pseudo dice [0.9671] 
2025-02-21 14:34:48.849422: Epoch time: 32.0 s 
2025-02-21 14:34:49.545263:  
2025-02-21 14:34:49.545388: Epoch 67 
2025-02-21 14:34:49.545451: Current learning rate: 0.00939 
2025-02-21 14:35:21.149502: train_loss -0.9003 
2025-02-21 14:35:21.149633: val_loss -0.9126 
2025-02-21 14:35:21.149679: Pseudo dice [0.9697] 
2025-02-21 14:35:21.149714: Epoch time: 31.6 s 
2025-02-21 14:35:21.860020:  
2025-02-21 14:35:21.860211: Epoch 68 
2025-02-21 14:35:21.860281: Current learning rate: 0.00939 
2025-02-21 14:35:53.453952: train_loss -0.8965 
2025-02-21 14:35:53.454087: val_loss -0.9368 
2025-02-21 14:35:53.454124: Pseudo dice [0.9762] 
2025-02-21 14:35:53.454159: Epoch time: 31.59 s 
2025-02-21 14:35:53.454187: Yayy! New best EMA pseudo Dice: 0.9702 
2025-02-21 14:35:54.507418:  
2025-02-21 14:35:54.507597: Epoch 69 
2025-02-21 14:35:54.507663: Current learning rate: 0.00938 
2025-02-21 14:36:26.025598: train_loss -0.9022 
2025-02-21 14:36:26.025741: val_loss -0.9136 
2025-02-21 14:36:26.025777: Pseudo dice [0.9712] 
2025-02-21 14:36:26.025826: Epoch time: 31.52 s 
2025-02-21 14:36:26.025862: Yayy! New best EMA pseudo Dice: 0.9703 
2025-02-21 14:36:27.091969:  
2025-02-21 14:36:27.092106: Epoch 70 
2025-02-21 14:36:27.092175: Current learning rate: 0.00937 
2025-02-21 14:36:59.124830: train_loss -0.9047 
2025-02-21 14:36:59.124981: val_loss -0.9226 
2025-02-21 14:36:59.125017: Pseudo dice [0.9729] 
2025-02-21 14:36:59.125056: Epoch time: 32.03 s 
2025-02-21 14:36:59.125084: Yayy! New best EMA pseudo Dice: 0.9706 
2025-02-21 14:37:00.181958:  
2025-02-21 14:37:00.182186: Epoch 71 
2025-02-21 14:37:00.182252: Current learning rate: 0.00936 
2025-02-21 14:37:31.715939: train_loss -0.893 
2025-02-21 14:37:31.716075: val_loss -0.9185 
2025-02-21 14:37:31.716111: Pseudo dice [0.9707] 
2025-02-21 14:37:31.716148: Epoch time: 31.53 s 
2025-02-21 14:37:31.716176: Yayy! New best EMA pseudo Dice: 0.9706 
2025-02-21 14:37:32.765762:  
2025-02-21 14:37:32.765935: Epoch 72 
2025-02-21 14:37:32.766065: Current learning rate: 0.00935 
2025-02-21 14:38:04.318369: train_loss -0.8717 
2025-02-21 14:38:04.318543: val_loss -0.9089 
2025-02-21 14:38:04.318630: Pseudo dice [0.9685] 
2025-02-21 14:38:04.318670: Epoch time: 31.55 s 
2025-02-21 14:38:05.072457:  
2025-02-21 14:38:05.072659: Epoch 73 
2025-02-21 14:38:05.072781: Current learning rate: 0.00934 
2025-02-21 14:38:36.914764: train_loss -0.8873 
2025-02-21 14:38:36.914922: val_loss -0.8954 
2025-02-21 14:38:36.914973: Pseudo dice [0.9609] 
2025-02-21 14:38:36.915015: Epoch time: 31.84 s 
2025-02-21 14:38:37.619531:  
2025-02-21 14:38:37.619733: Epoch 74 
2025-02-21 14:38:37.619780: Current learning rate: 0.00933 
2025-02-21 14:39:09.138624: train_loss -0.9062 
2025-02-21 14:39:09.138758: val_loss -0.9119 
2025-02-21 14:39:09.138793: Pseudo dice [0.9616] 
2025-02-21 14:39:09.138839: Epoch time: 31.52 s 
2025-02-21 14:39:09.846394:  
2025-02-21 14:39:09.846581: Epoch 75 
2025-02-21 14:39:09.846637: Current learning rate: 0.00932 
2025-02-21 14:39:41.430690: train_loss -0.907 
2025-02-21 14:39:41.430897: val_loss -0.9339 
2025-02-21 14:39:41.430955: Pseudo dice [0.9748] 
2025-02-21 14:39:41.431005: Epoch time: 31.58 s 
2025-02-21 14:39:42.171950:  
2025-02-21 14:39:42.172118: Epoch 76 
2025-02-21 14:39:42.172206: Current learning rate: 0.00931 
2025-02-21 14:40:13.833237: train_loss -0.9118 
2025-02-21 14:40:13.833375: val_loss -0.9322 
2025-02-21 14:40:13.833419: Pseudo dice [0.9743] 
2025-02-21 14:40:13.833461: Epoch time: 31.66 s 
2025-02-21 14:40:14.539110:  
2025-02-21 14:40:14.539297: Epoch 77 
2025-02-21 14:40:14.539365: Current learning rate: 0.0093 
2025-02-21 14:40:46.271899: train_loss -0.9132 
2025-02-21 14:40:46.272049: val_loss -0.9353 
2025-02-21 14:40:46.272087: Pseudo dice [0.9761] 
2025-02-21 14:40:46.272125: Epoch time: 31.73 s 
2025-02-21 14:40:46.999221:  
2025-02-21 14:40:46.999323: Epoch 78 
2025-02-21 14:40:46.999399: Current learning rate: 0.0093 
2025-02-21 14:41:18.548233: train_loss -0.9023 
2025-02-21 14:41:18.548387: val_loss -0.9347 
2025-02-21 14:41:18.548451: Pseudo dice [0.9763] 
2025-02-21 14:41:18.548525: Epoch time: 31.55 s 
2025-02-21 14:41:18.548556: Yayy! New best EMA pseudo Dice: 0.971 
2025-02-21 14:41:19.605964:  
2025-02-21 14:41:19.606075: Epoch 79 
2025-02-21 14:41:19.606157: Current learning rate: 0.00929 
2025-02-21 14:41:51.160623: train_loss -0.9047 
2025-02-21 14:41:51.160767: val_loss -0.9174 
2025-02-21 14:41:51.160804: Pseudo dice [0.9678] 
2025-02-21 14:41:51.160847: Epoch time: 31.56 s 
2025-02-21 14:41:52.477709:  
2025-02-21 14:41:52.477936: Epoch 80 
2025-02-21 14:41:52.478020: Current learning rate: 0.00928 
2025-02-21 14:42:23.995741: train_loss -0.9242 
2025-02-21 14:42:23.995872: val_loss -0.9261 
2025-02-21 14:42:23.995918: Pseudo dice [0.9721] 
2025-02-21 14:42:23.995959: Epoch time: 31.52 s 
2025-02-21 14:42:24.688000:  
2025-02-21 14:42:24.688106: Epoch 81 
2025-02-21 14:42:24.688170: Current learning rate: 0.00927 
2025-02-21 14:42:56.645937: train_loss -0.9132 
2025-02-21 14:42:56.646078: val_loss -0.9408 
2025-02-21 14:42:56.646114: Pseudo dice [0.9784] 
2025-02-21 14:42:56.646152: Epoch time: 31.96 s 
2025-02-21 14:42:56.646179: Yayy! New best EMA pseudo Dice: 0.9716 
2025-02-21 14:42:57.685764:  
2025-02-21 14:42:57.685889: Epoch 82 
2025-02-21 14:42:57.685943: Current learning rate: 0.00926 
2025-02-21 14:43:29.326592: train_loss -0.9048 
2025-02-21 14:43:29.326759: val_loss -0.9364 
2025-02-21 14:43:29.326824: Pseudo dice [0.9776] 
2025-02-21 14:43:29.326868: Epoch time: 31.64 s 
2025-02-21 14:43:29.326898: Yayy! New best EMA pseudo Dice: 0.9722 
2025-02-21 14:43:30.326313:  
2025-02-21 14:43:30.326422: Epoch 83 
2025-02-21 14:43:30.326490: Current learning rate: 0.00925 
2025-02-21 14:44:01.879665: train_loss -0.9067 
2025-02-21 14:44:01.879811: val_loss -0.9135 
2025-02-21 14:44:01.879852: Pseudo dice [0.9679] 
2025-02-21 14:44:01.879889: Epoch time: 31.55 s 
2025-02-21 14:44:02.532772:  
2025-02-21 14:44:02.532907: Epoch 84 
2025-02-21 14:44:02.532956: Current learning rate: 0.00924 
2025-02-21 14:44:34.233713: train_loss -0.9056 
2025-02-21 14:44:34.233857: val_loss -0.9192 
2025-02-21 14:44:34.233896: Pseudo dice [0.9699] 
2025-02-21 14:44:34.233939: Epoch time: 31.7 s 
2025-02-21 14:44:34.893856:  
2025-02-21 14:44:34.894071: Epoch 85 
2025-02-21 14:44:34.894179: Current learning rate: 0.00923 
2025-02-21 14:45:06.669376: train_loss -0.9033 
2025-02-21 14:45:06.669629: val_loss -0.9254 
2025-02-21 14:45:06.669688: Pseudo dice [0.9699] 
2025-02-21 14:45:06.669743: Epoch time: 31.78 s 
2025-02-21 14:45:07.346702:  
2025-02-21 14:45:07.346824: Epoch 86 
2025-02-21 14:45:07.346892: Current learning rate: 0.00922 
2025-02-21 14:45:38.960873: train_loss -0.8989 
2025-02-21 14:45:38.961024: val_loss -0.9168 
2025-02-21 14:45:38.961063: Pseudo dice [0.972] 
2025-02-21 14:45:38.961104: Epoch time: 31.61 s 
2025-02-21 14:45:39.621473:  
2025-02-21 14:45:39.621614: Epoch 87 
2025-02-21 14:45:39.621677: Current learning rate: 0.00921 
2025-02-21 14:46:11.177233: train_loss -0.9176 
2025-02-21 14:46:11.177365: val_loss -0.9306 
2025-02-21 14:46:11.177401: Pseudo dice [0.975] 
2025-02-21 14:46:11.177438: Epoch time: 31.56 s 
2025-02-21 14:46:11.837796:  
2025-02-21 14:46:11.837934: Epoch 88 
2025-02-21 14:46:11.837980: Current learning rate: 0.0092 
2025-02-21 14:46:43.797457: train_loss -0.9031 
2025-02-21 14:46:43.797598: val_loss -0.9376 
2025-02-21 14:46:43.797674: Pseudo dice [0.9771] 
2025-02-21 14:46:43.797712: Epoch time: 31.96 s 
2025-02-21 14:46:43.797740: Yayy! New best EMA pseudo Dice: 0.9724 
2025-02-21 14:46:44.824473:  
2025-02-21 14:46:44.824636: Epoch 89 
2025-02-21 14:46:44.824681: Current learning rate: 0.0092 
2025-02-21 14:47:16.375634: train_loss -0.8955 
2025-02-21 14:47:16.375762: val_loss -0.9386 
2025-02-21 14:47:16.375817: Pseudo dice [0.9777] 
2025-02-21 14:47:16.375878: Epoch time: 31.55 s 
2025-02-21 14:47:16.375909: Yayy! New best EMA pseudo Dice: 0.9729 
2025-02-21 14:47:17.402323:  
2025-02-21 14:47:17.402477: Epoch 90 
2025-02-21 14:47:17.402548: Current learning rate: 0.00919 
2025-02-21 14:47:48.953734: train_loss -0.9025 
2025-02-21 14:47:48.953960: val_loss -0.9352 
2025-02-21 14:47:48.954003: Pseudo dice [0.9756] 
2025-02-21 14:47:48.954048: Epoch time: 31.55 s 
2025-02-21 14:47:48.954077: Yayy! New best EMA pseudo Dice: 0.9732 
2025-02-21 14:47:50.070561:  
2025-02-21 14:47:50.070745: Epoch 91 
2025-02-21 14:47:50.070801: Current learning rate: 0.00918 
2025-02-21 14:48:21.735758: train_loss -0.9267 
2025-02-21 14:48:21.735962: val_loss -0.937 
2025-02-21 14:48:21.735999: Pseudo dice [0.975] 
2025-02-21 14:48:21.736037: Epoch time: 31.67 s 
2025-02-21 14:48:21.736065: Yayy! New best EMA pseudo Dice: 0.9733 
2025-02-21 14:48:22.830734:  
2025-02-21 14:48:22.830911: Epoch 92 
2025-02-21 14:48:22.830992: Current learning rate: 0.00917 
2025-02-21 14:48:54.495754: train_loss -0.9153 
2025-02-21 14:48:54.495904: val_loss -0.9317 
2025-02-21 14:48:54.495945: Pseudo dice [0.9754] 
2025-02-21 14:48:54.495985: Epoch time: 31.67 s 
2025-02-21 14:48:54.496012: Yayy! New best EMA pseudo Dice: 0.9735 
2025-02-21 14:48:55.516692:  
2025-02-21 14:48:55.516862: Epoch 93 
2025-02-21 14:48:55.516936: Current learning rate: 0.00916 
2025-02-21 14:49:27.184192: train_loss -0.919 
2025-02-21 14:49:27.184336: val_loss -0.9408 
2025-02-21 14:49:27.184372: Pseudo dice [0.9779] 
2025-02-21 14:49:27.184409: Epoch time: 31.67 s 
2025-02-21 14:49:27.184456: Yayy! New best EMA pseudo Dice: 0.974 
2025-02-21 14:49:28.199501:  
2025-02-21 14:49:28.199689: Epoch 94 
2025-02-21 14:49:28.199733: Current learning rate: 0.00915 
2025-02-21 14:49:59.736065: train_loss -0.9054 
2025-02-21 14:49:59.736193: val_loss -0.9013 
2025-02-21 14:49:59.736231: Pseudo dice [0.9606] 
2025-02-21 14:49:59.736267: Epoch time: 31.54 s 
2025-02-21 14:50:00.406567:  
2025-02-21 14:50:00.406739: Epoch 95 
2025-02-21 14:50:00.406786: Current learning rate: 0.00914 
2025-02-21 14:50:32.174163: train_loss -0.9055 
2025-02-21 14:50:32.174470: val_loss -0.924 
2025-02-21 14:50:32.174515: Pseudo dice [0.9713] 
2025-02-21 14:50:32.174590: Epoch time: 31.77 s 
2025-02-21 14:50:32.898557:  
2025-02-21 14:50:32.898712: Epoch 96 
2025-02-21 14:50:32.898760: Current learning rate: 0.00913 
2025-02-21 14:51:04.506350: train_loss -0.9202 
2025-02-21 14:51:04.506481: val_loss -0.9297 
2025-02-21 14:51:04.506517: Pseudo dice [0.9772] 
2025-02-21 14:51:04.506554: Epoch time: 31.61 s 
2025-02-21 14:51:05.821242:  
2025-02-21 14:51:05.821412: Epoch 97 
2025-02-21 14:51:05.821457: Current learning rate: 0.00912 
2025-02-21 14:51:37.459635: train_loss -0.9056 
2025-02-21 14:51:37.459779: val_loss -0.9218 
2025-02-21 14:51:37.459826: Pseudo dice [0.9731] 
2025-02-21 14:51:37.459871: Epoch time: 31.64 s 
2025-02-21 14:51:38.156077:  
2025-02-21 14:51:38.156242: Epoch 98 
2025-02-21 14:51:38.156292: Current learning rate: 0.00911 
2025-02-21 14:52:09.668845: train_loss -0.889 
2025-02-21 14:52:09.668997: val_loss -0.9184 
2025-02-21 14:52:09.669034: Pseudo dice [0.9712] 
2025-02-21 14:52:09.669072: Epoch time: 31.51 s 
2025-02-21 14:52:10.356666:  
2025-02-21 14:52:10.356803: Epoch 99 
2025-02-21 14:52:10.356924: Current learning rate: 0.0091 
2025-02-21 14:52:42.344191: train_loss -0.9228 
2025-02-21 14:52:42.344353: val_loss -0.9212 
2025-02-21 14:52:42.344392: Pseudo dice [0.9699] 
2025-02-21 14:52:42.344433: Epoch time: 31.99 s 
2025-02-21 14:52:43.372228:  
2025-02-21 14:52:43.372384: Epoch 100 
2025-02-21 14:52:43.372475: Current learning rate: 0.0091 
2025-02-21 14:53:14.982482: train_loss -0.8846 
2025-02-21 14:53:14.982640: val_loss -0.8939 
2025-02-21 14:53:14.982677: Pseudo dice [0.9657] 
2025-02-21 14:53:14.982715: Epoch time: 31.61 s 
2025-02-21 14:53:15.666497:  
2025-02-21 14:53:15.666677: Epoch 101 
2025-02-21 14:53:15.666757: Current learning rate: 0.00909 
2025-02-21 14:53:47.290488: train_loss -0.888 
2025-02-21 14:53:47.290668: val_loss -0.9187 
2025-02-21 14:53:47.290709: Pseudo dice [0.9711] 
2025-02-21 14:53:47.290751: Epoch time: 31.62 s 
2025-02-21 14:53:47.977430:  
2025-02-21 14:53:47.977557: Epoch 102 
2025-02-21 14:53:47.977628: Current learning rate: 0.00908 
2025-02-21 14:54:19.559412: train_loss -0.8964 
2025-02-21 14:54:19.559751: val_loss -0.8994 
2025-02-21 14:54:19.559790: Pseudo dice [0.9589] 
2025-02-21 14:54:19.559844: Epoch time: 31.58 s 
2025-02-21 14:54:20.266917:  
2025-02-21 14:54:20.267110: Epoch 103 
2025-02-21 14:54:20.267180: Current learning rate: 0.00907 
2025-02-21 14:54:52.264533: train_loss -0.8862 
2025-02-21 14:54:52.264688: val_loss -0.9399 
2025-02-21 14:54:52.264726: Pseudo dice [0.9774] 
2025-02-21 14:54:52.264763: Epoch time: 32.0 s 
2025-02-21 14:54:52.952170:  
2025-02-21 14:54:52.952313: Epoch 104 
2025-02-21 14:54:52.952370: Current learning rate: 0.00906 
2025-02-21 14:55:24.512580: train_loss -0.9161 
2025-02-21 14:55:24.512727: val_loss -0.9225 
2025-02-21 14:55:24.512766: Pseudo dice [0.972] 
2025-02-21 14:55:24.512802: Epoch time: 31.56 s 
2025-02-21 14:55:25.213785:  
2025-02-21 14:55:25.214018: Epoch 105 
2025-02-21 14:55:25.214109: Current learning rate: 0.00905 
2025-02-21 14:55:56.792378: train_loss -0.8987 
2025-02-21 14:55:56.792515: val_loss -0.9243 
2025-02-21 14:55:56.792554: Pseudo dice [0.973] 
2025-02-21 14:55:56.792591: Epoch time: 31.58 s 
2025-02-21 14:55:57.488012:  
2025-02-21 14:55:57.488168: Epoch 106 
2025-02-21 14:55:57.488273: Current learning rate: 0.00904 
2025-02-21 14:56:29.000188: train_loss -0.912 
2025-02-21 14:56:29.000323: val_loss -0.9424 
2025-02-21 14:56:29.000359: Pseudo dice [0.978] 
2025-02-21 14:56:29.000395: Epoch time: 31.51 s 
2025-02-21 14:56:29.682941:  
2025-02-21 14:56:29.683067: Epoch 107 
2025-02-21 14:56:29.683218: Current learning rate: 0.00903 
2025-02-21 14:57:01.538157: train_loss -0.9012 
2025-02-21 14:57:01.538339: val_loss -0.9275 
2025-02-21 14:57:01.538378: Pseudo dice [0.9645] 
2025-02-21 14:57:01.538417: Epoch time: 31.86 s 
2025-02-21 14:57:02.225532:  
2025-02-21 14:57:02.225736: Epoch 108 
2025-02-21 14:57:02.225781: Current learning rate: 0.00902 
2025-02-21 14:57:33.727537: train_loss -0.925 
2025-02-21 14:57:33.727663: val_loss -0.9221 
2025-02-21 14:57:33.727699: Pseudo dice [0.9726] 
2025-02-21 14:57:33.727739: Epoch time: 31.5 s 
2025-02-21 14:57:34.424872:  
2025-02-21 14:57:34.425091: Epoch 109 
2025-02-21 14:57:34.425141: Current learning rate: 0.00901 
2025-02-21 14:58:05.991669: train_loss -0.8978 
2025-02-21 14:58:05.991819: val_loss -0.9283 
2025-02-21 14:58:05.991861: Pseudo dice [0.971] 
2025-02-21 14:58:05.991900: Epoch time: 31.57 s 
2025-02-21 14:58:06.695200:  
2025-02-21 14:58:06.695379: Epoch 110 
2025-02-21 14:58:06.695494: Current learning rate: 0.009 
2025-02-21 14:58:38.492693: train_loss -0.9008 
2025-02-21 14:58:38.492869: val_loss -0.92 
2025-02-21 14:58:38.492910: Pseudo dice [0.9677] 
2025-02-21 14:58:38.492951: Epoch time: 31.8 s 
2025-02-21 14:58:39.205883:  
2025-02-21 14:58:39.206091: Epoch 111 
2025-02-21 14:58:39.206151: Current learning rate: 0.009 
2025-02-21 14:59:10.942531: train_loss -0.9108 
2025-02-21 14:59:10.942673: val_loss -0.9194 
2025-02-21 14:59:10.942709: Pseudo dice [0.9705] 
2025-02-21 14:59:10.942750: Epoch time: 31.74 s 
2025-02-21 14:59:11.630521:  
2025-02-21 14:59:11.630707: Epoch 112 
2025-02-21 14:59:11.630803: Current learning rate: 0.00899 
2025-02-21 14:59:43.238076: train_loss -0.9216 
2025-02-21 14:59:43.238213: val_loss -0.9455 
2025-02-21 14:59:43.238249: Pseudo dice [0.9794] 
2025-02-21 14:59:43.238312: Epoch time: 31.61 s 
2025-02-21 14:59:43.920665:  
2025-02-21 14:59:43.920857: Epoch 113 
2025-02-21 14:59:43.920909: Current learning rate: 0.00898 
2025-02-21 15:00:15.450443: train_loss -0.9139 
2025-02-21 15:00:15.450654: val_loss -0.9224 
2025-02-21 15:00:15.450776: Pseudo dice [0.9716] 
2025-02-21 15:00:15.450831: Epoch time: 31.53 s 
2025-02-21 15:00:16.149189:  
2025-02-21 15:00:16.149315: Epoch 114 
2025-02-21 15:00:16.149434: Current learning rate: 0.00897 
2025-02-21 15:00:48.075913: train_loss -0.9074 
2025-02-21 15:00:48.076057: val_loss -0.9249 
2025-02-21 15:00:48.076094: Pseudo dice [0.9729] 
2025-02-21 15:00:48.076133: Epoch time: 31.93 s 
2025-02-21 15:00:49.436181:  
2025-02-21 15:00:49.436355: Epoch 115 
2025-02-21 15:00:49.436414: Current learning rate: 0.00896 
2025-02-21 15:01:21.008138: train_loss -0.897 
2025-02-21 15:01:21.008261: val_loss -0.9234 
2025-02-21 15:01:21.008296: Pseudo dice [0.9741] 
2025-02-21 15:01:21.008331: Epoch time: 31.57 s 
2025-02-21 15:01:21.699893:  
2025-02-21 15:01:21.700065: Epoch 116 
2025-02-21 15:01:21.700139: Current learning rate: 0.00895 
2025-02-21 15:01:53.280119: train_loss -0.9323 
2025-02-21 15:01:53.280310: val_loss -0.9331 
2025-02-21 15:01:53.280353: Pseudo dice [0.9755] 
2025-02-21 15:01:53.280398: Epoch time: 31.58 s 
2025-02-21 15:01:54.003358:  
2025-02-21 15:01:54.003535: Epoch 117 
2025-02-21 15:01:54.003601: Current learning rate: 0.00894 
2025-02-21 15:02:25.672825: train_loss -0.9148 
2025-02-21 15:02:25.672951: val_loss -0.923 
2025-02-21 15:02:25.672988: Pseudo dice [0.9721] 
2025-02-21 15:02:25.673023: Epoch time: 31.67 s 
2025-02-21 15:02:26.375031:  
2025-02-21 15:02:26.375243: Epoch 118 
2025-02-21 15:02:26.375309: Current learning rate: 0.00893 
2025-02-21 15:02:58.475545: train_loss -0.9108 
2025-02-21 15:02:58.475696: val_loss -0.9231 
2025-02-21 15:02:58.475747: Pseudo dice [0.9706] 
2025-02-21 15:02:58.475827: Epoch time: 32.1 s 
2025-02-21 15:02:59.178129:  
2025-02-21 15:02:59.178301: Epoch 119 
2025-02-21 15:02:59.178365: Current learning rate: 0.00892 
2025-02-21 15:03:30.804833: train_loss -0.9225 
2025-02-21 15:03:30.805003: val_loss -0.9307 
2025-02-21 15:03:30.805041: Pseudo dice [0.9729] 
2025-02-21 15:03:30.805080: Epoch time: 31.63 s 
2025-02-21 15:03:31.509004:  
2025-02-21 15:03:31.509208: Epoch 120 
2025-02-21 15:03:31.509277: Current learning rate: 0.00891 
2025-02-21 15:04:03.181751: train_loss -0.9184 
2025-02-21 15:04:03.181892: val_loss -0.9322 
2025-02-21 15:04:03.181928: Pseudo dice [0.9762] 
2025-02-21 15:04:03.181964: Epoch time: 31.67 s 
2025-02-21 15:04:03.877974:  
2025-02-21 15:04:03.878172: Epoch 121 
2025-02-21 15:04:03.878245: Current learning rate: 0.0089 
2025-02-21 15:04:35.698622: train_loss -0.9243 
2025-02-21 15:04:35.698843: val_loss -0.9455 
2025-02-21 15:04:35.698886: Pseudo dice [0.9781] 
2025-02-21 15:04:35.698925: Epoch time: 31.82 s 
2025-02-21 15:04:36.429328:  
2025-02-21 15:04:36.429510: Epoch 122 
2025-02-21 15:04:36.429615: Current learning rate: 0.00889 
2025-02-21 15:05:08.331194: train_loss -0.9189 
2025-02-21 15:05:08.331371: val_loss -0.9333 
2025-02-21 15:05:08.331409: Pseudo dice [0.9738] 
2025-02-21 15:05:08.331447: Epoch time: 31.9 s 
2025-02-21 15:05:09.026659:  
2025-02-21 15:05:09.026906: Epoch 123 
2025-02-21 15:05:09.026954: Current learning rate: 0.00889 
2025-02-21 15:05:40.617048: train_loss -0.9144 
2025-02-21 15:05:40.617193: val_loss -0.9201 
2025-02-21 15:05:40.617230: Pseudo dice [0.9709] 
2025-02-21 15:05:40.617264: Epoch time: 31.59 s 
2025-02-21 15:05:41.321722:  
2025-02-21 15:05:41.321904: Epoch 124 
2025-02-21 15:05:41.321977: Current learning rate: 0.00888 
2025-02-21 15:06:12.838676: train_loss -0.9204 
2025-02-21 15:06:12.838818: val_loss -0.9363 
2025-02-21 15:06:12.838856: Pseudo dice [0.9766] 
2025-02-21 15:06:12.838892: Epoch time: 31.52 s 
2025-02-21 15:06:13.555064:  
2025-02-21 15:06:13.555219: Epoch 125 
2025-02-21 15:06:13.555265: Current learning rate: 0.00887 
2025-02-21 15:06:45.157743: train_loss -0.9161 
2025-02-21 15:06:45.157964: val_loss -0.9217 
2025-02-21 15:06:45.158000: Pseudo dice [0.9704] 
2025-02-21 15:06:45.158042: Epoch time: 31.6 s 
2025-02-21 15:06:45.860007:  
2025-02-21 15:06:45.860219: Epoch 126 
2025-02-21 15:06:45.860267: Current learning rate: 0.00886 
2025-02-21 15:07:17.604283: train_loss -0.9051 
2025-02-21 15:07:17.604452: val_loss -0.9266 
2025-02-21 15:07:17.604511: Pseudo dice [0.9719] 
2025-02-21 15:07:17.604553: Epoch time: 31.75 s 
2025-02-21 15:07:18.304590:  
2025-02-21 15:07:18.304774: Epoch 127 
2025-02-21 15:07:18.304860: Current learning rate: 0.00885 
2025-02-21 15:07:49.817407: train_loss -0.9204 
2025-02-21 15:07:49.817533: val_loss -0.9381 
2025-02-21 15:07:49.817576: Pseudo dice [0.9786] 
2025-02-21 15:07:49.817698: Epoch time: 31.51 s 
2025-02-21 15:07:50.514397:  
2025-02-21 15:07:50.514549: Epoch 128 
2025-02-21 15:07:50.514606: Current learning rate: 0.00884 
2025-02-21 15:08:22.107578: train_loss -0.9181 
2025-02-21 15:08:22.107707: val_loss -0.9304 
2025-02-21 15:08:22.107759: Pseudo dice [0.9734] 
2025-02-21 15:08:22.107817: Epoch time: 31.59 s 
2025-02-21 15:08:22.804473:  
2025-02-21 15:08:22.804614: Epoch 129 
2025-02-21 15:08:22.804671: Current learning rate: 0.00883 
2025-02-21 15:08:54.432665: train_loss -0.9212 
2025-02-21 15:08:54.432840: val_loss -0.9436 
2025-02-21 15:08:54.432908: Pseudo dice [0.9776] 
2025-02-21 15:08:54.432952: Epoch time: 31.63 s 
2025-02-21 15:08:55.135494:  
2025-02-21 15:08:55.135676: Epoch 130 
2025-02-21 15:08:55.135738: Current learning rate: 0.00882 
2025-02-21 15:09:26.936949: train_loss -0.8897 
2025-02-21 15:09:26.937076: val_loss -0.9199 
2025-02-21 15:09:26.937137: Pseudo dice [0.9747] 
2025-02-21 15:09:26.937179: Epoch time: 31.8 s 
2025-02-21 15:09:26.937210: Yayy! New best EMA pseudo Dice: 0.974 
2025-02-21 15:09:28.007367:  
2025-02-21 15:09:28.007560: Epoch 131 
2025-02-21 15:09:28.007649: Current learning rate: 0.00881 
2025-02-21 15:09:59.636568: train_loss -0.9092 
2025-02-21 15:09:59.636735: val_loss -0.9174 
2025-02-21 15:09:59.636866: Pseudo dice [0.9722] 
2025-02-21 15:09:59.636910: Epoch time: 31.63 s 
2025-02-21 15:10:00.975733:  
2025-02-21 15:10:00.975921: Epoch 132 
2025-02-21 15:10:00.975985: Current learning rate: 0.0088 
2025-02-21 15:10:32.554233: train_loss -0.896 
2025-02-21 15:10:32.554455: val_loss -0.8976 
2025-02-21 15:10:32.554499: Pseudo dice [0.9625] 
2025-02-21 15:10:32.554536: Epoch time: 31.58 s 
2025-02-21 15:10:33.261052:  
2025-02-21 15:10:33.261226: Epoch 133 
2025-02-21 15:10:33.261351: Current learning rate: 0.00879 
2025-02-21 15:11:05.315273: train_loss -0.8991 
2025-02-21 15:11:05.315417: val_loss -0.9077 
2025-02-21 15:11:05.315465: Pseudo dice [0.967] 
2025-02-21 15:11:05.315504: Epoch time: 32.05 s 
2025-02-21 15:11:06.017839:  
2025-02-21 15:11:06.018024: Epoch 134 
2025-02-21 15:11:06.018105: Current learning rate: 0.00879 
2025-02-21 15:11:37.645164: train_loss -0.9246 
2025-02-21 15:11:37.645324: val_loss -0.9204 
2025-02-21 15:11:37.645366: Pseudo dice [0.9718] 
2025-02-21 15:11:37.645404: Epoch time: 31.63 s 
2025-02-21 15:11:38.361013:  
2025-02-21 15:11:38.361197: Epoch 135 
2025-02-21 15:11:38.361268: Current learning rate: 0.00878 
2025-02-21 15:12:10.403622: train_loss -0.9184 
2025-02-21 15:12:10.404460: val_loss -0.9412 
2025-02-21 15:12:10.404514: Pseudo dice [0.9785] 
2025-02-21 15:12:10.404562: Epoch time: 32.04 s 
2025-02-21 15:12:11.130070:  
2025-02-21 15:12:11.130296: Epoch 136 
2025-02-21 15:12:11.130392: Current learning rate: 0.00877 
2025-02-21 15:12:42.828918: train_loss -0.9121 
2025-02-21 15:12:42.829242: val_loss -0.9181 
2025-02-21 15:12:42.829283: Pseudo dice [0.9658] 
2025-02-21 15:12:42.829333: Epoch time: 31.7 s 
2025-02-21 15:12:43.577052:  
2025-02-21 15:12:43.577259: Epoch 137 
2025-02-21 15:12:43.577320: Current learning rate: 0.00876 
2025-02-21 15:13:15.446056: train_loss -0.9178 
2025-02-21 15:13:15.446207: val_loss -0.9319 
2025-02-21 15:13:15.446332: Pseudo dice [0.9745] 
2025-02-21 15:13:15.446374: Epoch time: 31.87 s 
2025-02-21 15:13:16.161626:  
2025-02-21 15:13:16.161783: Epoch 138 
2025-02-21 15:13:16.161892: Current learning rate: 0.00875 
2025-02-21 15:13:47.712661: train_loss -0.9168 
2025-02-21 15:13:47.712802: val_loss -0.9348 
2025-02-21 15:13:47.712848: Pseudo dice [0.9764] 
2025-02-21 15:13:47.712887: Epoch time: 31.55 s 
2025-02-21 15:13:48.423494:  
2025-02-21 15:13:48.423640: Epoch 139 
2025-02-21 15:13:48.423728: Current learning rate: 0.00874 
2025-02-21 15:14:19.863544: train_loss -0.9231 
2025-02-21 15:14:19.863689: val_loss -0.9363 
2025-02-21 15:14:19.863777: Pseudo dice [0.9758] 
2025-02-21 15:14:19.863868: Epoch time: 31.44 s 
2025-02-21 15:14:20.586233:  
2025-02-21 15:14:20.586371: Epoch 140 
2025-02-21 15:14:20.586459: Current learning rate: 0.00873 
2025-02-21 15:14:52.483137: train_loss -0.9233 
2025-02-21 15:14:52.483291: val_loss -0.9264 
2025-02-21 15:14:52.483330: Pseudo dice [0.9733] 
2025-02-21 15:14:52.483370: Epoch time: 31.9 s 
2025-02-21 15:14:53.202699:  
2025-02-21 15:14:53.202900: Epoch 141 
2025-02-21 15:14:53.202958: Current learning rate: 0.00872 
2025-02-21 15:15:24.798766: train_loss -0.9116 
2025-02-21 15:15:24.798940: val_loss -0.9367 
2025-02-21 15:15:24.798978: Pseudo dice [0.9757] 
2025-02-21 15:15:24.799017: Epoch time: 31.6 s 
2025-02-21 15:15:25.514444:  
2025-02-21 15:15:25.514629: Epoch 142 
2025-02-21 15:15:25.514696: Current learning rate: 0.00871 
2025-02-21 15:15:57.094921: train_loss -0.9144 
2025-02-21 15:15:57.095075: val_loss -0.9386 
2025-02-21 15:15:57.095114: Pseudo dice [0.976] 
2025-02-21 15:15:57.095153: Epoch time: 31.58 s 
2025-02-21 15:15:57.804235:  
2025-02-21 15:15:57.804422: Epoch 143 
2025-02-21 15:15:57.804516: Current learning rate: 0.0087 
2025-02-21 15:16:29.345174: train_loss -0.9294 
2025-02-21 15:16:29.345326: val_loss -0.9358 
2025-02-21 15:16:29.345362: Pseudo dice [0.9769] 
2025-02-21 15:16:29.345402: Epoch time: 31.54 s 
2025-02-21 15:16:30.061754:  
2025-02-21 15:16:30.061962: Epoch 144 
2025-02-21 15:16:30.062040: Current learning rate: 0.00869 
2025-02-21 15:17:01.823915: train_loss -0.9212 
2025-02-21 15:17:01.824068: val_loss -0.9465 
2025-02-21 15:17:01.824106: Pseudo dice [0.9814] 
2025-02-21 15:17:01.824144: Epoch time: 31.76 s 
2025-02-21 15:17:01.824173: Yayy! New best EMA pseudo Dice: 0.9747 
2025-02-21 15:17:02.855220:  
2025-02-21 15:17:02.855416: Epoch 145 
2025-02-21 15:17:02.855500: Current learning rate: 0.00868 
2025-02-21 15:17:34.500451: train_loss -0.9161 
2025-02-21 15:17:34.500609: val_loss -0.9187 
2025-02-21 15:17:34.500646: Pseudo dice [0.9695] 
2025-02-21 15:17:34.500684: Epoch time: 31.65 s 
2025-02-21 15:17:35.211826:  
2025-02-21 15:17:35.212027: Epoch 146 
2025-02-21 15:17:35.212080: Current learning rate: 0.00868 
2025-02-21 15:18:06.859669: train_loss -0.8981 
2025-02-21 15:18:06.859833: val_loss -0.9326 
2025-02-21 15:18:06.859875: Pseudo dice [0.9732] 
2025-02-21 15:18:06.859946: Epoch time: 31.65 s 
2025-02-21 15:18:07.568869:  
2025-02-21 15:18:07.569026: Epoch 147 
2025-02-21 15:18:07.569108: Current learning rate: 0.00867 
2025-02-21 15:18:39.104616: train_loss -0.9324 
2025-02-21 15:18:39.104748: val_loss -0.9304 
2025-02-21 15:18:39.104784: Pseudo dice [0.9739] 
2025-02-21 15:18:39.104829: Epoch time: 31.54 s 
2025-02-21 15:18:39.820571:  
2025-02-21 15:18:39.820749: Epoch 148 
2025-02-21 15:18:39.820803: Current learning rate: 0.00866 
2025-02-21 15:19:11.728862: train_loss -0.9069 
2025-02-21 15:19:11.729024: val_loss -0.9445 
2025-02-21 15:19:11.729063: Pseudo dice [0.9777] 
2025-02-21 15:19:11.729104: Epoch time: 31.91 s 
2025-02-21 15:19:13.392050:  
2025-02-21 15:19:13.392288: Epoch 149 
2025-02-21 15:19:13.392349: Current learning rate: 0.00865 
2025-02-21 15:19:44.999833: train_loss -0.919 
2025-02-21 15:19:44.999987: val_loss -0.9261 
2025-02-21 15:19:45.000025: Pseudo dice [0.973] 
2025-02-21 15:19:45.000065: Epoch time: 31.61 s 
2025-02-21 15:19:46.048855:  
2025-02-21 15:19:46.049086: Epoch 150 
2025-02-21 15:19:46.049159: Current learning rate: 0.00864 
2025-02-21 15:20:17.682368: train_loss -0.905 
2025-02-21 15:20:17.682501: val_loss -0.9271 
2025-02-21 15:20:17.682543: Pseudo dice [0.9747] 
2025-02-21 15:20:17.682612: Epoch time: 31.63 s 
2025-02-21 15:20:18.395298:  
2025-02-21 15:20:18.395492: Epoch 151 
2025-02-21 15:20:18.395566: Current learning rate: 0.00863 
2025-02-21 15:20:50.023039: train_loss -0.9268 
2025-02-21 15:20:50.023194: val_loss -0.9339 
2025-02-21 15:20:50.023230: Pseudo dice [0.9748] 
2025-02-21 15:20:50.023268: Epoch time: 31.63 s 
2025-02-21 15:20:50.745030:  
2025-02-21 15:20:50.745231: Epoch 152 
2025-02-21 15:20:50.745289: Current learning rate: 0.00862 
2025-02-21 15:21:22.589838: train_loss -0.9217 
2025-02-21 15:21:22.590016: val_loss -0.9314 
2025-02-21 15:21:22.590060: Pseudo dice [0.9733] 
2025-02-21 15:21:22.590099: Epoch time: 31.85 s 
2025-02-21 15:21:23.306211:  
2025-02-21 15:21:23.306418: Epoch 153 
2025-02-21 15:21:23.306481: Current learning rate: 0.00861 
2025-02-21 15:21:54.927847: train_loss -0.9202 
2025-02-21 15:21:54.928012: val_loss -0.9424 
2025-02-21 15:21:54.928051: Pseudo dice [0.9767] 
2025-02-21 15:21:54.928100: Epoch time: 31.62 s 
2025-02-21 15:21:55.647279:  
2025-02-21 15:21:55.647432: Epoch 154 
2025-02-21 15:21:55.647474: Current learning rate: 0.0086 
2025-02-21 15:22:27.194918: train_loss -0.9129 
2025-02-21 15:22:27.195052: val_loss -0.9345 
2025-02-21 15:22:27.195087: Pseudo dice [0.9756] 
2025-02-21 15:22:27.195124: Epoch time: 31.55 s 
2025-02-21 15:22:27.919056:  
2025-02-21 15:22:27.919201: Epoch 155 
2025-02-21 15:22:27.919286: Current learning rate: 0.00859 
2025-02-21 15:22:59.872429: train_loss -0.9079 
2025-02-21 15:22:59.872607: val_loss -0.9153 
2025-02-21 15:22:59.872707: Pseudo dice [0.968] 
2025-02-21 15:22:59.872753: Epoch time: 31.95 s 
2025-02-21 15:23:00.616976:  
2025-02-21 15:23:00.617153: Epoch 156 
2025-02-21 15:23:00.617271: Current learning rate: 0.00858 
2025-02-21 15:23:32.098712: train_loss -0.924 
2025-02-21 15:23:32.098863: val_loss -0.9341 
2025-02-21 15:23:32.098906: Pseudo dice [0.9749] 
2025-02-21 15:23:32.098948: Epoch time: 31.48 s 
2025-02-21 15:23:32.835135:  
2025-02-21 15:23:32.835346: Epoch 157 
2025-02-21 15:23:32.835424: Current learning rate: 0.00858 
2025-02-21 15:24:04.382557: train_loss -0.9031 
2025-02-21 15:24:04.382698: val_loss -0.931 
2025-02-21 15:24:04.382738: Pseudo dice [0.9764] 
2025-02-21 15:24:04.382778: Epoch time: 31.55 s 
2025-02-21 15:24:05.096894:  
2025-02-21 15:24:05.097050: Epoch 158 
2025-02-21 15:24:05.097116: Current learning rate: 0.00857 
2025-02-21 15:24:36.753077: train_loss -0.9196 
2025-02-21 15:24:36.753210: val_loss -0.9122 
2025-02-21 15:24:36.753245: Pseudo dice [0.967] 
2025-02-21 15:24:36.753281: Epoch time: 31.66 s 
2025-02-21 15:24:37.469147:  
2025-02-21 15:24:37.469281: Epoch 159 
2025-02-21 15:24:37.469355: Current learning rate: 0.00856 
2025-02-21 15:25:09.787902: train_loss -0.9122 
2025-02-21 15:25:09.788104: val_loss -0.9255 
2025-02-21 15:25:09.788143: Pseudo dice [0.9741] 
2025-02-21 15:25:09.788186: Epoch time: 32.32 s 
2025-02-21 15:25:10.540003:  
2025-02-21 15:25:10.540187: Epoch 160 
2025-02-21 15:25:10.540243: Current learning rate: 0.00855 
2025-02-21 15:25:42.746108: train_loss -0.9181 
2025-02-21 15:25:42.746394: val_loss -0.9285 
2025-02-21 15:25:42.746439: Pseudo dice [0.9734] 
2025-02-21 15:25:42.746505: Epoch time: 32.21 s 
2025-02-21 15:25:43.471336:  
2025-02-21 15:25:43.471516: Epoch 161 
2025-02-21 15:25:43.471590: Current learning rate: 0.00854 
2025-02-21 15:26:15.085207: train_loss -0.9312 
2025-02-21 15:26:15.085345: val_loss -0.9389 
2025-02-21 15:26:15.085382: Pseudo dice [0.9754] 
2025-02-21 15:26:15.085421: Epoch time: 31.61 s 
2025-02-21 15:26:15.804450:  
2025-02-21 15:26:15.804657: Epoch 162 
2025-02-21 15:26:15.804717: Current learning rate: 0.00853 
2025-02-21 15:26:47.559227: train_loss -0.9263 
2025-02-21 15:26:47.559408: val_loss -0.9455 
2025-02-21 15:26:47.559444: Pseudo dice [0.9805] 
2025-02-21 15:26:47.559492: Epoch time: 31.76 s 
2025-02-21 15:26:48.315569:  
2025-02-21 15:26:48.315771: Epoch 163 
2025-02-21 15:26:48.315905: Current learning rate: 0.00852 
2025-02-21 15:27:20.259002: train_loss -0.9329 
2025-02-21 15:27:20.259135: val_loss -0.9456 
2025-02-21 15:27:20.259211: Pseudo dice [0.9803] 
2025-02-21 15:27:20.259297: Epoch time: 31.94 s 
2025-02-21 15:27:20.259337: Yayy! New best EMA pseudo Dice: 0.975 
2025-02-21 15:27:21.301429:  
2025-02-21 15:27:21.301620: Epoch 164 
2025-02-21 15:27:21.301701: Current learning rate: 0.00851 
2025-02-21 15:27:52.908334: train_loss -0.9076 
2025-02-21 15:27:52.908469: val_loss -0.9447 
2025-02-21 15:27:52.908508: Pseudo dice [0.9795] 
2025-02-21 15:27:52.908544: Epoch time: 31.61 s 
2025-02-21 15:27:52.908572: Yayy! New best EMA pseudo Dice: 0.9755 
2025-02-21 15:27:53.949385:  
2025-02-21 15:27:53.949554: Epoch 165 
2025-02-21 15:27:53.949621: Current learning rate: 0.0085 
2025-02-21 15:28:25.744445: train_loss -0.8982 
2025-02-21 15:28:25.744604: val_loss -0.9328 
2025-02-21 15:28:25.744640: Pseudo dice [0.9747] 
2025-02-21 15:28:25.744677: Epoch time: 31.8 s 
2025-02-21 15:28:27.106035:  
2025-02-21 15:28:27.106249: Epoch 166 
2025-02-21 15:28:27.106298: Current learning rate: 0.00849 
2025-02-21 15:28:58.701504: train_loss -0.9218 
2025-02-21 15:28:58.701632: val_loss -0.9411 
2025-02-21 15:28:58.701668: Pseudo dice [0.9783] 
2025-02-21 15:28:58.701704: Epoch time: 31.6 s 
2025-02-21 15:28:58.701730: Yayy! New best EMA pseudo Dice: 0.9757 
2025-02-21 15:28:59.755564:  
2025-02-21 15:28:59.755771: Epoch 167 
2025-02-21 15:28:59.755833: Current learning rate: 0.00848 
2025-02-21 15:29:31.644045: train_loss -0.9061 
2025-02-21 15:29:31.644178: val_loss -0.9542 
2025-02-21 15:29:31.644223: Pseudo dice [0.983] 
2025-02-21 15:29:31.644260: Epoch time: 31.89 s 
2025-02-21 15:29:31.644288: Yayy! New best EMA pseudo Dice: 0.9764 
2025-02-21 15:29:32.687553:  
2025-02-21 15:29:32.687729: Epoch 168 
2025-02-21 15:29:32.687782: Current learning rate: 0.00847 
2025-02-21 15:30:04.152275: train_loss -0.932 
2025-02-21 15:30:04.152417: val_loss -0.9279 
2025-02-21 15:30:04.152453: Pseudo dice [0.9742] 
2025-02-21 15:30:04.152496: Epoch time: 31.47 s 
2025-02-21 15:30:04.875616:  
2025-02-21 15:30:04.875840: Epoch 169 
2025-02-21 15:30:04.875889: Current learning rate: 0.00847 
2025-02-21 15:30:36.345019: train_loss -0.9312 
2025-02-21 15:30:36.345146: val_loss -0.9107 
2025-02-21 15:30:36.345190: Pseudo dice [0.9676] 
2025-02-21 15:30:36.345229: Epoch time: 31.47 s 
2025-02-21 15:30:37.059598:  
2025-02-21 15:30:37.059819: Epoch 170 
2025-02-21 15:30:37.059882: Current learning rate: 0.00846 
2025-02-21 15:31:08.742310: train_loss -0.9022 
2025-02-21 15:31:08.742465: val_loss -0.9436 
2025-02-21 15:31:08.742501: Pseudo dice [0.9783] 
2025-02-21 15:31:08.742599: Epoch time: 31.68 s 
2025-02-21 15:31:09.459851:  
2025-02-21 15:31:09.460027: Epoch 171 
2025-02-21 15:31:09.460074: Current learning rate: 0.00845 
2025-02-21 15:31:41.194966: train_loss -0.9281 
2025-02-21 15:31:41.195106: val_loss -0.9594 
2025-02-21 15:31:41.195143: Pseudo dice [0.9839] 
2025-02-21 15:31:41.195183: Epoch time: 31.74 s 
2025-02-21 15:31:41.195211: Yayy! New best EMA pseudo Dice: 0.9765 
2025-02-21 15:31:42.232857:  
2025-02-21 15:31:42.233005: Epoch 172 
2025-02-21 15:31:42.233066: Current learning rate: 0.00844 
2025-02-21 15:32:13.896051: train_loss -0.9386 
2025-02-21 15:32:13.896185: val_loss -0.9152 
2025-02-21 15:32:13.896221: Pseudo dice [0.9727] 
2025-02-21 15:32:13.896258: Epoch time: 31.66 s 
2025-02-21 15:32:14.622231:  
2025-02-21 15:32:14.622391: Epoch 173 
2025-02-21 15:32:14.622453: Current learning rate: 0.00843 
2025-02-21 15:32:46.136019: train_loss -0.9286 
2025-02-21 15:32:46.136167: val_loss -0.9364 
2025-02-21 15:32:46.136204: Pseudo dice [0.9738] 
2025-02-21 15:32:46.136243: Epoch time: 31.51 s 
2025-02-21 15:32:46.842595:  
2025-02-21 15:32:46.842777: Epoch 174 
2025-02-21 15:32:46.842844: Current learning rate: 0.00842 
2025-02-21 15:33:18.869661: train_loss -0.9262 
2025-02-21 15:33:18.869784: val_loss -0.9366 
2025-02-21 15:33:18.869826: Pseudo dice [0.979] 
2025-02-21 15:33:18.869865: Epoch time: 32.03 s 
2025-02-21 15:33:19.587194:  
2025-02-21 15:33:19.587393: Epoch 175 
2025-02-21 15:33:19.587499: Current learning rate: 0.00841 
2025-02-21 15:33:51.124047: train_loss -0.9282 
2025-02-21 15:33:51.124202: val_loss -0.9408 
2025-02-21 15:33:51.124245: Pseudo dice [0.977] 
2025-02-21 15:33:51.124281: Epoch time: 31.54 s 
2025-02-21 15:33:51.850858:  
2025-02-21 15:33:51.851044: Epoch 176 
2025-02-21 15:33:51.851130: Current learning rate: 0.0084 
2025-02-21 15:34:23.558717: train_loss -0.9136 
2025-02-21 15:34:23.558877: val_loss -0.9377 
2025-02-21 15:34:23.558920: Pseudo dice [0.9763] 
2025-02-21 15:34:23.558959: Epoch time: 31.71 s 
2025-02-21 15:34:24.272418:  
2025-02-21 15:34:24.272549: Epoch 177 
2025-02-21 15:34:24.272594: Current learning rate: 0.00839 
2025-02-21 15:34:55.888533: train_loss -0.9214 
2025-02-21 15:34:55.888708: val_loss -0.9423 
2025-02-21 15:34:55.888745: Pseudo dice [0.9799] 
2025-02-21 15:34:55.888784: Epoch time: 31.62 s 
2025-02-21 15:34:55.888816: Yayy! New best EMA pseudo Dice: 0.9766 
2025-02-21 15:34:56.988949:  
2025-02-21 15:34:56.989157: Epoch 178 
2025-02-21 15:34:56.989254: Current learning rate: 0.00838 
2025-02-21 15:35:28.692926: train_loss -0.9383 
2025-02-21 15:35:28.693066: val_loss -0.9416 
2025-02-21 15:35:28.693104: Pseudo dice [0.979] 
2025-02-21 15:35:28.693142: Epoch time: 31.7 s 
2025-02-21 15:35:28.693170: Yayy! New best EMA pseudo Dice: 0.9769 
2025-02-21 15:35:29.750005:  
2025-02-21 15:35:29.750181: Epoch 179 
2025-02-21 15:35:29.750238: Current learning rate: 0.00837 
2025-02-21 15:36:01.774076: train_loss -0.9318 
2025-02-21 15:36:01.774265: val_loss -0.9433 
2025-02-21 15:36:01.774311: Pseudo dice [0.9795] 
2025-02-21 15:36:01.774358: Epoch time: 32.02 s 
2025-02-21 15:36:01.774393: Yayy! New best EMA pseudo Dice: 0.9771 
2025-02-21 15:36:02.878824:  
2025-02-21 15:36:02.879022: Epoch 180 
2025-02-21 15:36:02.879100: Current learning rate: 0.00836 
2025-02-21 15:36:35.037478: train_loss -0.924 
2025-02-21 15:36:35.037655: val_loss -0.9302 
2025-02-21 15:36:35.037694: Pseudo dice [0.978] 
2025-02-21 15:36:35.037735: Epoch time: 32.16 s 
2025-02-21 15:36:35.037765: Yayy! New best EMA pseudo Dice: 0.9772 
2025-02-21 15:36:36.051796:  
2025-02-21 15:36:36.051924: Epoch 181 
2025-02-21 15:36:36.052002: Current learning rate: 0.00836 
2025-02-21 15:37:08.147941: train_loss -0.9242 
2025-02-21 15:37:08.148073: val_loss -0.9447 
2025-02-21 15:37:08.148113: Pseudo dice [0.9789] 
2025-02-21 15:37:08.148154: Epoch time: 32.1 s 
2025-02-21 15:37:08.148183: Yayy! New best EMA pseudo Dice: 0.9774 
2025-02-21 15:37:10.047801:  
2025-02-21 15:37:10.047978: Epoch 182 
2025-02-21 15:37:10.048049: Current learning rate: 0.00835 
2025-02-21 15:37:41.758591: train_loss -0.9131 
2025-02-21 15:37:41.758741: val_loss -0.9427 
2025-02-21 15:37:41.758779: Pseudo dice [0.9805] 
2025-02-21 15:37:41.758822: Epoch time: 31.71 s 
2025-02-21 15:37:41.758853: Yayy! New best EMA pseudo Dice: 0.9777 
2025-02-21 15:37:42.813374:  
2025-02-21 15:37:42.813539: Epoch 183 
2025-02-21 15:37:42.813597: Current learning rate: 0.00834 
2025-02-21 15:38:14.465253: train_loss -0.9166 
2025-02-21 15:38:14.465400: val_loss -0.9534 
2025-02-21 15:38:14.465515: Pseudo dice [0.9829] 
2025-02-21 15:38:14.465594: Epoch time: 31.65 s 
2025-02-21 15:38:14.465626: Yayy! New best EMA pseudo Dice: 0.9782 
2025-02-21 15:38:15.615811:  
2025-02-21 15:38:15.616042: Epoch 184 
2025-02-21 15:38:15.616129: Current learning rate: 0.00833 
2025-02-21 15:38:47.359567: train_loss -0.9199 
2025-02-21 15:38:47.359696: val_loss -0.9289 
2025-02-21 15:38:47.359742: Pseudo dice [0.9738] 
2025-02-21 15:38:47.359790: Epoch time: 31.74 s 
2025-02-21 15:38:48.072064:  
2025-02-21 15:38:48.072297: Epoch 185 
2025-02-21 15:38:48.072378: Current learning rate: 0.00832 
2025-02-21 15:39:19.643723: train_loss -0.923 
2025-02-21 15:39:19.643920: val_loss -0.9109 
2025-02-21 15:39:19.643958: Pseudo dice [0.9672] 
2025-02-21 15:39:19.643997: Epoch time: 31.57 s 
2025-02-21 15:39:20.457000:  
2025-02-21 15:39:20.457211: Epoch 186 
2025-02-21 15:39:20.457313: Current learning rate: 0.00831 
2025-02-21 15:39:52.626060: train_loss -0.9131 
2025-02-21 15:39:52.626189: val_loss -0.9432 
2025-02-21 15:39:52.626225: Pseudo dice [0.9788] 
2025-02-21 15:39:52.626262: Epoch time: 32.17 s 
2025-02-21 15:39:53.334747:  
2025-02-21 15:39:53.334919: Epoch 187 
2025-02-21 15:39:53.334987: Current learning rate: 0.0083 
2025-02-21 15:40:24.999666: train_loss -0.9243 
2025-02-21 15:40:24.999805: val_loss -0.9528 
2025-02-21 15:40:24.999858: Pseudo dice [0.983] 
2025-02-21 15:40:24.999911: Epoch time: 31.67 s 
2025-02-21 15:40:25.710169:  
2025-02-21 15:40:25.710309: Epoch 188 
2025-02-21 15:40:25.710392: Current learning rate: 0.00829 
2025-02-21 15:40:57.731305: train_loss -0.9043 
2025-02-21 15:40:57.731502: val_loss -0.9311 
2025-02-21 15:40:57.731540: Pseudo dice [0.9756] 
2025-02-21 15:40:57.731580: Epoch time: 32.02 s 
2025-02-21 15:40:58.535414:  
2025-02-21 15:40:58.535621: Epoch 189 
2025-02-21 15:40:58.535682: Current learning rate: 0.00828 
2025-02-21 15:41:30.462954: train_loss -0.9184 
2025-02-21 15:41:30.463279: val_loss -0.9476 
2025-02-21 15:41:30.463317: Pseudo dice [0.9816] 
2025-02-21 15:41:30.463359: Epoch time: 31.93 s 
2025-02-21 15:41:31.207326:  
2025-02-21 15:41:31.207473: Epoch 190 
2025-02-21 15:41:31.207573: Current learning rate: 0.00827 
2025-02-21 15:42:03.451903: train_loss -0.9127 
2025-02-21 15:42:03.452070: val_loss -0.926 
2025-02-21 15:42:03.452142: Pseudo dice [0.9722] 
2025-02-21 15:42:03.452184: Epoch time: 32.25 s 
2025-02-21 15:42:04.176662:  
2025-02-21 15:42:04.176945: Epoch 191 
2025-02-21 15:42:04.177032: Current learning rate: 0.00826 
2025-02-21 15:42:36.401353: train_loss -0.9059 
2025-02-21 15:42:36.401509: val_loss -0.9427 
2025-02-21 15:42:36.401593: Pseudo dice [0.9793] 
2025-02-21 15:42:36.401654: Epoch time: 32.23 s 
2025-02-21 15:42:37.329160:  
2025-02-21 15:42:37.329359: Epoch 192 
2025-02-21 15:42:37.329442: Current learning rate: 0.00825 
2025-02-21 15:43:09.342438: train_loss -0.9336 
2025-02-21 15:43:09.342669: val_loss -0.936 
2025-02-21 15:43:09.342708: Pseudo dice [0.9739] 
2025-02-21 15:43:09.342749: Epoch time: 32.01 s 
2025-02-21 15:43:10.062445:  
2025-02-21 15:43:10.062619: Epoch 193 
2025-02-21 15:43:10.062680: Current learning rate: 0.00824 
2025-02-21 15:43:41.697747: train_loss -0.9298 
2025-02-21 15:43:41.697892: val_loss -0.9553 
2025-02-21 15:43:41.697929: Pseudo dice [0.9841] 
2025-02-21 15:43:41.697968: Epoch time: 31.64 s 
2025-02-21 15:43:42.423888:  
2025-02-21 15:43:42.424057: Epoch 194 
2025-02-21 15:43:42.424125: Current learning rate: 0.00824 
2025-02-21 15:44:14.251478: train_loss -0.9063 
2025-02-21 15:44:14.251621: val_loss -0.9168 
2025-02-21 15:44:14.251657: Pseudo dice [0.9687] 
2025-02-21 15:44:14.251695: Epoch time: 31.83 s 
2025-02-21 15:44:14.976858:  
2025-02-21 15:44:14.977054: Epoch 195 
2025-02-21 15:44:14.977099: Current learning rate: 0.00823 
2025-02-21 15:44:47.178295: train_loss -0.9208 
2025-02-21 15:44:47.178550: val_loss -0.9412 
2025-02-21 15:44:47.178590: Pseudo dice [0.9784] 
2025-02-21 15:44:47.178630: Epoch time: 32.2 s 
2025-02-21 15:44:47.908083:  
2025-02-21 15:44:47.908293: Epoch 196 
2025-02-21 15:44:47.908386: Current learning rate: 0.00822 
2025-02-21 15:45:19.995556: train_loss -0.9165 
2025-02-21 15:45:19.995698: val_loss -0.9416 
2025-02-21 15:45:19.995734: Pseudo dice [0.9787] 
2025-02-21 15:45:19.995773: Epoch time: 32.09 s 
2025-02-21 15:45:20.723574:  
2025-02-21 15:45:20.723765: Epoch 197 
2025-02-21 15:45:20.723852: Current learning rate: 0.00821 
2025-02-21 15:45:52.490301: train_loss -0.9206 
2025-02-21 15:45:52.490436: val_loss -0.9285 
2025-02-21 15:45:52.490473: Pseudo dice [0.9748] 
2025-02-21 15:45:52.490512: Epoch time: 31.77 s 
2025-02-21 15:45:53.214532:  
2025-02-21 15:45:53.214692: Epoch 198 
2025-02-21 15:45:53.214770: Current learning rate: 0.0082 
2025-02-21 15:46:25.186563: train_loss -0.9082 
2025-02-21 15:46:25.186817: val_loss -0.9383 
2025-02-21 15:46:25.186860: Pseudo dice [0.9766] 
2025-02-21 15:46:25.186900: Epoch time: 31.97 s 
2025-02-21 15:46:26.586135:  
2025-02-21 15:46:26.586325: Epoch 199 
2025-02-21 15:46:26.586375: Current learning rate: 0.00819 
2025-02-21 15:46:58.015437: train_loss -0.9308 
2025-02-21 15:46:58.015567: val_loss -0.9459 
2025-02-21 15:46:58.015604: Pseudo dice [0.9788] 
2025-02-21 15:46:58.015676: Epoch time: 31.43 s 
2025-02-21 15:46:59.093380:  
2025-02-21 15:46:59.093544: Epoch 200 
2025-02-21 15:46:59.093595: Current learning rate: 0.00818 
2025-02-21 15:47:30.843659: train_loss -0.9208 
2025-02-21 15:47:30.843814: val_loss -0.9449 
2025-02-21 15:47:30.843853: Pseudo dice [0.9792] 
2025-02-21 15:47:30.843894: Epoch time: 31.75 s 
2025-02-21 15:47:31.602712:  
2025-02-21 15:47:31.602946: Epoch 201 
2025-02-21 15:47:31.603019: Current learning rate: 0.00817 
2025-02-21 15:48:03.001523: train_loss -0.9127 
2025-02-21 15:48:03.001681: val_loss -0.9357 
2025-02-21 15:48:03.001718: Pseudo dice [0.9741] 
2025-02-21 15:48:03.001756: Epoch time: 31.4 s 
2025-02-21 15:48:03.731815:  
2025-02-21 15:48:03.732048: Epoch 202 
2025-02-21 15:48:03.732139: Current learning rate: 0.00816 
2025-02-21 15:48:35.316779: train_loss -0.9189 
2025-02-21 15:48:35.316964: val_loss -0.9117 
2025-02-21 15:48:35.317049: Pseudo dice [0.9666] 
2025-02-21 15:48:35.317092: Epoch time: 31.59 s 
2025-02-21 15:48:36.052756:  
2025-02-21 15:48:36.052909: Epoch 203 
2025-02-21 15:48:36.053005: Current learning rate: 0.00815 
2025-02-21 15:49:07.778589: train_loss -0.9108 
2025-02-21 15:49:07.778760: val_loss -0.9428 
2025-02-21 15:49:07.778799: Pseudo dice [0.9794] 
2025-02-21 15:49:07.778847: Epoch time: 31.73 s 
2025-02-21 15:49:08.519441:  
2025-02-21 15:49:08.519658: Epoch 204 
2025-02-21 15:49:08.519733: Current learning rate: 0.00814 
2025-02-21 15:49:40.028031: train_loss -0.9128 
2025-02-21 15:49:40.028213: val_loss -0.9381 
2025-02-21 15:49:40.028258: Pseudo dice [0.9789] 
2025-02-21 15:49:40.028306: Epoch time: 31.51 s 
2025-02-21 15:49:40.764772:  
2025-02-21 15:49:40.765018: Epoch 205 
2025-02-21 15:49:40.765120: Current learning rate: 0.00813 
2025-02-21 15:50:12.186760: train_loss -0.9231 
2025-02-21 15:50:12.186896: val_loss -0.9412 
2025-02-21 15:50:12.186933: Pseudo dice [0.9753] 
2025-02-21 15:50:12.186970: Epoch time: 31.42 s 
2025-02-21 15:50:12.870263:  
2025-02-21 15:50:12.870413: Epoch 206 
2025-02-21 15:50:12.870540: Current learning rate: 0.00813 
2025-02-21 15:50:44.578026: train_loss -0.9338 
2025-02-21 15:50:44.578215: val_loss -0.9488 
2025-02-21 15:50:44.578253: Pseudo dice [0.9804] 
2025-02-21 15:50:44.578293: Epoch time: 31.71 s 
2025-02-21 15:50:45.317491:  
2025-02-21 15:50:45.317724: Epoch 207 
2025-02-21 15:50:45.317819: Current learning rate: 0.00812 
2025-02-21 15:51:16.799467: train_loss -0.9118 
2025-02-21 15:51:16.799611: val_loss -0.9204 
2025-02-21 15:51:16.799647: Pseudo dice [0.9709] 
2025-02-21 15:51:16.799685: Epoch time: 31.48 s 
2025-02-21 15:51:17.477801:  
2025-02-21 15:51:17.477968: Epoch 208 
2025-02-21 15:51:17.478030: Current learning rate: 0.00811 
2025-02-21 15:51:48.961597: train_loss -0.9295 
2025-02-21 15:51:48.961771: val_loss -0.9386 
2025-02-21 15:51:48.961841: Pseudo dice [0.9742] 
2025-02-21 15:51:48.961881: Epoch time: 31.48 s 
2025-02-21 15:51:49.648862:  
2025-02-21 15:51:49.649050: Epoch 209 
2025-02-21 15:51:49.649123: Current learning rate: 0.0081 
2025-02-21 15:52:21.214218: train_loss -0.9271 
2025-02-21 15:52:21.214478: val_loss -0.9242 
2025-02-21 15:52:21.214521: Pseudo dice [0.9733] 
2025-02-21 15:52:21.214570: Epoch time: 31.57 s 
2025-02-21 15:52:21.952720:  
2025-02-21 15:52:21.952950: Epoch 210 
2025-02-21 15:52:21.953058: Current learning rate: 0.00809 
2025-02-21 15:52:53.616131: train_loss -0.9366 
2025-02-21 15:52:53.616285: val_loss -0.9438 
2025-02-21 15:52:53.616334: Pseudo dice [0.9786] 
2025-02-21 15:52:53.616373: Epoch time: 31.66 s 
2025-02-21 15:52:54.297796:  
2025-02-21 15:52:54.297993: Epoch 211 
2025-02-21 15:52:54.298038: Current learning rate: 0.00808 
2025-02-21 15:53:25.665622: train_loss -0.9267 
2025-02-21 15:53:25.665764: val_loss -0.9378 
2025-02-21 15:53:25.665801: Pseudo dice [0.9773] 
2025-02-21 15:53:25.665849: Epoch time: 31.37 s 
2025-02-21 15:53:26.348328:  
2025-02-21 15:53:26.348506: Epoch 212 
2025-02-21 15:53:26.348611: Current learning rate: 0.00807 
2025-02-21 15:53:57.742726: train_loss -0.9298 
2025-02-21 15:53:57.742890: val_loss -0.9485 
2025-02-21 15:53:57.742926: Pseudo dice [0.9817] 
2025-02-21 15:53:57.742963: Epoch time: 31.4 s 
2025-02-21 15:53:58.432540:  
2025-02-21 15:53:58.432704: Epoch 213 
2025-02-21 15:53:58.432757: Current learning rate: 0.00806 
2025-02-21 15:54:29.949198: train_loss -0.9109 
2025-02-21 15:54:29.949348: val_loss -0.9399 
2025-02-21 15:54:29.949387: Pseudo dice [0.9754] 
2025-02-21 15:54:29.949452: Epoch time: 31.52 s 
2025-02-21 15:54:30.629802:  
2025-02-21 15:54:30.629944: Epoch 214 
2025-02-21 15:54:30.630014: Current learning rate: 0.00805 
2025-02-21 15:55:02.653231: train_loss -0.9253 
2025-02-21 15:55:02.653567: val_loss -0.954 
2025-02-21 15:55:02.653610: Pseudo dice [0.9821] 
2025-02-21 15:55:02.653652: Epoch time: 32.02 s 
2025-02-21 15:55:03.403685:  
2025-02-21 15:55:03.403944: Epoch 215 
2025-02-21 15:55:03.404021: Current learning rate: 0.00804 
2025-02-21 15:55:34.968020: train_loss -0.9218 
2025-02-21 15:55:34.968167: val_loss -0.9352 
2025-02-21 15:55:34.968206: Pseudo dice [0.9761] 
2025-02-21 15:55:34.968244: Epoch time: 31.57 s 
2025-02-21 15:55:36.314203:  
2025-02-21 15:55:36.314392: Epoch 216 
2025-02-21 15:55:36.314468: Current learning rate: 0.00803 
2025-02-21 15:56:07.809232: train_loss -0.9081 
2025-02-21 15:56:07.809375: val_loss -0.9423 
2025-02-21 15:56:07.809411: Pseudo dice [0.9802] 
2025-02-21 15:56:07.809451: Epoch time: 31.5 s 
2025-02-21 15:56:08.491127:  
2025-02-21 15:56:08.491317: Epoch 217 
2025-02-21 15:56:08.491411: Current learning rate: 0.00802 
2025-02-21 15:56:40.049108: train_loss -0.9195 
2025-02-21 15:56:40.049240: val_loss -0.9291 
2025-02-21 15:56:40.049277: Pseudo dice [0.9746] 
2025-02-21 15:56:40.049317: Epoch time: 31.56 s 
2025-02-21 15:56:40.740507:  
2025-02-21 15:56:40.740697: Epoch 218 
2025-02-21 15:56:40.740770: Current learning rate: 0.00801 
2025-02-21 15:57:12.403143: train_loss -0.9151 
2025-02-21 15:57:12.403414: val_loss -0.932 
2025-02-21 15:57:12.403458: Pseudo dice [0.9733] 
2025-02-21 15:57:12.403538: Epoch time: 31.66 s 
2025-02-21 15:57:13.154711:  
2025-02-21 15:57:13.154956: Epoch 219 
2025-02-21 15:57:13.155047: Current learning rate: 0.00801 
2025-02-21 15:57:45.298411: train_loss -0.9295 
2025-02-21 15:57:45.298627: val_loss -0.9333 
2025-02-21 15:57:45.298676: Pseudo dice [0.9749] 
2025-02-21 15:57:45.298717: Epoch time: 32.14 s 
2025-02-21 15:57:45.996466:  
2025-02-21 15:57:45.996661: Epoch 220 
2025-02-21 15:57:45.996756: Current learning rate: 0.008 
2025-02-21 15:58:17.704236: train_loss -0.9148 
2025-02-21 15:58:17.704476: val_loss -0.9517 
2025-02-21 15:58:17.704515: Pseudo dice [0.9825] 
2025-02-21 15:58:17.704553: Epoch time: 31.71 s 
2025-02-21 15:58:18.394655:  
2025-02-21 15:58:18.394871: Epoch 221 
2025-02-21 15:58:18.394925: Current learning rate: 0.00799 
2025-02-21 15:58:50.191790: train_loss -0.9357 
2025-02-21 15:58:50.191999: val_loss -0.938 
2025-02-21 15:58:50.192055: Pseudo dice [0.9778] 
2025-02-21 15:58:50.192122: Epoch time: 31.8 s 
2025-02-21 15:58:50.893589:  
2025-02-21 15:58:50.893777: Epoch 222 
2025-02-21 15:58:50.893894: Current learning rate: 0.00798 
2025-02-21 15:59:22.707897: train_loss -0.9065 
2025-02-21 15:59:22.708089: val_loss -0.9471 
2025-02-21 15:59:22.708127: Pseudo dice [0.9787] 
2025-02-21 15:59:22.708169: Epoch time: 31.82 s 
2025-02-21 15:59:23.391891:  
2025-02-21 15:59:23.392072: Epoch 223 
2025-02-21 15:59:23.392145: Current learning rate: 0.00797 
2025-02-21 15:59:55.232369: train_loss -0.9368 
2025-02-21 15:59:55.232710: val_loss -0.9452 
2025-02-21 15:59:55.232752: Pseudo dice [0.9779] 
2025-02-21 15:59:55.232795: Epoch time: 31.84 s 
2025-02-21 15:59:55.955584:  
2025-02-21 15:59:55.955759: Epoch 224 
2025-02-21 15:59:55.955922: Current learning rate: 0.00796 
2025-02-21 16:00:27.880485: train_loss -0.9135 
2025-02-21 16:00:27.880607: val_loss -0.9482 
2025-02-21 16:00:27.880644: Pseudo dice [0.981] 
2025-02-21 16:00:27.880680: Epoch time: 31.93 s 
2025-02-21 16:00:28.564785:  
2025-02-21 16:00:28.564947: Epoch 225 
2025-02-21 16:00:28.565000: Current learning rate: 0.00795 
2025-02-21 16:01:00.441698: train_loss -0.9266 
2025-02-21 16:01:00.442222: val_loss -0.9318 
2025-02-21 16:01:00.442263: Pseudo dice [0.9758] 
2025-02-21 16:01:00.442306: Epoch time: 31.88 s 
2025-02-21 16:01:01.206781:  
2025-02-21 16:01:01.206924: Epoch 226 
2025-02-21 16:01:01.206999: Current learning rate: 0.00794 
2025-02-21 16:01:33.054268: train_loss -0.9178 
2025-02-21 16:01:33.054519: val_loss -0.9416 
2025-02-21 16:01:33.054648: Pseudo dice [0.9795] 
2025-02-21 16:01:33.054732: Epoch time: 31.85 s 
2025-02-21 16:01:33.895777:  
2025-02-21 16:01:33.895994: Epoch 227 
2025-02-21 16:01:33.896072: Current learning rate: 0.00793 
2025-02-21 16:02:05.437669: train_loss -0.9283 
2025-02-21 16:02:05.437804: val_loss -0.9451 
2025-02-21 16:02:05.437934: Pseudo dice [0.9779] 
2025-02-21 16:02:05.437981: Epoch time: 31.54 s 
2025-02-21 16:02:06.289390:  
2025-02-21 16:02:06.289556: Epoch 228 
2025-02-21 16:02:06.289625: Current learning rate: 0.00792 
2025-02-21 16:02:38.407050: train_loss -0.9024 
2025-02-21 16:02:38.407293: val_loss -0.9494 
2025-02-21 16:02:38.407345: Pseudo dice [0.9822] 
2025-02-21 16:02:38.407393: Epoch time: 32.12 s 
2025-02-21 16:02:39.075830:  
2025-02-21 16:02:39.075984: Epoch 229 
2025-02-21 16:02:39.076059: Current learning rate: 0.00791 
2025-02-21 16:03:11.725387: train_loss -0.9241 
2025-02-21 16:03:11.725555: val_loss -0.9267 
2025-02-21 16:03:11.725593: Pseudo dice [0.9739] 
2025-02-21 16:03:11.725632: Epoch time: 32.65 s 
2025-02-21 16:03:12.634135:  
2025-02-21 16:03:12.634358: Epoch 230 
2025-02-21 16:03:12.634469: Current learning rate: 0.0079 
2025-02-21 16:03:45.201783: train_loss -0.9276 
2025-02-21 16:03:45.202033: val_loss -0.9263 
2025-02-21 16:03:45.202076: Pseudo dice [0.9727] 
2025-02-21 16:03:45.202128: Epoch time: 32.57 s 
2025-02-21 16:03:45.939187:  
2025-02-21 16:03:45.939435: Epoch 231 
2025-02-21 16:03:45.939545: Current learning rate: 0.00789 
2025-02-21 16:04:17.389179: train_loss -0.9193 
2025-02-21 16:04:17.389322: val_loss -0.9252 
2025-02-21 16:04:17.389358: Pseudo dice [0.9713] 
2025-02-21 16:04:17.389397: Epoch time: 31.45 s 
2025-02-21 16:04:18.069917:  
2025-02-21 16:04:18.070071: Epoch 232 
2025-02-21 16:04:18.070116: Current learning rate: 0.00789 
2025-02-21 16:04:49.438524: train_loss -0.9239 
2025-02-21 16:04:49.438672: val_loss -0.948 
2025-02-21 16:04:49.438712: Pseudo dice [0.9812] 
2025-02-21 16:04:49.438751: Epoch time: 31.37 s 
2025-02-21 16:04:50.112853:  
2025-02-21 16:04:50.113014: Epoch 233 
2025-02-21 16:04:50.113093: Current learning rate: 0.00788 
2025-02-21 16:05:21.437969: train_loss -0.9331 
2025-02-21 16:05:21.438106: val_loss -0.9543 
2025-02-21 16:05:21.438143: Pseudo dice [0.9835] 
2025-02-21 16:05:21.438180: Epoch time: 31.33 s 
2025-02-21 16:05:22.780128:  
2025-02-21 16:05:22.780291: Epoch 234 
2025-02-21 16:05:22.780371: Current learning rate: 0.00787 
2025-02-21 16:05:54.840344: train_loss -0.9205 
2025-02-21 16:05:54.840484: val_loss -0.9528 
2025-02-21 16:05:54.840520: Pseudo dice [0.9828] 
2025-02-21 16:05:54.840582: Epoch time: 32.06 s 
2025-02-21 16:05:54.840614: Yayy! New best EMA pseudo Dice: 0.9783 
2025-02-21 16:05:55.834079:  
2025-02-21 16:05:55.834227: Epoch 235 
2025-02-21 16:05:55.834271: Current learning rate: 0.00786 
2025-02-21 16:06:27.255458: train_loss -0.9357 
2025-02-21 16:06:27.255617: val_loss -0.9441 
2025-02-21 16:06:27.255654: Pseudo dice [0.9796] 
2025-02-21 16:06:27.255695: Epoch time: 31.42 s 
2025-02-21 16:06:27.255724: Yayy! New best EMA pseudo Dice: 0.9784 
2025-02-21 16:06:28.265435:  
2025-02-21 16:06:28.265602: Epoch 236 
2025-02-21 16:06:28.265693: Current learning rate: 0.00785 
2025-02-21 16:06:59.831778: train_loss -0.9146 
2025-02-21 16:06:59.831943: val_loss -0.9448 
2025-02-21 16:06:59.831983: Pseudo dice [0.9792] 
2025-02-21 16:06:59.832021: Epoch time: 31.57 s 
2025-02-21 16:06:59.832050: Yayy! New best EMA pseudo Dice: 0.9785 
2025-02-21 16:07:01.179116:  
2025-02-21 16:07:01.179276: Epoch 237 
2025-02-21 16:07:01.179366: Current learning rate: 0.00784 
2025-02-21 16:07:32.587934: train_loss -0.9032 
2025-02-21 16:07:32.588101: val_loss -0.9405 
2025-02-21 16:07:32.588139: Pseudo dice [0.977] 
2025-02-21 16:07:32.588179: Epoch time: 31.41 s 
2025-02-21 16:07:33.270649:  
2025-02-21 16:07:33.270866: Epoch 238 
2025-02-21 16:07:33.270942: Current learning rate: 0.00783 
2025-02-21 16:08:05.134067: train_loss -0.9203 
2025-02-21 16:08:05.134238: val_loss -0.9475 
2025-02-21 16:08:05.134274: Pseudo dice [0.9808] 
2025-02-21 16:08:05.134346: Epoch time: 31.86 s 
2025-02-21 16:08:05.134377: Yayy! New best EMA pseudo Dice: 0.9786 
2025-02-21 16:08:06.179598:  
2025-02-21 16:08:06.179760: Epoch 239 
2025-02-21 16:08:06.179823: Current learning rate: 0.00782 
2025-02-21 16:08:37.565952: train_loss -0.9282 
2025-02-21 16:08:37.566102: val_loss -0.9473 
2025-02-21 16:08:37.566197: Pseudo dice [0.9805] 
2025-02-21 16:08:37.566239: Epoch time: 31.39 s 
2025-02-21 16:08:37.566267: Yayy! New best EMA pseudo Dice: 0.9788 
2025-02-21 16:08:38.588569:  
2025-02-21 16:08:38.588768: Epoch 240 
2025-02-21 16:08:38.588837: Current learning rate: 0.00781 
2025-02-21 16:09:10.115892: train_loss -0.9273 
2025-02-21 16:09:10.116026: val_loss -0.9449 
2025-02-21 16:09:10.116066: Pseudo dice [0.9798] 
2025-02-21 16:09:10.116102: Epoch time: 31.53 s 
2025-02-21 16:09:10.116128: Yayy! New best EMA pseudo Dice: 0.9789 
2025-02-21 16:09:11.153444:  
2025-02-21 16:09:11.153652: Epoch 241 
2025-02-21 16:09:11.153721: Current learning rate: 0.0078 
2025-02-21 16:09:42.716377: train_loss -0.917 
2025-02-21 16:09:42.716576: val_loss -0.9473 
2025-02-21 16:09:42.716613: Pseudo dice [0.9807] 
2025-02-21 16:09:42.716652: Epoch time: 31.56 s 
2025-02-21 16:09:42.716681: Yayy! New best EMA pseudo Dice: 0.9791 
2025-02-21 16:09:43.774786:  
2025-02-21 16:09:43.774969: Epoch 242 
2025-02-21 16:09:43.775040: Current learning rate: 0.00779 
2025-02-21 16:10:15.478939: train_loss -0.9323 
2025-02-21 16:10:15.479080: val_loss -0.9493 
2025-02-21 16:10:15.479119: Pseudo dice [0.9808] 
2025-02-21 16:10:15.479158: Epoch time: 31.7 s 
2025-02-21 16:10:15.479187: Yayy! New best EMA pseudo Dice: 0.9792 
2025-02-21 16:10:16.498430:  
2025-02-21 16:10:16.498635: Epoch 243 
2025-02-21 16:10:16.498689: Current learning rate: 0.00778 
2025-02-21 16:10:47.945760: train_loss -0.9295 
2025-02-21 16:10:47.945917: val_loss -0.9511 
2025-02-21 16:10:47.945957: Pseudo dice [0.9801] 
2025-02-21 16:10:47.945994: Epoch time: 31.45 s 
2025-02-21 16:10:47.946023: Yayy! New best EMA pseudo Dice: 0.9793 
2025-02-21 16:10:48.982280:  
2025-02-21 16:10:48.982467: Epoch 244 
2025-02-21 16:10:48.982556: Current learning rate: 0.00777 
2025-02-21 16:11:20.743615: train_loss -0.923 
2025-02-21 16:11:20.743752: val_loss -0.948 
2025-02-21 16:11:20.743846: Pseudo dice [0.9801] 
2025-02-21 16:11:20.743888: Epoch time: 31.76 s 
2025-02-21 16:11:20.743918: Yayy! New best EMA pseudo Dice: 0.9794 
2025-02-21 16:11:21.766780:  
2025-02-21 16:11:21.766946: Epoch 245 
2025-02-21 16:11:21.767090: Current learning rate: 0.00777 
2025-02-21 16:11:53.316435: train_loss -0.939 
2025-02-21 16:11:53.316596: val_loss -0.9385 
2025-02-21 16:11:53.316632: Pseudo dice [0.9778] 
2025-02-21 16:11:53.316671: Epoch time: 31.55 s 
2025-02-21 16:11:54.003784:  
2025-02-21 16:11:54.003930: Epoch 246 
2025-02-21 16:11:54.004000: Current learning rate: 0.00776 
2025-02-21 16:12:26.161422: train_loss -0.9208 
2025-02-21 16:12:26.161578: val_loss -0.9334 
2025-02-21 16:12:26.161620: Pseudo dice [0.976] 
2025-02-21 16:12:26.161667: Epoch time: 32.16 s 
2025-02-21 16:12:26.891709:  
2025-02-21 16:12:26.891896: Epoch 247 
2025-02-21 16:12:26.891993: Current learning rate: 0.00775 
2025-02-21 16:12:58.451349: train_loss -0.9245 
2025-02-21 16:12:58.451599: val_loss -0.9374 
2025-02-21 16:12:58.451645: Pseudo dice [0.9794] 
2025-02-21 16:12:58.451691: Epoch time: 31.56 s 
2025-02-21 16:12:59.236790:  
2025-02-21 16:12:59.236985: Epoch 248 
2025-02-21 16:12:59.237121: Current learning rate: 0.00774 
2025-02-21 16:13:31.146544: train_loss -0.9094 
2025-02-21 16:13:31.146887: val_loss -0.926 
2025-02-21 16:13:31.146991: Pseudo dice [0.9736] 
2025-02-21 16:13:31.147053: Epoch time: 31.91 s 
2025-02-21 16:13:31.991278:  
2025-02-21 16:13:31.991431: Epoch 249 
2025-02-21 16:13:31.991486: Current learning rate: 0.00773 
2025-02-21 16:14:03.684264: train_loss -0.9175 
2025-02-21 16:14:03.684421: val_loss -0.9395 
2025-02-21 16:14:03.684459: Pseudo dice [0.9766] 
2025-02-21 16:14:03.684497: Epoch time: 31.69 s 
2025-02-21 16:14:04.911916:  
2025-02-21 16:14:04.912088: Epoch 250 
2025-02-21 16:14:04.912176: Current learning rate: 0.00772 
2025-02-21 16:14:36.670084: train_loss -0.9168 
2025-02-21 16:14:36.670284: val_loss -0.9426 
2025-02-21 16:14:36.670336: Pseudo dice [0.9788] 
2025-02-21 16:14:36.670391: Epoch time: 31.76 s 
2025-02-21 16:14:38.155675:  
2025-02-21 16:14:38.155894: Epoch 251 
2025-02-21 16:14:38.155965: Current learning rate: 0.00771 
2025-02-21 16:15:09.943519: train_loss -0.9299 
2025-02-21 16:15:09.943658: val_loss -0.9441 
2025-02-21 16:15:09.943705: Pseudo dice [0.9785] 
2025-02-21 16:15:09.943744: Epoch time: 31.79 s 
2025-02-21 16:15:10.634405:  
2025-02-21 16:15:10.634623: Epoch 252 
2025-02-21 16:15:10.634687: Current learning rate: 0.0077 
2025-02-21 16:15:42.819009: train_loss -0.9167 
2025-02-21 16:15:42.819276: val_loss -0.9445 
2025-02-21 16:15:42.819323: Pseudo dice [0.9781] 
2025-02-21 16:15:42.819361: Epoch time: 32.19 s 
2025-02-21 16:15:43.522194:  
2025-02-21 16:15:43.522388: Epoch 253 
2025-02-21 16:15:43.522463: Current learning rate: 0.00769 
2025-02-21 16:16:15.606953: train_loss -0.9209 
2025-02-21 16:16:15.607180: val_loss -0.9318 
2025-02-21 16:16:15.607220: Pseudo dice [0.9764] 
2025-02-21 16:16:15.607260: Epoch time: 32.09 s 
2025-02-21 16:16:16.302712:  
2025-02-21 16:16:16.302934: Epoch 254 
2025-02-21 16:16:16.303008: Current learning rate: 0.00768 
2025-02-21 16:16:47.988574: train_loss -0.9215 
2025-02-21 16:16:47.988713: val_loss -0.9515 
2025-02-21 16:16:47.988748: Pseudo dice [0.9834] 
2025-02-21 16:16:47.988786: Epoch time: 31.69 s 
2025-02-21 16:16:48.673205:  
2025-02-21 16:16:48.673381: Epoch 255 
2025-02-21 16:16:48.673459: Current learning rate: 0.00767 
2025-02-21 16:17:20.470285: train_loss -0.9249 
2025-02-21 16:17:20.470421: val_loss -0.9295 
2025-02-21 16:17:20.470496: Pseudo dice [0.973] 
2025-02-21 16:17:20.470536: Epoch time: 31.8 s 
2025-02-21 16:17:21.166341:  
2025-02-21 16:17:21.166571: Epoch 256 
2025-02-21 16:17:21.166646: Current learning rate: 0.00766 
2025-02-21 16:17:52.815003: train_loss -0.9256 
2025-02-21 16:17:52.815249: val_loss -0.9461 
2025-02-21 16:17:52.815289: Pseudo dice [0.9786] 
2025-02-21 16:17:52.815328: Epoch time: 31.65 s 
2025-02-21 16:17:53.729534:  
2025-02-21 16:17:53.729728: Epoch 257 
2025-02-21 16:17:53.729798: Current learning rate: 0.00765 
2025-02-21 16:18:25.485440: train_loss -0.93 
2025-02-21 16:18:25.485595: val_loss -0.9296 
2025-02-21 16:18:25.485636: Pseudo dice [0.9709] 
2025-02-21 16:18:25.485676: Epoch time: 31.76 s 
2025-02-21 16:18:26.331454:  
2025-02-21 16:18:26.331632: Epoch 258 
2025-02-21 16:18:26.331709: Current learning rate: 0.00764 
2025-02-21 16:18:58.191091: train_loss -0.9332 
2025-02-21 16:18:58.191245: val_loss -0.9412 
2025-02-21 16:18:58.191283: Pseudo dice [0.9791] 
2025-02-21 16:18:58.191323: Epoch time: 31.86 s 
2025-02-21 16:18:58.883569:  
2025-02-21 16:18:58.883783: Epoch 259 
2025-02-21 16:18:58.883862: Current learning rate: 0.00764 
2025-02-21 16:19:30.794347: train_loss -0.9371 
2025-02-21 16:19:30.794631: val_loss -0.9409 
2025-02-21 16:19:30.794672: Pseudo dice [0.9764] 
2025-02-21 16:19:30.794712: Epoch time: 31.91 s 
2025-02-21 16:19:31.536622:  
2025-02-21 16:19:31.536824: Epoch 260 
2025-02-21 16:19:31.536906: Current learning rate: 0.00763 
2025-02-21 16:20:03.624029: train_loss -0.9367 
2025-02-21 16:20:03.624195: val_loss -0.9585 
2025-02-21 16:20:03.624233: Pseudo dice [0.9845] 
2025-02-21 16:20:03.624274: Epoch time: 32.09 s 
2025-02-21 16:20:04.328799:  
2025-02-21 16:20:04.328963: Epoch 261 
2025-02-21 16:20:04.329020: Current learning rate: 0.00762 
2025-02-21 16:20:36.349823: train_loss -0.9259 
2025-02-21 16:20:36.350104: val_loss -0.9417 
2025-02-21 16:20:36.350144: Pseudo dice [0.9787] 
2025-02-21 16:20:36.350184: Epoch time: 32.02 s 
2025-02-21 16:20:37.050549:  
2025-02-21 16:20:37.050689: Epoch 262 
2025-02-21 16:20:37.050795: Current learning rate: 0.00761 
2025-02-21 16:21:09.550096: train_loss -0.9322 
2025-02-21 16:21:09.550529: val_loss -0.9384 
2025-02-21 16:21:09.550731: Pseudo dice [0.9773] 
2025-02-21 16:21:09.551049: Epoch time: 32.5 s 
2025-02-21 16:21:10.314421:  
2025-02-21 16:21:10.314574: Epoch 263 
2025-02-21 16:21:10.314650: Current learning rate: 0.0076 
2025-02-21 16:21:42.137980: train_loss -0.9224 
2025-02-21 16:21:42.138119: val_loss -0.908 
2025-02-21 16:21:42.138162: Pseudo dice [0.9627] 
2025-02-21 16:21:42.138215: Epoch time: 31.82 s 
2025-02-21 16:21:42.838576:  
2025-02-21 16:21:42.838740: Epoch 264 
2025-02-21 16:21:42.838838: Current learning rate: 0.00759 
2025-02-21 16:22:15.035762: train_loss -0.9088 
2025-02-21 16:22:15.036024: val_loss -0.9468 
2025-02-21 16:22:15.036085: Pseudo dice [0.9791] 
2025-02-21 16:22:15.036128: Epoch time: 32.2 s 
2025-02-21 16:22:15.730343:  
2025-02-21 16:22:15.730517: Epoch 265 
2025-02-21 16:22:15.730595: Current learning rate: 0.00758 
2025-02-21 16:22:47.999226: train_loss -0.9156 
2025-02-21 16:22:47.999614: val_loss -0.9513 
2025-02-21 16:22:47.999710: Pseudo dice [0.9831] 
2025-02-21 16:22:47.999776: Epoch time: 32.27 s 
2025-02-21 16:22:48.778768:  
2025-02-21 16:22:48.778891: Epoch 266 
2025-02-21 16:22:48.778965: Current learning rate: 0.00757 
2025-02-21 16:23:20.553545: train_loss -0.9104 
2025-02-21 16:23:20.553696: val_loss -0.9358 
2025-02-21 16:23:20.553734: Pseudo dice [0.9783] 
2025-02-21 16:23:20.553772: Epoch time: 31.78 s 
2025-02-21 16:23:21.237078:  
2025-02-21 16:23:21.237251: Epoch 267 
2025-02-21 16:23:21.237315: Current learning rate: 0.00756 
2025-02-21 16:23:52.756175: train_loss -0.9273 
2025-02-21 16:23:52.756302: val_loss -0.9391 
2025-02-21 16:23:52.756340: Pseudo dice [0.9767] 
2025-02-21 16:23:52.756379: Epoch time: 31.52 s 
2025-02-21 16:23:53.447628:  
2025-02-21 16:23:53.447824: Epoch 268 
2025-02-21 16:23:53.447873: Current learning rate: 0.00755 
2025-02-21 16:24:24.832949: train_loss -0.9343 
2025-02-21 16:24:24.833097: val_loss -0.9519 
2025-02-21 16:24:24.833163: Pseudo dice [0.9825] 
2025-02-21 16:24:24.833207: Epoch time: 31.39 s 
2025-02-21 16:24:26.227473:  
2025-02-21 16:24:26.227728: Epoch 269 
2025-02-21 16:24:26.227831: Current learning rate: 0.00754 
2025-02-21 16:24:57.732914: train_loss -0.9181 
2025-02-21 16:24:57.733052: val_loss -0.953 
2025-02-21 16:24:57.733090: Pseudo dice [0.982] 
2025-02-21 16:24:57.733126: Epoch time: 31.51 s 
2025-02-21 16:24:58.422819:  
2025-02-21 16:24:58.423066: Epoch 270 
2025-02-21 16:24:58.423119: Current learning rate: 0.00753 
2025-02-21 16:25:29.911269: train_loss -0.935 
2025-02-21 16:25:29.911392: val_loss -0.9385 
2025-02-21 16:25:29.911431: Pseudo dice [0.9763] 
2025-02-21 16:25:29.911471: Epoch time: 31.49 s 
2025-02-21 16:25:30.660119:  
2025-02-21 16:25:30.660398: Epoch 271 
2025-02-21 16:25:30.660486: Current learning rate: 0.00752 
2025-02-21 16:26:02.068790: train_loss -0.9375 
2025-02-21 16:26:02.068939: val_loss -0.9508 
2025-02-21 16:26:02.069014: Pseudo dice [0.9825] 
2025-02-21 16:26:02.069053: Epoch time: 31.41 s 
2025-02-21 16:26:02.802825:  
2025-02-21 16:26:02.803049: Epoch 272 
2025-02-21 16:26:02.803145: Current learning rate: 0.00751 
2025-02-21 16:26:34.327494: train_loss -0.9315 
2025-02-21 16:26:34.327633: val_loss -0.9502 
2025-02-21 16:26:34.327671: Pseudo dice [0.9808] 
2025-02-21 16:26:34.327709: Epoch time: 31.53 s 
2025-02-21 16:26:35.011828:  
2025-02-21 16:26:35.012021: Epoch 273 
2025-02-21 16:26:35.012068: Current learning rate: 0.00751 
2025-02-21 16:27:06.428799: train_loss -0.9026 
2025-02-21 16:27:06.428946: val_loss -0.9408 
2025-02-21 16:27:06.428982: Pseudo dice [0.9817] 
2025-02-21 16:27:06.429024: Epoch time: 31.42 s 
2025-02-21 16:27:07.121744:  
2025-02-21 16:27:07.121959: Epoch 274 
2025-02-21 16:27:07.122042: Current learning rate: 0.0075 
2025-02-21 16:27:38.567363: train_loss -0.9196 
2025-02-21 16:27:38.567544: val_loss -0.9488 
2025-02-21 16:27:38.567580: Pseudo dice [0.9812] 
2025-02-21 16:27:38.567622: Epoch time: 31.45 s 
2025-02-21 16:27:39.301960:  
2025-02-21 16:27:39.302220: Epoch 275 
2025-02-21 16:27:39.302347: Current learning rate: 0.00749 
2025-02-21 16:28:10.825600: train_loss -0.9371 
2025-02-21 16:28:10.825727: val_loss -0.948 
2025-02-21 16:28:10.825762: Pseudo dice [0.9803] 
2025-02-21 16:28:10.825799: Epoch time: 31.52 s 
2025-02-21 16:28:10.825839: Yayy! New best EMA pseudo Dice: 0.9794 
2025-02-21 16:28:11.835591:  
2025-02-21 16:28:11.835731: Epoch 276 
2025-02-21 16:28:11.835837: Current learning rate: 0.00748 
2025-02-21 16:28:43.150590: train_loss -0.9209 
2025-02-21 16:28:43.150724: val_loss -0.9303 
2025-02-21 16:28:43.150761: Pseudo dice [0.9735] 
2025-02-21 16:28:43.150797: Epoch time: 31.32 s 
2025-02-21 16:28:43.842611:  
2025-02-21 16:28:43.842811: Epoch 277 
2025-02-21 16:28:43.842885: Current learning rate: 0.00747 
2025-02-21 16:29:15.575185: train_loss -0.9069 
2025-02-21 16:29:15.575349: val_loss -0.9278 
2025-02-21 16:29:15.575400: Pseudo dice [0.9728] 
2025-02-21 16:29:15.575440: Epoch time: 31.73 s 
2025-02-21 16:29:16.284981:  
2025-02-21 16:29:16.285113: Epoch 278 
2025-02-21 16:29:16.285196: Current learning rate: 0.00746 
2025-02-21 16:29:47.677389: train_loss -0.9172 
2025-02-21 16:29:47.677522: val_loss -0.949 
2025-02-21 16:29:47.677558: Pseudo dice [0.9816] 
2025-02-21 16:29:47.677592: Epoch time: 31.39 s 
2025-02-21 16:29:48.367885:  
2025-02-21 16:29:48.368044: Epoch 279 
2025-02-21 16:29:48.368130: Current learning rate: 0.00745 
2025-02-21 16:30:19.944240: train_loss -0.9204 
2025-02-21 16:30:19.944435: val_loss -0.9547 
2025-02-21 16:30:19.944475: Pseudo dice [0.9832] 
2025-02-21 16:30:19.944515: Epoch time: 31.58 s 
2025-02-21 16:30:20.641466:  
2025-02-21 16:30:20.641693: Epoch 280 
2025-02-21 16:30:20.641754: Current learning rate: 0.00744 
2025-02-21 16:30:51.995453: train_loss -0.9162 
2025-02-21 16:30:51.995689: val_loss -0.9351 
2025-02-21 16:30:51.995728: Pseudo dice [0.9783] 
2025-02-21 16:30:51.995776: Epoch time: 31.35 s 
2025-02-21 16:30:52.717305:  
2025-02-21 16:30:52.717460: Epoch 281 
2025-02-21 16:30:52.717505: Current learning rate: 0.00743 
2025-02-21 16:31:24.072916: train_loss -0.9303 
2025-02-21 16:31:24.073053: val_loss -0.9483 
2025-02-21 16:31:24.073089: Pseudo dice [0.9792] 
2025-02-21 16:31:24.073124: Epoch time: 31.36 s 
2025-02-21 16:31:24.759309:  
2025-02-21 16:31:24.759483: Epoch 282 
2025-02-21 16:31:24.759543: Current learning rate: 0.00742 
2025-02-21 16:31:56.501293: train_loss -0.9375 
2025-02-21 16:31:56.501436: val_loss -0.9555 
2025-02-21 16:31:56.501474: Pseudo dice [0.9819] 
2025-02-21 16:31:56.501516: Epoch time: 31.74 s 
2025-02-21 16:31:57.204226:  
2025-02-21 16:31:57.204406: Epoch 283 
2025-02-21 16:31:57.204477: Current learning rate: 0.00741 
2025-02-21 16:32:28.747236: train_loss -0.9307 
2025-02-21 16:32:28.747588: val_loss -0.9465 
2025-02-21 16:32:28.747641: Pseudo dice [0.9808] 
2025-02-21 16:32:28.747687: Epoch time: 31.54 s 
2025-02-21 16:32:28.747718: Yayy! New best EMA pseudo Dice: 0.9794 
2025-02-21 16:32:29.787739:  
2025-02-21 16:32:29.787935: Epoch 284 
2025-02-21 16:32:29.788037: Current learning rate: 0.0074 
2025-02-21 16:33:01.304879: train_loss -0.9422 
2025-02-21 16:33:01.305028: val_loss -0.9438 
2025-02-21 16:33:01.305064: Pseudo dice [0.9792] 
2025-02-21 16:33:01.305103: Epoch time: 31.52 s 
2025-02-21 16:33:02.000141:  
2025-02-21 16:33:02.000303: Epoch 285 
2025-02-21 16:33:02.000394: Current learning rate: 0.00739 
2025-02-21 16:33:33.578404: train_loss -0.9177 
2025-02-21 16:33:33.578526: val_loss -0.9281 
2025-02-21 16:33:33.578561: Pseudo dice [0.9742] 
2025-02-21 16:33:33.578596: Epoch time: 31.58 s 
2025-02-21 16:33:34.267826:  
2025-02-21 16:33:34.267974: Epoch 286 
2025-02-21 16:33:34.268026: Current learning rate: 0.00738 
2025-02-21 16:34:05.806516: train_loss -0.9332 
2025-02-21 16:34:05.806661: val_loss -0.9485 
2025-02-21 16:34:05.806699: Pseudo dice [0.9807] 
2025-02-21 16:34:05.806740: Epoch time: 31.54 s 
2025-02-21 16:34:07.147547:  
2025-02-21 16:34:07.147733: Epoch 287 
2025-02-21 16:34:07.147792: Current learning rate: 0.00738 
2025-02-21 16:34:38.890110: train_loss -0.929 
2025-02-21 16:34:38.890257: val_loss -0.9502 
2025-02-21 16:34:38.890292: Pseudo dice [0.9803] 
2025-02-21 16:34:38.890329: Epoch time: 31.74 s 
2025-02-21 16:34:39.592941:  
2025-02-21 16:34:39.593131: Epoch 288 
2025-02-21 16:34:39.593176: Current learning rate: 0.00737 
2025-02-21 16:35:11.740967: train_loss -0.9429 
2025-02-21 16:35:11.741218: val_loss -0.9592 
2025-02-21 16:35:11.741259: Pseudo dice [0.9838] 
2025-02-21 16:35:11.741325: Epoch time: 32.15 s 
2025-02-21 16:35:11.741371: Yayy! New best EMA pseudo Dice: 0.9796 
2025-02-21 16:35:12.772478:  
2025-02-21 16:35:12.772659: Epoch 289 
2025-02-21 16:35:12.772722: Current learning rate: 0.00736 
2025-02-21 16:35:44.574167: train_loss -0.9278 
2025-02-21 16:35:44.574314: val_loss -0.946 
2025-02-21 16:35:44.574354: Pseudo dice [0.9786] 
2025-02-21 16:35:44.574392: Epoch time: 31.8 s 
2025-02-21 16:35:45.280791:  
2025-02-21 16:35:45.281003: Epoch 290 
2025-02-21 16:35:45.281070: Current learning rate: 0.00735 
2025-02-21 16:36:16.965958: train_loss -0.9241 
2025-02-21 16:36:16.966089: val_loss -0.9481 
2025-02-21 16:36:16.966126: Pseudo dice [0.9801] 
2025-02-21 16:36:16.966164: Epoch time: 31.69 s 
2025-02-21 16:36:17.658612:  
2025-02-21 16:36:17.658768: Epoch 291 
2025-02-21 16:36:17.658837: Current learning rate: 0.00734 
2025-02-21 16:36:49.337576: train_loss -0.934 
2025-02-21 16:36:49.337705: val_loss -0.9398 
2025-02-21 16:36:49.337748: Pseudo dice [0.9787] 
2025-02-21 16:36:49.337793: Epoch time: 31.68 s 
2025-02-21 16:36:50.035029:  
2025-02-21 16:36:50.035209: Epoch 292 
2025-02-21 16:36:50.035274: Current learning rate: 0.00733 
2025-02-21 16:37:21.868655: train_loss -0.9306 
2025-02-21 16:37:21.868786: val_loss -0.9457 
2025-02-21 16:37:21.868829: Pseudo dice [0.9806] 
2025-02-21 16:37:21.868867: Epoch time: 31.83 s 
2025-02-21 16:37:22.664563:  
2025-02-21 16:37:22.664785: Epoch 293 
2025-02-21 16:37:22.664891: Current learning rate: 0.00732 
2025-02-21 16:37:54.738981: train_loss -0.9088 
2025-02-21 16:37:54.739126: val_loss -0.9301 
2025-02-21 16:37:54.739162: Pseudo dice [0.9758] 
2025-02-21 16:37:54.739201: Epoch time: 32.08 s 
2025-02-21 16:37:55.441119:  
2025-02-21 16:37:55.441320: Epoch 294 
2025-02-21 16:37:55.441365: Current learning rate: 0.00731 
2025-02-21 16:38:27.108471: train_loss -0.9275 
2025-02-21 16:38:27.108637: val_loss -0.92 
2025-02-21 16:38:27.108681: Pseudo dice [0.9721] 
2025-02-21 16:38:27.108723: Epoch time: 31.67 s 
2025-02-21 16:38:27.824828:  
2025-02-21 16:38:27.825038: Epoch 295 
2025-02-21 16:38:27.825101: Current learning rate: 0.0073 
2025-02-21 16:38:59.667321: train_loss -0.9264 
2025-02-21 16:38:59.667472: val_loss -0.9458 
2025-02-21 16:38:59.667515: Pseudo dice [0.9789] 
2025-02-21 16:38:59.667553: Epoch time: 31.84 s 
2025-02-21 16:39:00.379445:  
2025-02-21 16:39:00.379664: Epoch 296 
2025-02-21 16:39:00.379766: Current learning rate: 0.00729 
2025-02-21 16:39:32.138207: train_loss -0.9145 
2025-02-21 16:39:32.138345: val_loss -0.948 
2025-02-21 16:39:32.138381: Pseudo dice [0.9796] 
2025-02-21 16:39:32.138421: Epoch time: 31.76 s 
2025-02-21 16:39:32.838022:  
2025-02-21 16:39:32.838192: Epoch 297 
2025-02-21 16:39:32.838244: Current learning rate: 0.00728 
2025-02-21 16:40:04.665817: train_loss -0.934 
2025-02-21 16:40:04.665945: val_loss -0.9446 
2025-02-21 16:40:04.665981: Pseudo dice [0.9784] 
2025-02-21 16:40:04.666019: Epoch time: 31.83 s 
2025-02-21 16:40:05.358555:  
2025-02-21 16:40:05.358689: Epoch 298 
2025-02-21 16:40:05.358754: Current learning rate: 0.00727 
2025-02-21 16:40:36.831800: train_loss -0.918 
2025-02-21 16:40:36.832046: val_loss -0.9267 
2025-02-21 16:40:36.832085: Pseudo dice [0.9695] 
2025-02-21 16:40:36.832134: Epoch time: 31.47 s 
2025-02-21 16:40:37.660621:  
2025-02-21 16:40:37.660765: Epoch 299 
2025-02-21 16:40:37.660837: Current learning rate: 0.00726 
2025-02-21 16:41:10.273310: train_loss -0.9311 
2025-02-21 16:41:10.273444: val_loss -0.956 
2025-02-21 16:41:10.273480: Pseudo dice [0.9834] 
2025-02-21 16:41:10.273572: Epoch time: 32.61 s 
2025-02-21 16:41:11.478408:  
2025-02-21 16:41:11.478569: Epoch 300 
2025-02-21 16:41:11.478643: Current learning rate: 0.00725 
2025-02-21 16:41:43.612130: train_loss -0.921 
2025-02-21 16:41:43.612361: val_loss -0.9435 
2025-02-21 16:41:43.612410: Pseudo dice [0.9788] 
2025-02-21 16:41:43.612450: Epoch time: 32.13 s 
2025-02-21 16:41:44.310194:  
2025-02-21 16:41:44.310338: Epoch 301 
2025-02-21 16:41:44.310384: Current learning rate: 0.00724 
2025-02-21 16:42:16.149514: train_loss -0.9265 
2025-02-21 16:42:16.149938: val_loss -0.9574 
2025-02-21 16:42:16.149979: Pseudo dice [0.984] 
2025-02-21 16:42:16.150020: Epoch time: 31.84 s 
2025-02-21 16:42:16.861791:  
2025-02-21 16:42:16.861928: Epoch 302 
2025-02-21 16:42:16.862002: Current learning rate: 0.00724 
2025-02-21 16:42:48.732764: train_loss -0.9348 
2025-02-21 16:42:48.732917: val_loss -0.9538 
2025-02-21 16:42:48.732953: Pseudo dice [0.981] 
2025-02-21 16:42:48.732991: Epoch time: 31.87 s 
2025-02-21 16:42:49.441181:  
2025-02-21 16:42:49.441336: Epoch 303 
2025-02-21 16:42:49.441380: Current learning rate: 0.00723 
2025-02-21 16:43:21.446318: train_loss -0.9312 
2025-02-21 16:43:21.446726: val_loss -0.9432 
2025-02-21 16:43:21.446790: Pseudo dice [0.9782] 
2025-02-21 16:43:21.446865: Epoch time: 32.01 s 
2025-02-21 16:43:22.998188:  
2025-02-21 16:43:22.998373: Epoch 304 
2025-02-21 16:43:22.998469: Current learning rate: 0.00722 
2025-02-21 16:43:54.896334: train_loss -0.9344 
2025-02-21 16:43:54.896637: val_loss -0.9419 
2025-02-21 16:43:54.896735: Pseudo dice [0.9773] 
2025-02-21 16:43:54.896829: Epoch time: 31.9 s 
2025-02-21 16:43:55.730848:  
2025-02-21 16:43:55.731060: Epoch 305 
2025-02-21 16:43:55.731136: Current learning rate: 0.00721 
2025-02-21 16:44:27.770925: train_loss -0.9307 
2025-02-21 16:44:27.771083: val_loss -0.9401 
2025-02-21 16:44:27.771126: Pseudo dice [0.978] 
2025-02-21 16:44:27.771168: Epoch time: 32.04 s 
2025-02-21 16:44:28.500053:  
2025-02-21 16:44:28.500280: Epoch 306 
2025-02-21 16:44:28.500394: Current learning rate: 0.0072 
2025-02-21 16:45:00.786519: train_loss -0.921 
2025-02-21 16:45:00.787064: val_loss -0.9393 
2025-02-21 16:45:00.787104: Pseudo dice [0.9779] 
2025-02-21 16:45:00.787144: Epoch time: 32.29 s 
2025-02-21 16:45:01.649427:  
2025-02-21 16:45:01.649679: Epoch 307 
2025-02-21 16:45:01.649787: Current learning rate: 0.00719 
2025-02-21 16:45:33.433488: train_loss -0.9306 
2025-02-21 16:45:33.433611: val_loss -0.9432 
2025-02-21 16:45:33.433647: Pseudo dice [0.9762] 
2025-02-21 16:45:33.433684: Epoch time: 31.78 s 
2025-02-21 16:45:34.131173:  
2025-02-21 16:45:34.131316: Epoch 308 
2025-02-21 16:45:34.131361: Current learning rate: 0.00718 
2025-02-21 16:46:05.559841: train_loss -0.9279 
2025-02-21 16:46:05.560010: val_loss -0.9598 
2025-02-21 16:46:05.560049: Pseudo dice [0.9841] 
2025-02-21 16:46:05.560092: Epoch time: 31.43 s 
2025-02-21 16:46:06.273436:  
2025-02-21 16:46:06.273624: Epoch 309 
2025-02-21 16:46:06.273674: Current learning rate: 0.00717 
2025-02-21 16:46:37.572778: train_loss -0.9373 
2025-02-21 16:46:37.572914: val_loss -0.9389 
2025-02-21 16:46:37.572957: Pseudo dice [0.9776] 
2025-02-21 16:46:37.572994: Epoch time: 31.3 s 
2025-02-21 16:46:38.278352:  
2025-02-21 16:46:38.278533: Epoch 310 
2025-02-21 16:46:38.278595: Current learning rate: 0.00716 
2025-02-21 16:47:09.669834: train_loss -0.9296 
2025-02-21 16:47:09.669967: val_loss -0.9446 
2025-02-21 16:47:09.670005: Pseudo dice [0.9774] 
2025-02-21 16:47:09.670043: Epoch time: 31.39 s 
2025-02-21 16:47:10.368560:  
2025-02-21 16:47:10.368746: Epoch 311 
2025-02-21 16:47:10.368799: Current learning rate: 0.00715 
2025-02-21 16:47:41.830168: train_loss -0.9331 
2025-02-21 16:47:41.830294: val_loss -0.9462 
2025-02-21 16:47:41.830330: Pseudo dice [0.9816] 
2025-02-21 16:47:41.830369: Epoch time: 31.46 s 
2025-02-21 16:47:42.548323:  
2025-02-21 16:47:42.548519: Epoch 312 
2025-02-21 16:47:42.548566: Current learning rate: 0.00714 
2025-02-21 16:48:14.178529: train_loss -0.9236 
2025-02-21 16:48:14.178658: val_loss -0.9362 
2025-02-21 16:48:14.178696: Pseudo dice [0.9758] 
2025-02-21 16:48:14.178734: Epoch time: 31.63 s 
2025-02-21 16:48:14.876479:  
2025-02-21 16:48:14.876655: Epoch 313 
2025-02-21 16:48:14.876708: Current learning rate: 0.00713 
2025-02-21 16:48:46.202148: train_loss -0.9278 
2025-02-21 16:48:46.202362: val_loss -0.9421 
2025-02-21 16:48:46.202415: Pseudo dice [0.9796] 
2025-02-21 16:48:46.202463: Epoch time: 31.33 s 
2025-02-21 16:48:46.915029:  
2025-02-21 16:48:46.915228: Epoch 314 
2025-02-21 16:48:46.915349: Current learning rate: 0.00712 
2025-02-21 16:49:18.455497: train_loss -0.9366 
2025-02-21 16:49:18.455707: val_loss -0.9468 
2025-02-21 16:49:18.455748: Pseudo dice [0.979] 
2025-02-21 16:49:18.455789: Epoch time: 31.54 s 
2025-02-21 16:49:19.208595:  
2025-02-21 16:49:19.208869: Epoch 315 
2025-02-21 16:49:19.208932: Current learning rate: 0.00711 
2025-02-21 16:49:50.704884: train_loss -0.9218 
2025-02-21 16:49:50.705083: val_loss -0.9371 
2025-02-21 16:49:50.705119: Pseudo dice [0.9738] 
2025-02-21 16:49:50.705162: Epoch time: 31.5 s 
2025-02-21 16:49:51.430699:  
2025-02-21 16:49:51.430884: Epoch 316 
2025-02-21 16:49:51.430958: Current learning rate: 0.0071 
2025-02-21 16:50:22.802884: train_loss -0.9234 
2025-02-21 16:50:22.803028: val_loss -0.9421 
2025-02-21 16:50:22.803065: Pseudo dice [0.9769] 
2025-02-21 16:50:22.803105: Epoch time: 31.37 s 
2025-02-21 16:50:23.516638:  
2025-02-21 16:50:23.516879: Epoch 317 
2025-02-21 16:50:23.516970: Current learning rate: 0.0071 
2025-02-21 16:50:55.071127: train_loss -0.9392 
2025-02-21 16:50:55.071259: val_loss -0.9303 
2025-02-21 16:50:55.071295: Pseudo dice [0.973] 
2025-02-21 16:50:55.071332: Epoch time: 31.56 s 
2025-02-21 16:50:55.775411:  
2025-02-21 16:50:55.775609: Epoch 318 
2025-02-21 16:50:55.775706: Current learning rate: 0.00709 
2025-02-21 16:51:27.200624: train_loss -0.9393 
2025-02-21 16:51:27.200764: val_loss -0.9488 
2025-02-21 16:51:27.200812: Pseudo dice [0.9803] 
2025-02-21 16:51:27.200865: Epoch time: 31.43 s 
2025-02-21 16:51:27.906830:  
2025-02-21 16:51:27.907001: Epoch 319 
2025-02-21 16:51:27.907051: Current learning rate: 0.00708 
2025-02-21 16:51:59.247682: train_loss -0.9351 
2025-02-21 16:51:59.247824: val_loss -0.9484 
2025-02-21 16:51:59.247868: Pseudo dice [0.9797] 
2025-02-21 16:51:59.247905: Epoch time: 31.34 s 
2025-02-21 16:51:59.955165:  
2025-02-21 16:51:59.955344: Epoch 320 
2025-02-21 16:51:59.955390: Current learning rate: 0.00707 
2025-02-21 16:52:31.429964: train_loss -0.9382 
2025-02-21 16:52:31.430108: val_loss -0.9586 
2025-02-21 16:52:31.430148: Pseudo dice [0.985] 
2025-02-21 16:52:31.430186: Epoch time: 31.48 s 
2025-02-21 16:52:32.748100:  
2025-02-21 16:52:32.748268: Epoch 321 
2025-02-21 16:52:32.748339: Current learning rate: 0.00706 
2025-02-21 16:53:04.318477: train_loss -0.9303 
2025-02-21 16:53:04.318707: val_loss -0.9477 
2025-02-21 16:53:04.318788: Pseudo dice [0.9785] 
2025-02-21 16:53:04.318870: Epoch time: 31.57 s 
2025-02-21 16:53:05.111986:  
2025-02-21 16:53:05.112149: Epoch 322 
2025-02-21 16:53:05.112229: Current learning rate: 0.00705 
2025-02-21 16:53:36.986924: train_loss -0.9254 
2025-02-21 16:53:36.987077: val_loss -0.9595 
2025-02-21 16:53:36.987116: Pseudo dice [0.9839] 
2025-02-21 16:53:36.987154: Epoch time: 31.88 s 
2025-02-21 16:53:37.694975:  
2025-02-21 16:53:37.695224: Epoch 323 
2025-02-21 16:53:37.695289: Current learning rate: 0.00704 
2025-02-21 16:54:09.338120: train_loss -0.9263 
2025-02-21 16:54:09.338332: val_loss -0.9514 
2025-02-21 16:54:09.338372: Pseudo dice [0.9799] 
2025-02-21 16:54:09.338413: Epoch time: 31.64 s 
2025-02-21 16:54:10.184304:  
2025-02-21 16:54:10.184553: Epoch 324 
2025-02-21 16:54:10.184632: Current learning rate: 0.00703 
2025-02-21 16:54:41.755317: train_loss -0.9333 
2025-02-21 16:54:41.755528: val_loss -0.9581 
2025-02-21 16:54:41.755568: Pseudo dice [0.9837] 
2025-02-21 16:54:41.755611: Epoch time: 31.57 s 
2025-02-21 16:54:41.755641: Yayy! New best EMA pseudo Dice: 0.9798 
2025-02-21 16:54:42.850796:  
2025-02-21 16:54:42.851020: Epoch 325 
2025-02-21 16:54:42.851063: Current learning rate: 0.00702 
2025-02-21 16:55:14.482611: train_loss -0.9188 
2025-02-21 16:55:14.482776: val_loss -0.9472 
2025-02-21 16:55:14.482815: Pseudo dice [0.9783] 
2025-02-21 16:55:14.482861: Epoch time: 31.63 s 
2025-02-21 16:55:15.229281:  
2025-02-21 16:55:15.229526: Epoch 326 
2025-02-21 16:55:15.229610: Current learning rate: 0.00701 
2025-02-21 16:55:46.578028: train_loss -0.93 
2025-02-21 16:55:46.578180: val_loss -0.9415 
2025-02-21 16:55:46.578229: Pseudo dice [0.976] 
2025-02-21 16:55:46.578268: Epoch time: 31.35 s 
2025-02-21 16:55:47.294438:  
2025-02-21 16:55:47.294621: Epoch 327 
2025-02-21 16:55:47.294695: Current learning rate: 0.007 
2025-02-21 16:56:19.363488: train_loss -0.9278 
2025-02-21 16:56:19.363646: val_loss -0.9516 
2025-02-21 16:56:19.363686: Pseudo dice [0.982] 
2025-02-21 16:56:19.363729: Epoch time: 32.07 s 
2025-02-21 16:56:20.072873:  
2025-02-21 16:56:20.073083: Epoch 328 
2025-02-21 16:56:20.073167: Current learning rate: 0.00699 
2025-02-21 16:56:52.081273: train_loss -0.9268 
2025-02-21 16:56:52.081420: val_loss -0.9572 
2025-02-21 16:56:52.081460: Pseudo dice [0.9834] 
2025-02-21 16:56:52.081522: Epoch time: 32.01 s 
2025-02-21 16:56:52.081577: Yayy! New best EMA pseudo Dice: 0.9799 
2025-02-21 16:56:53.104182:  
2025-02-21 16:56:53.104379: Epoch 329 
2025-02-21 16:56:53.104429: Current learning rate: 0.00698 
2025-02-21 16:57:24.728740: train_loss -0.927 
2025-02-21 16:57:24.728885: val_loss -0.9427 
2025-02-21 16:57:24.728922: Pseudo dice [0.979] 
2025-02-21 16:57:24.728958: Epoch time: 31.63 s 
2025-02-21 16:57:25.441139:  
2025-02-21 16:57:25.441355: Epoch 330 
2025-02-21 16:57:25.441445: Current learning rate: 0.00697 
2025-02-21 16:57:57.278371: train_loss -0.9373 
2025-02-21 16:57:57.278676: val_loss -0.9534 
2025-02-21 16:57:57.278790: Pseudo dice [0.9824] 
2025-02-21 16:57:57.278910: Epoch time: 31.84 s 
2025-02-21 16:57:57.278994: Yayy! New best EMA pseudo Dice: 0.9801 
2025-02-21 16:57:58.536617:  
2025-02-21 16:57:58.536819: Epoch 331 
2025-02-21 16:57:58.536901: Current learning rate: 0.00696 
2025-02-21 16:58:30.128780: train_loss -0.9308 
2025-02-21 16:58:30.128920: val_loss -0.9452 
2025-02-21 16:58:30.128958: Pseudo dice [0.9784] 
2025-02-21 16:58:30.128995: Epoch time: 31.59 s 
2025-02-21 16:58:30.841800:  
2025-02-21 16:58:30.841975: Epoch 332 
2025-02-21 16:58:30.842053: Current learning rate: 0.00696 
2025-02-21 16:59:02.473931: train_loss -0.9211 
2025-02-21 16:59:02.474090: val_loss -0.9492 
2025-02-21 16:59:02.474129: Pseudo dice [0.9807] 
2025-02-21 16:59:02.474168: Epoch time: 31.63 s 
2025-02-21 16:59:03.178663:  
2025-02-21 16:59:03.178813: Epoch 333 
2025-02-21 16:59:03.178894: Current learning rate: 0.00695 
2025-02-21 16:59:34.986559: train_loss -0.9226 
2025-02-21 16:59:34.986693: val_loss -0.9311 
2025-02-21 16:59:34.986731: Pseudo dice [0.9739] 
2025-02-21 16:59:34.986767: Epoch time: 31.81 s 
2025-02-21 16:59:35.687030:  
2025-02-21 16:59:35.687156: Epoch 334 
2025-02-21 16:59:35.687235: Current learning rate: 0.00694 
2025-02-21 17:00:07.284081: train_loss -0.9302 
2025-02-21 17:00:07.284269: val_loss -0.9428 
2025-02-21 17:00:07.284329: Pseudo dice [0.9794] 
2025-02-21 17:00:07.284414: Epoch time: 31.6 s 
2025-02-21 17:00:08.220298:  
2025-02-21 17:00:08.220479: Epoch 335 
2025-02-21 17:00:08.220638: Current learning rate: 0.00693 
2025-02-21 17:00:40.507956: train_loss -0.9226 
2025-02-21 17:00:40.508090: val_loss -0.9379 
2025-02-21 17:00:40.508169: Pseudo dice [0.9795] 
2025-02-21 17:00:40.508214: Epoch time: 32.29 s 
2025-02-21 17:00:41.217301:  
2025-02-21 17:00:41.217435: Epoch 336 
2025-02-21 17:00:41.217484: Current learning rate: 0.00692 
2025-02-21 17:01:13.767888: train_loss -0.9296 
2025-02-21 17:01:13.768025: val_loss -0.9492 
2025-02-21 17:01:13.768062: Pseudo dice [0.9815] 
2025-02-21 17:01:13.768099: Epoch time: 32.55 s 
2025-02-21 17:01:14.615435:  
2025-02-21 17:01:14.615628: Epoch 337 
2025-02-21 17:01:14.615731: Current learning rate: 0.00691 
2025-02-21 17:01:46.501963: train_loss -0.9394 
2025-02-21 17:01:46.502445: val_loss -0.9371 
2025-02-21 17:01:46.502802: Pseudo dice [0.9781] 
2025-02-21 17:01:46.503144: Epoch time: 31.89 s 
2025-02-21 17:01:48.077378:  
2025-02-21 17:01:48.077493: Epoch 338 
2025-02-21 17:01:48.077592: Current learning rate: 0.0069 
2025-02-21 17:02:19.833375: train_loss -0.9318 
2025-02-21 17:02:19.833653: val_loss -0.9528 
2025-02-21 17:02:19.833728: Pseudo dice [0.982] 
2025-02-21 17:02:19.833799: Epoch time: 31.76 s 
2025-02-21 17:02:20.768924:  
2025-02-21 17:02:20.769109: Epoch 339 
2025-02-21 17:02:20.769194: Current learning rate: 0.00689 
2025-02-21 17:02:52.782600: train_loss -0.9226 
2025-02-21 17:02:52.782759: val_loss -0.9356 
2025-02-21 17:02:52.782799: Pseudo dice [0.9767] 
2025-02-21 17:02:52.782847: Epoch time: 32.01 s 
2025-02-21 17:02:53.514366:  
2025-02-21 17:02:53.514554: Epoch 340 
2025-02-21 17:02:53.514599: Current learning rate: 0.00688 
2025-02-21 17:03:25.446312: train_loss -0.9239 
2025-02-21 17:03:25.446454: val_loss -0.9405 
2025-02-21 17:03:25.446492: Pseudo dice [0.9787] 
2025-02-21 17:03:25.446530: Epoch time: 31.93 s 
2025-02-21 17:03:26.148880:  
2025-02-21 17:03:26.149025: Epoch 341 
2025-02-21 17:03:26.149070: Current learning rate: 0.00687 
2025-02-21 17:03:57.964308: train_loss -0.9336 
2025-02-21 17:03:57.964625: val_loss -0.9484 
2025-02-21 17:03:57.964715: Pseudo dice [0.9815] 
2025-02-21 17:03:57.964761: Epoch time: 31.82 s 
2025-02-21 17:03:58.825523:  
2025-02-21 17:03:58.825712: Epoch 342 
2025-02-21 17:03:58.825796: Current learning rate: 0.00686 
2025-02-21 17:04:31.018725: train_loss -0.9353 
2025-02-21 17:04:31.018867: val_loss -0.9452 
2025-02-21 17:04:31.018907: Pseudo dice [0.9792] 
2025-02-21 17:04:31.018946: Epoch time: 32.19 s 
2025-02-21 17:04:31.731120:  
2025-02-21 17:04:31.731283: Epoch 343 
2025-02-21 17:04:31.731327: Current learning rate: 0.00685 
2025-02-21 17:05:03.640530: train_loss -0.9374 
2025-02-21 17:05:03.640664: val_loss -0.9484 
2025-02-21 17:05:03.640702: Pseudo dice [0.9813] 
2025-02-21 17:05:03.640742: Epoch time: 31.91 s 
2025-02-21 17:05:04.359346:  
2025-02-21 17:05:04.359536: Epoch 344 
2025-02-21 17:05:04.359612: Current learning rate: 0.00684 
2025-02-21 17:05:36.533114: train_loss -0.9435 
2025-02-21 17:05:36.533248: val_loss -0.9482 
2025-02-21 17:05:36.533288: Pseudo dice [0.9827] 
2025-02-21 17:05:36.533324: Epoch time: 32.17 s 
2025-02-21 17:05:37.255092:  
2025-02-21 17:05:37.255316: Epoch 345 
2025-02-21 17:05:37.255414: Current learning rate: 0.00683 
2025-02-21 17:06:09.643580: train_loss -0.939 
2025-02-21 17:06:09.643857: val_loss -0.9494 
2025-02-21 17:06:09.643910: Pseudo dice [0.982] 
2025-02-21 17:06:09.643960: Epoch time: 32.39 s 
2025-02-21 17:06:09.643991: Yayy! New best EMA pseudo Dice: 0.9802 
2025-02-21 17:06:10.709106:  
2025-02-21 17:06:10.709249: Epoch 346 
2025-02-21 17:06:10.709351: Current learning rate: 0.00682 
2025-02-21 17:06:42.618938: train_loss -0.9407 
2025-02-21 17:06:42.619137: val_loss -0.9566 
2025-02-21 17:06:42.619177: Pseudo dice [0.9839] 
2025-02-21 17:06:42.619221: Epoch time: 31.91 s 
2025-02-21 17:06:42.619251: Yayy! New best EMA pseudo Dice: 0.9806 
2025-02-21 17:06:43.749180:  
2025-02-21 17:06:43.749407: Epoch 347 
2025-02-21 17:06:43.749503: Current learning rate: 0.00681 
2025-02-21 17:07:15.310344: train_loss -0.9275 
2025-02-21 17:07:15.310599: val_loss -0.9323 
2025-02-21 17:07:15.310657: Pseudo dice [0.9756] 
2025-02-21 17:07:15.310705: Epoch time: 31.56 s 
2025-02-21 17:07:16.028844:  
2025-02-21 17:07:16.029004: Epoch 348 
2025-02-21 17:07:16.029050: Current learning rate: 0.0068 
2025-02-21 17:07:48.318452: train_loss -0.9027 
2025-02-21 17:07:48.318627: val_loss -0.9314 
2025-02-21 17:07:48.318671: Pseudo dice [0.9728] 
2025-02-21 17:07:48.318763: Epoch time: 32.29 s 
2025-02-21 17:07:49.097380:  
2025-02-21 17:07:49.097600: Epoch 349 
2025-02-21 17:07:49.097679: Current learning rate: 0.0068 
2025-02-21 17:08:22.242320: train_loss -0.9183 
2025-02-21 17:08:22.242763: val_loss -0.9433 
2025-02-21 17:08:22.242820: Pseudo dice [0.9788] 
2025-02-21 17:08:22.242871: Epoch time: 33.15 s 
2025-02-21 17:08:23.466022:  
2025-02-21 17:08:23.466173: Epoch 350 
2025-02-21 17:08:23.466253: Current learning rate: 0.00679 
2025-02-21 17:08:55.241174: train_loss -0.9374 
2025-02-21 17:08:55.241398: val_loss -0.9427 
2025-02-21 17:08:55.241441: Pseudo dice [0.9781] 
2025-02-21 17:08:55.241479: Epoch time: 31.78 s 
2025-02-21 17:08:55.958126:  
2025-02-21 17:08:55.958305: Epoch 351 
2025-02-21 17:08:55.958385: Current learning rate: 0.00678 
2025-02-21 17:09:28.055199: train_loss -0.9359 
2025-02-21 17:09:28.055492: val_loss -0.9384 
2025-02-21 17:09:28.055569: Pseudo dice [0.9756] 
2025-02-21 17:09:28.055611: Epoch time: 32.1 s 
2025-02-21 17:09:28.779857:  
2025-02-21 17:09:28.780000: Epoch 352 
2025-02-21 17:09:28.780061: Current learning rate: 0.00677 
2025-02-21 17:10:01.979955: train_loss -0.9318 
2025-02-21 17:10:01.980207: val_loss -0.959 
2025-02-21 17:10:01.980250: Pseudo dice [0.9838] 
2025-02-21 17:10:01.980290: Epoch time: 33.2 s 
2025-02-21 17:10:02.898465:  
2025-02-21 17:10:02.898584: Epoch 353 
2025-02-21 17:10:02.898662: Current learning rate: 0.00676 
2025-02-21 17:10:34.685744: train_loss -0.9429 
2025-02-21 17:10:34.686129: val_loss -0.9402 
2025-02-21 17:10:34.686179: Pseudo dice [0.9779] 
2025-02-21 17:10:34.686221: Epoch time: 31.79 s 
2025-02-21 17:10:35.475501:  
2025-02-21 17:10:35.475590: Epoch 354 
2025-02-21 17:10:35.475662: Current learning rate: 0.00675 
2025-02-21 17:11:07.810357: train_loss -0.9268 
2025-02-21 17:11:07.810515: val_loss -0.9569 
2025-02-21 17:11:07.810552: Pseudo dice [0.9838] 
2025-02-21 17:11:07.810591: Epoch time: 32.34 s 
2025-02-21 17:11:09.362671:  
2025-02-21 17:11:09.362865: Epoch 355 
2025-02-21 17:11:09.362978: Current learning rate: 0.00674 
2025-02-21 17:11:42.456648: train_loss -0.9233 
2025-02-21 17:11:42.456851: val_loss -0.9538 
2025-02-21 17:11:42.456897: Pseudo dice [0.9826] 
2025-02-21 17:11:42.456979: Epoch time: 33.09 s 
2025-02-21 17:11:43.242384:  
2025-02-21 17:11:43.242638: Epoch 356 
2025-02-21 17:11:43.242725: Current learning rate: 0.00673 
2025-02-21 17:12:14.679488: train_loss -0.9452 
2025-02-21 17:12:14.679625: val_loss -0.9577 
2025-02-21 17:12:14.679665: Pseudo dice [0.9846] 
2025-02-21 17:12:14.679703: Epoch time: 31.44 s 
2025-02-21 17:12:15.396841:  
2025-02-21 17:12:15.397047: Epoch 357 
2025-02-21 17:12:15.397139: Current learning rate: 0.00672 
2025-02-21 17:12:47.069113: train_loss -0.9116 
2025-02-21 17:12:47.069302: val_loss -0.9465 
2025-02-21 17:12:47.069340: Pseudo dice [0.9803] 
2025-02-21 17:12:47.069377: Epoch time: 31.67 s 
2025-02-21 17:12:47.799463:  
2025-02-21 17:12:47.799670: Epoch 358 
2025-02-21 17:12:47.799733: Current learning rate: 0.00671 
2025-02-21 17:13:19.190742: train_loss -0.9197 
2025-02-21 17:13:19.190869: val_loss -0.9575 
2025-02-21 17:13:19.190906: Pseudo dice [0.9843] 
2025-02-21 17:13:19.190942: Epoch time: 31.39 s 
2025-02-21 17:13:19.190970: Yayy! New best EMA pseudo Dice: 0.9808 
2025-02-21 17:13:20.225198:  
2025-02-21 17:13:20.225360: Epoch 359 
2025-02-21 17:13:20.225404: Current learning rate: 0.0067 
2025-02-21 17:13:51.657912: train_loss -0.9296 
2025-02-21 17:13:51.658061: val_loss -0.9489 
2025-02-21 17:13:51.658105: Pseudo dice [0.9822] 
2025-02-21 17:13:51.658145: Epoch time: 31.43 s 
2025-02-21 17:13:51.658179: Yayy! New best EMA pseudo Dice: 0.9809 
2025-02-21 17:13:52.733188:  
2025-02-21 17:13:52.733351: Epoch 360 
2025-02-21 17:13:52.733400: Current learning rate: 0.00669 
2025-02-21 17:14:24.094326: train_loss -0.9309 
2025-02-21 17:14:24.094463: val_loss -0.9506 
2025-02-21 17:14:24.094501: Pseudo dice [0.9832] 
2025-02-21 17:14:24.094542: Epoch time: 31.36 s 
2025-02-21 17:14:24.094572: Yayy! New best EMA pseudo Dice: 0.9811 
2025-02-21 17:14:25.138426:  
2025-02-21 17:14:25.138608: Epoch 361 
2025-02-21 17:14:25.138668: Current learning rate: 0.00668 
2025-02-21 17:14:56.638825: train_loss -0.9263 
2025-02-21 17:14:56.638980: val_loss -0.9532 
2025-02-21 17:14:56.639026: Pseudo dice [0.9811] 
2025-02-21 17:14:56.639069: Epoch time: 31.5 s 
2025-02-21 17:14:57.365237:  
2025-02-21 17:14:57.365405: Epoch 362 
2025-02-21 17:14:57.365458: Current learning rate: 0.00667 
2025-02-21 17:15:28.998201: train_loss -0.9321 
2025-02-21 17:15:28.998428: val_loss -0.9503 
2025-02-21 17:15:28.998473: Pseudo dice [0.9807] 
2025-02-21 17:15:28.998515: Epoch time: 31.63 s 
2025-02-21 17:15:29.711449:  
2025-02-21 17:15:29.711689: Epoch 363 
2025-02-21 17:15:29.711750: Current learning rate: 0.00666 
2025-02-21 17:16:01.104046: train_loss -0.9376 
2025-02-21 17:16:01.104188: val_loss -0.946 
2025-02-21 17:16:01.104227: Pseudo dice [0.979] 
2025-02-21 17:16:01.104270: Epoch time: 31.39 s 
2025-02-21 17:16:01.822984:  
2025-02-21 17:16:01.823204: Epoch 364 
2025-02-21 17:16:01.823257: Current learning rate: 0.00665 
2025-02-21 17:16:33.266368: train_loss -0.9275 
2025-02-21 17:16:33.266535: val_loss -0.944 
2025-02-21 17:16:33.266573: Pseudo dice [0.9791] 
2025-02-21 17:16:33.266609: Epoch time: 31.44 s 
2025-02-21 17:16:33.988038:  
2025-02-21 17:16:33.988197: Epoch 365 
2025-02-21 17:16:33.988284: Current learning rate: 0.00665 
2025-02-21 17:17:05.537183: train_loss -0.9219 
2025-02-21 17:17:05.537316: val_loss -0.9498 
2025-02-21 17:17:05.537352: Pseudo dice [0.9797] 
2025-02-21 17:17:05.537391: Epoch time: 31.55 s 
2025-02-21 17:17:06.283517:  
2025-02-21 17:17:06.283695: Epoch 366 
2025-02-21 17:17:06.283756: Current learning rate: 0.00664 
2025-02-21 17:17:37.675853: train_loss -0.9219 
2025-02-21 17:17:37.675997: val_loss -0.9273 
2025-02-21 17:17:37.676038: Pseudo dice [0.9747] 
2025-02-21 17:17:37.676074: Epoch time: 31.39 s 
2025-02-21 17:17:38.390890:  
2025-02-21 17:17:38.391038: Epoch 367 
2025-02-21 17:17:38.391088: Current learning rate: 0.00663 
2025-02-21 17:18:09.988602: train_loss -0.9222 
2025-02-21 17:18:09.988729: val_loss -0.9545 
2025-02-21 17:18:09.988767: Pseudo dice [0.981] 
2025-02-21 17:18:09.988803: Epoch time: 31.6 s 
2025-02-21 17:18:10.695352:  
2025-02-21 17:18:10.695517: Epoch 368 
2025-02-21 17:18:10.695573: Current learning rate: 0.00662 
2025-02-21 17:18:42.109623: train_loss -0.9241 
2025-02-21 17:18:42.109766: val_loss -0.9574 
2025-02-21 17:18:42.109846: Pseudo dice [0.9838] 
2025-02-21 17:18:42.109894: Epoch time: 31.41 s 
2025-02-21 17:18:42.821582:  
2025-02-21 17:18:42.821718: Epoch 369 
2025-02-21 17:18:42.821829: Current learning rate: 0.00661 
2025-02-21 17:19:14.321320: train_loss -0.9421 
2025-02-21 17:19:14.321484: val_loss -0.9551 
2025-02-21 17:19:14.321547: Pseudo dice [0.9825] 
2025-02-21 17:19:14.321616: Epoch time: 31.5 s 
2025-02-21 17:19:15.056362:  
2025-02-21 17:19:15.056559: Epoch 370 
2025-02-21 17:19:15.056653: Current learning rate: 0.0066 
2025-02-21 17:19:46.756356: train_loss -0.918 
2025-02-21 17:19:46.756521: val_loss -0.9425 
2025-02-21 17:19:46.756562: Pseudo dice [0.9792] 
2025-02-21 17:19:46.756601: Epoch time: 31.7 s 
2025-02-21 17:19:47.476980:  
2025-02-21 17:19:47.477123: Epoch 371 
2025-02-21 17:19:47.477201: Current learning rate: 0.00659 
2025-02-21 17:20:19.128338: train_loss -0.9388 
2025-02-21 17:20:19.128496: val_loss -0.9424 
2025-02-21 17:20:19.128534: Pseudo dice [0.9783] 
2025-02-21 17:20:19.128571: Epoch time: 31.65 s 
2025-02-21 17:20:20.465415:  
2025-02-21 17:20:20.465602: Epoch 372 
2025-02-21 17:20:20.465682: Current learning rate: 0.00658 
2025-02-21 17:20:52.085546: train_loss -0.936 
2025-02-21 17:20:52.085704: val_loss -0.9472 
2025-02-21 17:20:52.085741: Pseudo dice [0.9788] 
2025-02-21 17:20:52.085788: Epoch time: 31.62 s 
2025-02-21 17:20:52.820788:  
2025-02-21 17:20:52.820965: Epoch 373 
2025-02-21 17:20:52.821019: Current learning rate: 0.00657 
2025-02-21 17:21:24.606380: train_loss -0.9357 
2025-02-21 17:21:24.606540: val_loss -0.9596 
2025-02-21 17:21:24.606580: Pseudo dice [0.9835] 
2025-02-21 17:21:24.606619: Epoch time: 31.79 s 
2025-02-21 17:21:25.321543:  
2025-02-21 17:21:25.321738: Epoch 374 
2025-02-21 17:21:25.321796: Current learning rate: 0.00656 
2025-02-21 17:21:57.399947: train_loss -0.9299 
2025-02-21 17:21:57.400079: val_loss -0.956 
2025-02-21 17:21:57.400118: Pseudo dice [0.9829] 
2025-02-21 17:21:57.400156: Epoch time: 32.08 s 
2025-02-21 17:21:58.113261:  
2025-02-21 17:21:58.113425: Epoch 375 
2025-02-21 17:21:58.113475: Current learning rate: 0.00655 
2025-02-21 17:22:29.783464: train_loss -0.9328 
2025-02-21 17:22:29.783597: val_loss -0.9407 
2025-02-21 17:22:29.783644: Pseudo dice [0.976] 
2025-02-21 17:22:29.783692: Epoch time: 31.67 s 
2025-02-21 17:22:30.506784:  
2025-02-21 17:22:30.507005: Epoch 376 
2025-02-21 17:22:30.507089: Current learning rate: 0.00654 
2025-02-21 17:23:02.163439: train_loss -0.9306 
2025-02-21 17:23:02.163618: val_loss -0.9505 
2025-02-21 17:23:02.163664: Pseudo dice [0.9803] 
2025-02-21 17:23:02.163706: Epoch time: 31.66 s 
2025-02-21 17:23:02.896595:  
2025-02-21 17:23:02.896800: Epoch 377 
2025-02-21 17:23:02.896870: Current learning rate: 0.00653 
2025-02-21 17:23:34.591169: train_loss -0.9307 
2025-02-21 17:23:34.591331: val_loss -0.9562 
2025-02-21 17:23:34.591372: Pseudo dice [0.9822] 
2025-02-21 17:23:34.591413: Epoch time: 31.7 s 
2025-02-21 17:23:35.313206:  
2025-02-21 17:23:35.313434: Epoch 378 
2025-02-21 17:23:35.313495: Current learning rate: 0.00652 
2025-02-21 17:24:06.803206: train_loss -0.9305 
2025-02-21 17:24:06.803342: val_loss -0.948 
2025-02-21 17:24:06.803381: Pseudo dice [0.9787] 
2025-02-21 17:24:06.803423: Epoch time: 31.49 s 
2025-02-21 17:24:07.644066:  
2025-02-21 17:24:07.644195: Epoch 379 
2025-02-21 17:24:07.644261: Current learning rate: 0.00651 
2025-02-21 17:24:39.535847: train_loss -0.9264 
2025-02-21 17:24:39.536048: val_loss -0.9387 
2025-02-21 17:24:39.536156: Pseudo dice [0.9785] 
2025-02-21 17:24:39.536206: Epoch time: 31.89 s 
2025-02-21 17:24:40.248771:  
2025-02-21 17:24:40.248953: Epoch 380 
2025-02-21 17:24:40.249010: Current learning rate: 0.0065 
2025-02-21 17:25:12.008899: train_loss -0.9434 
2025-02-21 17:25:12.009036: val_loss -0.9536 
2025-02-21 17:25:12.009075: Pseudo dice [0.9804] 
2025-02-21 17:25:12.009113: Epoch time: 31.76 s 
2025-02-21 17:25:12.719690:  
2025-02-21 17:25:12.719876: Epoch 381 
2025-02-21 17:25:12.719937: Current learning rate: 0.00649 
2025-02-21 17:25:44.506807: train_loss -0.9411 
2025-02-21 17:25:44.506940: val_loss -0.9534 
2025-02-21 17:25:44.506994: Pseudo dice [0.9837] 
2025-02-21 17:25:44.507040: Epoch time: 31.79 s 
2025-02-21 17:25:45.232652:  
2025-02-21 17:25:45.232827: Epoch 382 
2025-02-21 17:25:45.232884: Current learning rate: 0.00648 
2025-02-21 17:26:17.154004: train_loss -0.9404 
2025-02-21 17:26:17.154170: val_loss -0.9584 
2025-02-21 17:26:17.154214: Pseudo dice [0.9851] 
2025-02-21 17:26:17.154255: Epoch time: 31.92 s 
2025-02-21 17:26:17.886552:  
2025-02-21 17:26:17.886760: Epoch 383 
2025-02-21 17:26:17.886849: Current learning rate: 0.00648 
2025-02-21 17:26:49.631989: train_loss -0.9385 
2025-02-21 17:26:49.632151: val_loss -0.9508 
2025-02-21 17:26:49.632190: Pseudo dice [0.9827] 
2025-02-21 17:26:49.632229: Epoch time: 31.75 s 
2025-02-21 17:26:50.358072:  
2025-02-21 17:26:50.358274: Epoch 384 
2025-02-21 17:26:50.358325: Current learning rate: 0.00647 
2025-02-21 17:27:22.008032: train_loss -0.925 
2025-02-21 17:27:22.008183: val_loss -0.9503 
2025-02-21 17:27:22.008238: Pseudo dice [0.9822] 
2025-02-21 17:27:22.008307: Epoch time: 31.65 s 
2025-02-21 17:27:22.008338: Yayy! New best EMA pseudo Dice: 0.9812 
2025-02-21 17:27:23.253034:  
2025-02-21 17:27:23.253241: Epoch 385 
2025-02-21 17:27:23.253335: Current learning rate: 0.00646 
2025-02-21 17:27:56.039000: train_loss -0.9311 
2025-02-21 17:27:56.039242: val_loss -0.9414 
2025-02-21 17:27:56.039286: Pseudo dice [0.9795] 
2025-02-21 17:27:56.039325: Epoch time: 32.79 s 
2025-02-21 17:27:56.995217:  
2025-02-21 17:27:56.995407: Epoch 386 
2025-02-21 17:27:56.995522: Current learning rate: 0.00645 
2025-02-21 17:28:29.165959: train_loss -0.9229 
2025-02-21 17:28:29.166160: val_loss -0.9404 
2025-02-21 17:28:29.166208: Pseudo dice [0.9784] 
2025-02-21 17:28:29.166247: Epoch time: 32.17 s 
2025-02-21 17:28:29.908885:  
2025-02-21 17:28:29.909027: Epoch 387 
2025-02-21 17:28:29.909102: Current learning rate: 0.00644 
2025-02-21 17:29:01.692675: train_loss -0.9316 
2025-02-21 17:29:01.692933: val_loss -0.9474 
2025-02-21 17:29:01.692980: Pseudo dice [0.9796] 
2025-02-21 17:29:01.693023: Epoch time: 31.78 s 
2025-02-21 17:29:03.271754:  
2025-02-21 17:29:03.271947: Epoch 388 
2025-02-21 17:29:03.272026: Current learning rate: 0.00643 
2025-02-21 17:29:34.993876: train_loss -0.9406 
2025-02-21 17:29:34.994252: val_loss -0.9574 
2025-02-21 17:29:34.994337: Pseudo dice [0.985] 
2025-02-21 17:29:34.994377: Epoch time: 31.72 s 
2025-02-21 17:29:35.815565:  
2025-02-21 17:29:35.815820: Epoch 389 
2025-02-21 17:29:35.815907: Current learning rate: 0.00642 
2025-02-21 17:30:07.686302: train_loss -0.9317 
2025-02-21 17:30:07.686441: val_loss -0.9581 
2025-02-21 17:30:07.686479: Pseudo dice [0.9841] 
2025-02-21 17:30:07.686516: Epoch time: 31.87 s 
2025-02-21 17:30:07.686544: Yayy! New best EMA pseudo Dice: 0.9814 
2025-02-21 17:30:08.731585:  
2025-02-21 17:30:08.731814: Epoch 390 
2025-02-21 17:30:08.731874: Current learning rate: 0.00641 
2025-02-21 17:30:40.832061: train_loss -0.944 
2025-02-21 17:30:40.832219: val_loss -0.9487 
2025-02-21 17:30:40.832258: Pseudo dice [0.9789] 
2025-02-21 17:30:40.832298: Epoch time: 32.1 s 
2025-02-21 17:30:41.556263:  
2025-02-21 17:30:41.556494: Epoch 391 
2025-02-21 17:30:41.556559: Current learning rate: 0.0064 
2025-02-21 17:31:13.497852: train_loss -0.9343 
2025-02-21 17:31:13.498368: val_loss -0.9503 
2025-02-21 17:31:13.498470: Pseudo dice [0.9801] 
2025-02-21 17:31:13.498549: Epoch time: 31.94 s 
2025-02-21 17:31:14.415940:  
2025-02-21 17:31:14.416202: Epoch 392 
2025-02-21 17:31:14.416305: Current learning rate: 0.00639 
2025-02-21 17:31:46.451063: train_loss -0.9341 
2025-02-21 17:31:46.451202: val_loss -0.9595 
2025-02-21 17:31:46.451241: Pseudo dice [0.984] 
2025-02-21 17:31:46.451293: Epoch time: 32.04 s 
2025-02-21 17:31:47.187580:  
2025-02-21 17:31:47.187790: Epoch 393 
2025-02-21 17:31:47.187874: Current learning rate: 0.00638 
2025-02-21 17:32:19.177485: train_loss -0.9182 
2025-02-21 17:32:19.177753: val_loss -0.9402 
2025-02-21 17:32:19.177840: Pseudo dice [0.9776] 
2025-02-21 17:32:19.177990: Epoch time: 31.99 s 
2025-02-21 17:32:20.013684:  
2025-02-21 17:32:20.013880: Epoch 394 
2025-02-21 17:32:20.013985: Current learning rate: 0.00637 
2025-02-21 17:32:52.877979: train_loss -0.9251 
2025-02-21 17:32:52.878249: val_loss -0.9489 
2025-02-21 17:32:52.878340: Pseudo dice [0.9816] 
2025-02-21 17:32:52.878415: Epoch time: 32.86 s 
2025-02-21 17:32:53.818897:  
2025-02-21 17:32:53.819058: Epoch 395 
2025-02-21 17:32:53.819136: Current learning rate: 0.00636 
2025-02-21 17:33:26.631196: train_loss -0.9315 
2025-02-21 17:33:26.631614: val_loss -0.9519 
2025-02-21 17:33:26.631735: Pseudo dice [0.9832] 
2025-02-21 17:33:26.631776: Epoch time: 32.81 s 
2025-02-21 17:33:27.370853:  
2025-02-21 17:33:27.371083: Epoch 396 
2025-02-21 17:33:27.371132: Current learning rate: 0.00635 
2025-02-21 17:33:59.706569: train_loss -0.923 
2025-02-21 17:33:59.707018: val_loss -0.9538 
2025-02-21 17:33:59.707085: Pseudo dice [0.9822] 
2025-02-21 17:33:59.707132: Epoch time: 32.34 s 
2025-02-21 17:34:00.537107:  
2025-02-21 17:34:00.537329: Epoch 397 
2025-02-21 17:34:00.537403: Current learning rate: 0.00634 
2025-02-21 17:34:32.707106: train_loss -0.9296 
2025-02-21 17:34:32.707440: val_loss -0.9418 
2025-02-21 17:34:32.707496: Pseudo dice [0.9773] 
2025-02-21 17:34:32.707540: Epoch time: 32.17 s 
2025-02-21 17:34:33.636364:  
2025-02-21 17:34:33.636530: Epoch 398 
2025-02-21 17:34:33.636629: Current learning rate: 0.00633 
2025-02-21 17:35:05.689253: train_loss -0.9301 
2025-02-21 17:35:05.689512: val_loss -0.9505 
2025-02-21 17:35:05.689566: Pseudo dice [0.9825] 
2025-02-21 17:35:05.689607: Epoch time: 32.05 s 
2025-02-21 17:35:06.428060:  
2025-02-21 17:35:06.428263: Epoch 399 
2025-02-21 17:35:06.428329: Current learning rate: 0.00632 
2025-02-21 17:35:38.829593: train_loss -0.9323 
2025-02-21 17:35:38.829758: val_loss -0.9532 
2025-02-21 17:35:38.829802: Pseudo dice [0.9818] 
2025-02-21 17:35:38.829854: Epoch time: 32.4 s 
2025-02-21 17:35:39.927728:  
2025-02-21 17:35:39.927884: Epoch 400 
2025-02-21 17:35:39.927959: Current learning rate: 0.00631 
2025-02-21 17:36:12.124500: train_loss -0.9396 
2025-02-21 17:36:12.124663: val_loss -0.9549 
2025-02-21 17:36:12.124733: Pseudo dice [0.9833] 
2025-02-21 17:36:12.124783: Epoch time: 32.2 s 
2025-02-21 17:36:12.863357:  
2025-02-21 17:36:12.863479: Epoch 401 
2025-02-21 17:36:12.863563: Current learning rate: 0.0063 
2025-02-21 17:36:44.621967: train_loss -0.9364 
2025-02-21 17:36:44.622114: val_loss -0.9512 
2025-02-21 17:36:44.622155: Pseudo dice [0.9806] 
2025-02-21 17:36:44.622195: Epoch time: 31.76 s 
2025-02-21 17:36:45.361477:  
2025-02-21 17:36:45.361648: Epoch 402 
2025-02-21 17:36:45.361747: Current learning rate: 0.0063 
2025-02-21 17:37:18.249799: train_loss -0.939 
2025-02-21 17:37:18.250003: val_loss -0.962 
2025-02-21 17:37:18.250046: Pseudo dice [0.9846] 
2025-02-21 17:37:18.250096: Epoch time: 32.89 s 
2025-02-21 17:37:18.250127: Yayy! New best EMA pseudo Dice: 0.9816 
2025-02-21 17:37:19.369888:  
2025-02-21 17:37:19.370036: Epoch 403 
2025-02-21 17:37:19.370103: Current learning rate: 0.00629 
2025-02-21 17:37:52.330801: train_loss -0.9316 
2025-02-21 17:37:52.331572: val_loss -0.9495 
2025-02-21 17:37:52.331822: Pseudo dice [0.9805] 
2025-02-21 17:37:52.331900: Epoch time: 32.96 s 
2025-02-21 17:37:53.237298:  
2025-02-21 17:37:53.237417: Epoch 404 
2025-02-21 17:37:53.237487: Current learning rate: 0.00628 
2025-02-21 17:38:25.132644: train_loss -0.9198 
2025-02-21 17:38:25.132778: val_loss -0.9365 
2025-02-21 17:38:25.132863: Pseudo dice [0.975] 
2025-02-21 17:38:25.132906: Epoch time: 31.9 s 
2025-02-21 17:38:26.525226:  
2025-02-21 17:38:26.525415: Epoch 405 
2025-02-21 17:38:26.525474: Current learning rate: 0.00627 
2025-02-21 17:38:58.004220: train_loss -0.9311 
2025-02-21 17:38:58.004389: val_loss -0.9483 
2025-02-21 17:38:58.004426: Pseudo dice [0.9806] 
2025-02-21 17:38:58.004469: Epoch time: 31.48 s 
2025-02-21 17:38:58.738085:  
2025-02-21 17:38:58.738375: Epoch 406 
2025-02-21 17:38:58.738469: Current learning rate: 0.00626 
2025-02-21 17:39:30.179877: train_loss -0.9338 
2025-02-21 17:39:30.180009: val_loss -0.9482 
2025-02-21 17:39:30.180047: Pseudo dice [0.9796] 
2025-02-21 17:39:30.180085: Epoch time: 31.44 s 
2025-02-21 17:39:30.911998:  
2025-02-21 17:39:30.912240: Epoch 407 
2025-02-21 17:39:30.912330: Current learning rate: 0.00625 
2025-02-21 17:40:02.322374: train_loss -0.9348 
2025-02-21 17:40:02.322524: val_loss -0.9487 
2025-02-21 17:40:02.322564: Pseudo dice [0.9811] 
2025-02-21 17:40:02.322604: Epoch time: 31.41 s 
2025-02-21 17:40:03.039350:  
2025-02-21 17:40:03.039519: Epoch 408 
2025-02-21 17:40:03.039578: Current learning rate: 0.00624 
2025-02-21 17:40:34.378798: train_loss -0.9173 
2025-02-21 17:40:34.378947: val_loss -0.9557 
2025-02-21 17:40:34.379023: Pseudo dice [0.9828] 
2025-02-21 17:40:34.379086: Epoch time: 31.34 s 
2025-02-21 17:40:35.182941:  
2025-02-21 17:40:35.183193: Epoch 409 
2025-02-21 17:40:35.183286: Current learning rate: 0.00623 
2025-02-21 17:41:06.660354: train_loss -0.9248 
2025-02-21 17:41:06.660495: val_loss -0.943 
2025-02-21 17:41:06.660535: Pseudo dice [0.9774] 
2025-02-21 17:41:06.660572: Epoch time: 31.48 s 
2025-02-21 17:41:07.395282:  
2025-02-21 17:41:07.395451: Epoch 410 
2025-02-21 17:41:07.395513: Current learning rate: 0.00622 
2025-02-21 17:41:38.752636: train_loss -0.9357 
2025-02-21 17:41:38.752791: val_loss -0.9482 
2025-02-21 17:41:38.752839: Pseudo dice [0.9793] 
2025-02-21 17:41:38.752880: Epoch time: 31.36 s 
2025-02-21 17:41:39.435220:  
2025-02-21 17:41:39.435387: Epoch 411 
2025-02-21 17:41:39.435440: Current learning rate: 0.00621 
2025-02-21 17:42:10.839125: train_loss -0.9216 
2025-02-21 17:42:10.839245: val_loss -0.9485 
2025-02-21 17:42:10.839284: Pseudo dice [0.9815] 
2025-02-21 17:42:10.839320: Epoch time: 31.4 s 
2025-02-21 17:42:11.529274:  
2025-02-21 17:42:11.529476: Epoch 412 
2025-02-21 17:42:11.529533: Current learning rate: 0.0062 
2025-02-21 17:42:43.008289: train_loss -0.9345 
2025-02-21 17:42:43.008491: val_loss -0.9625 
2025-02-21 17:42:43.008553: Pseudo dice [0.9857] 
2025-02-21 17:42:43.008605: Epoch time: 31.48 s 
2025-02-21 17:42:43.756902:  
2025-02-21 17:42:43.757163: Epoch 413 
2025-02-21 17:42:43.757260: Current learning rate: 0.00619 
2025-02-21 17:43:15.114968: train_loss -0.9276 
2025-02-21 17:43:15.115122: val_loss -0.9514 
2025-02-21 17:43:15.115160: Pseudo dice [0.9801] 
2025-02-21 17:43:15.115229: Epoch time: 31.36 s 
2025-02-21 17:43:15.802439:  
2025-02-21 17:43:15.802609: Epoch 414 
2025-02-21 17:43:15.802686: Current learning rate: 0.00618 
2025-02-21 17:43:47.538967: train_loss -0.9154 
2025-02-21 17:43:47.539407: val_loss -0.9379 
2025-02-21 17:43:47.539463: Pseudo dice [0.9736] 
2025-02-21 17:43:47.539514: Epoch time: 31.74 s 
2025-02-21 17:43:48.266927:  
2025-02-21 17:43:48.267159: Epoch 415 
2025-02-21 17:43:48.267236: Current learning rate: 0.00617 
2025-02-21 17:44:19.744050: train_loss -0.9259 
2025-02-21 17:44:19.744184: val_loss -0.9519 
2025-02-21 17:44:19.744222: Pseudo dice [0.9829] 
2025-02-21 17:44:19.744267: Epoch time: 31.48 s 
2025-02-21 17:44:20.449886:  
2025-02-21 17:44:20.450069: Epoch 416 
2025-02-21 17:44:20.450144: Current learning rate: 0.00616 
2025-02-21 17:44:52.013342: train_loss -0.9095 
2025-02-21 17:44:52.013724: val_loss -0.9545 
2025-02-21 17:44:52.013778: Pseudo dice [0.9821] 
2025-02-21 17:44:52.013825: Epoch time: 31.56 s 
2025-02-21 17:44:52.732654:  
2025-02-21 17:44:52.732919: Epoch 417 
2025-02-21 17:44:52.732990: Current learning rate: 0.00615 
2025-02-21 17:45:24.196892: train_loss -0.9238 
2025-02-21 17:45:24.197050: val_loss -0.9365 
2025-02-21 17:45:24.197125: Pseudo dice [0.9776] 
2025-02-21 17:45:24.197199: Epoch time: 31.46 s 
2025-02-21 17:45:25.030361:  
2025-02-21 17:45:25.030507: Epoch 418 
2025-02-21 17:45:25.030602: Current learning rate: 0.00614 
2025-02-21 17:45:56.649423: train_loss -0.9352 
2025-02-21 17:45:56.649582: val_loss -0.9421 
2025-02-21 17:45:56.649646: Pseudo dice [0.9781] 
2025-02-21 17:45:56.649715: Epoch time: 31.62 s 
2025-02-21 17:45:57.458176:  
2025-02-21 17:45:57.458298: Epoch 419 
2025-02-21 17:45:57.458384: Current learning rate: 0.00613 
2025-02-21 17:46:29.380580: train_loss -0.9304 
2025-02-21 17:46:29.380774: val_loss -0.9492 
2025-02-21 17:46:29.380820: Pseudo dice [0.9805] 
2025-02-21 17:46:29.380863: Epoch time: 31.92 s 
2025-02-21 17:46:30.088034:  
2025-02-21 17:46:30.088196: Epoch 420 
2025-02-21 17:46:30.088276: Current learning rate: 0.00612 
2025-02-21 17:47:01.932937: train_loss -0.925 
2025-02-21 17:47:01.933082: val_loss -0.9493 
2025-02-21 17:47:01.933160: Pseudo dice [0.9809] 
2025-02-21 17:47:01.933215: Epoch time: 31.85 s 
2025-02-21 17:47:02.624921:  
2025-02-21 17:47:02.625073: Epoch 421 
2025-02-21 17:47:02.625140: Current learning rate: 0.00612 
2025-02-21 17:47:34.678606: train_loss -0.9294 
2025-02-21 17:47:34.678984: val_loss -0.9376 
2025-02-21 17:47:34.679033: Pseudo dice [0.9784] 
2025-02-21 17:47:34.679073: Epoch time: 32.05 s 
2025-02-21 17:47:36.000292:  
2025-02-21 17:47:36.000463: Epoch 422 
2025-02-21 17:47:36.000567: Current learning rate: 0.00611 
2025-02-21 17:48:07.620660: train_loss -0.9129 
2025-02-21 17:48:07.620799: val_loss -0.9257 
2025-02-21 17:48:07.620847: Pseudo dice [0.9748] 
2025-02-21 17:48:07.620887: Epoch time: 31.62 s 
2025-02-21 17:48:08.313996:  
2025-02-21 17:48:08.314194: Epoch 423 
2025-02-21 17:48:08.314260: Current learning rate: 0.0061 
2025-02-21 17:48:39.988346: train_loss -0.9238 
2025-02-21 17:48:39.988497: val_loss -0.946 
2025-02-21 17:48:39.988536: Pseudo dice [0.9809] 
2025-02-21 17:48:39.988574: Epoch time: 31.68 s 
2025-02-21 17:48:40.673429:  
2025-02-21 17:48:40.673561: Epoch 424 
2025-02-21 17:48:40.673670: Current learning rate: 0.00609 
2025-02-21 17:49:12.242148: train_loss -0.9287 
2025-02-21 17:49:12.242313: val_loss -0.9419 
2025-02-21 17:49:12.242353: Pseudo dice [0.9785] 
2025-02-21 17:49:12.242392: Epoch time: 31.57 s 
2025-02-21 17:49:12.941397:  
2025-02-21 17:49:12.941622: Epoch 425 
2025-02-21 17:49:12.941676: Current learning rate: 0.00608 
2025-02-21 17:49:44.571371: train_loss -0.9357 
2025-02-21 17:49:44.571506: val_loss -0.9437 
2025-02-21 17:49:44.571544: Pseudo dice [0.9787] 
2025-02-21 17:49:44.571582: Epoch time: 31.63 s 
2025-02-21 17:49:45.276367:  
2025-02-21 17:49:45.276591: Epoch 426 
2025-02-21 17:49:45.276687: Current learning rate: 0.00607 
2025-02-21 17:50:16.827708: train_loss -0.932 
2025-02-21 17:50:16.827869: val_loss -0.9415 
2025-02-21 17:50:16.827908: Pseudo dice [0.9764] 
2025-02-21 17:50:16.827950: Epoch time: 31.55 s 
2025-02-21 17:50:17.529117:  
2025-02-21 17:50:17.529358: Epoch 427 
2025-02-21 17:50:17.529427: Current learning rate: 0.00606 
2025-02-21 17:50:49.691384: train_loss -0.9362 
2025-02-21 17:50:49.691557: val_loss -0.9495 
2025-02-21 17:50:49.691602: Pseudo dice [0.9816] 
2025-02-21 17:50:49.691648: Epoch time: 32.16 s 
2025-02-21 17:50:50.390323:  
2025-02-21 17:50:50.390512: Epoch 428 
2025-02-21 17:50:50.390572: Current learning rate: 0.00605 
2025-02-21 17:51:22.112926: train_loss -0.9381 
2025-02-21 17:51:22.113062: val_loss -0.9572 
2025-02-21 17:51:22.113103: Pseudo dice [0.9826] 
2025-02-21 17:51:22.113167: Epoch time: 31.72 s 
2025-02-21 17:51:22.802224:  
2025-02-21 17:51:22.802381: Epoch 429 
2025-02-21 17:51:22.802426: Current learning rate: 0.00604 
2025-02-21 17:51:54.773466: train_loss -0.9324 
2025-02-21 17:51:54.773626: val_loss -0.9475 
2025-02-21 17:51:54.773695: Pseudo dice [0.9775] 
2025-02-21 17:51:54.773733: Epoch time: 31.97 s 
2025-02-21 17:51:55.485022:  
2025-02-21 17:51:55.485252: Epoch 430 
2025-02-21 17:51:55.485316: Current learning rate: 0.00603 
2025-02-21 17:52:27.232897: train_loss -0.9293 
2025-02-21 17:52:27.233098: val_loss -0.9439 
2025-02-21 17:52:27.233144: Pseudo dice [0.9777] 
2025-02-21 17:52:27.233191: Epoch time: 31.75 s 
2025-02-21 17:52:27.939265:  
2025-02-21 17:52:27.939464: Epoch 431 
2025-02-21 17:52:27.939540: Current learning rate: 0.00602 
2025-02-21 17:53:00.016541: train_loss -0.9287 
2025-02-21 17:53:00.016742: val_loss -0.9368 
2025-02-21 17:53:00.016782: Pseudo dice [0.9756] 
2025-02-21 17:53:00.016832: Epoch time: 32.08 s 
2025-02-21 17:53:00.741178:  
2025-02-21 17:53:00.741389: Epoch 432 
2025-02-21 17:53:00.741475: Current learning rate: 0.00601 
2025-02-21 17:53:32.164227: train_loss -0.9383 
2025-02-21 17:53:32.164381: val_loss -0.9484 
2025-02-21 17:53:32.164420: Pseudo dice [0.9812] 
2025-02-21 17:53:32.164461: Epoch time: 31.42 s 
2025-02-21 17:53:32.860198:  
2025-02-21 17:53:32.860362: Epoch 433 
2025-02-21 17:53:32.860409: Current learning rate: 0.006 
2025-02-21 17:54:05.010010: train_loss -0.932 
2025-02-21 17:54:05.010218: val_loss -0.947 
2025-02-21 17:54:05.010258: Pseudo dice [0.9796] 
2025-02-21 17:54:05.010301: Epoch time: 32.15 s 
2025-02-21 17:54:05.710928:  
2025-02-21 17:54:05.711068: Epoch 434 
2025-02-21 17:54:05.711192: Current learning rate: 0.00599 
2025-02-21 17:54:37.903528: train_loss -0.9346 
2025-02-21 17:54:37.903694: val_loss -0.9504 
2025-02-21 17:54:37.903730: Pseudo dice [0.9807] 
2025-02-21 17:54:37.903768: Epoch time: 32.19 s 
2025-02-21 17:54:38.613460:  
2025-02-21 17:54:38.613651: Epoch 435 
2025-02-21 17:54:38.613719: Current learning rate: 0.00598 
2025-02-21 17:55:10.830232: train_loss -0.9382 
2025-02-21 17:55:10.830443: val_loss -0.9619 
2025-02-21 17:55:10.830505: Pseudo dice [0.9851] 
2025-02-21 17:55:10.830559: Epoch time: 32.22 s 
2025-02-21 17:55:11.677686:  
2025-02-21 17:55:11.677896: Epoch 436 
2025-02-21 17:55:11.678057: Current learning rate: 0.00597 
2025-02-21 17:55:43.530592: train_loss -0.9346 
2025-02-21 17:55:43.530762: val_loss -0.9494 
2025-02-21 17:55:43.530813: Pseudo dice [0.9807] 
2025-02-21 17:55:43.530860: Epoch time: 31.85 s 
2025-02-21 17:55:44.231713:  
2025-02-21 17:55:44.231863: Epoch 437 
2025-02-21 17:55:44.231927: Current learning rate: 0.00596 
2025-02-21 17:56:16.213325: train_loss -0.9315 
2025-02-21 17:56:16.213477: val_loss -0.9357 
2025-02-21 17:56:16.213516: Pseudo dice [0.9761] 
2025-02-21 17:56:16.213554: Epoch time: 31.98 s 
2025-02-21 17:56:16.914595:  
2025-02-21 17:56:16.914796: Epoch 438 
2025-02-21 17:56:16.914877: Current learning rate: 0.00595 
2025-02-21 17:56:48.963208: train_loss -0.9386 
2025-02-21 17:56:48.963495: val_loss -0.946 
2025-02-21 17:56:48.963565: Pseudo dice [0.979] 
2025-02-21 17:56:48.963625: Epoch time: 32.05 s 
2025-02-21 17:56:49.816398:  
2025-02-21 17:56:49.816584: Epoch 439 
2025-02-21 17:56:49.816670: Current learning rate: 0.00594 
2025-02-21 17:57:21.498302: train_loss -0.9353 
2025-02-21 17:57:21.498586: val_loss -0.9531 
2025-02-21 17:57:21.498633: Pseudo dice [0.9823] 
2025-02-21 17:57:21.498681: Epoch time: 31.68 s 
2025-02-21 17:57:23.065391:  
2025-02-21 17:57:23.065567: Epoch 440 
2025-02-21 17:57:23.065675: Current learning rate: 0.00593 
2025-02-21 17:57:55.210346: train_loss -0.9379 
2025-02-21 17:57:55.210786: val_loss -0.9315 
2025-02-21 17:57:55.210898: Pseudo dice [0.976] 
2025-02-21 17:57:55.210971: Epoch time: 32.15 s 
2025-02-21 17:57:55.909136:  
2025-02-21 17:57:55.909371: Epoch 441 
2025-02-21 17:57:55.909449: Current learning rate: 0.00592 
2025-02-21 17:58:27.808817: train_loss -0.9319 
2025-02-21 17:58:27.808990: val_loss -0.9594 
2025-02-21 17:58:27.809050: Pseudo dice [0.9841] 
2025-02-21 17:58:27.809089: Epoch time: 31.9 s 
2025-02-21 17:58:28.751289:  
2025-02-21 17:58:28.751512: Epoch 442 
2025-02-21 17:58:28.751615: Current learning rate: 0.00592 
2025-02-21 17:59:01.267065: train_loss -0.9229 
2025-02-21 17:59:01.267564: val_loss -0.9352 
2025-02-21 17:59:01.267678: Pseudo dice [0.9772] 
2025-02-21 17:59:01.267781: Epoch time: 32.52 s 
2025-02-21 17:59:02.220403:  
2025-02-21 17:59:02.220689: Epoch 443 
2025-02-21 17:59:02.220767: Current learning rate: 0.00591 
2025-02-21 17:59:34.351526: train_loss -0.9337 
2025-02-21 17:59:34.351674: val_loss -0.9612 
2025-02-21 17:59:34.351712: Pseudo dice [0.9855] 
2025-02-21 17:59:34.351750: Epoch time: 32.13 s 
2025-02-21 17:59:35.071452:  
2025-02-21 17:59:35.071640: Epoch 444 
2025-02-21 17:59:35.071749: Current learning rate: 0.0059 
2025-02-21 18:00:07.013928: train_loss -0.9416 
2025-02-21 18:00:07.014112: val_loss -0.9409 
2025-02-21 18:00:07.014156: Pseudo dice [0.9766] 
2025-02-21 18:00:07.014198: Epoch time: 31.94 s 
2025-02-21 18:00:07.715065:  
2025-02-21 18:00:07.715250: Epoch 445 
2025-02-21 18:00:07.715323: Current learning rate: 0.00589 
2025-02-21 18:00:39.967750: train_loss -0.9396 
2025-02-21 18:00:39.967888: val_loss -0.9588 
2025-02-21 18:00:39.967929: Pseudo dice [0.9832] 
2025-02-21 18:00:39.967965: Epoch time: 32.25 s 
2025-02-21 18:00:40.662229:  
2025-02-21 18:00:40.662459: Epoch 446 
2025-02-21 18:00:40.662534: Current learning rate: 0.00588 
2025-02-21 18:01:12.783670: train_loss -0.9278 
2025-02-21 18:01:12.784478: val_loss -0.9483 
2025-02-21 18:01:12.784521: Pseudo dice [0.9792] 
2025-02-21 18:01:12.784564: Epoch time: 32.12 s 
2025-02-21 18:01:13.687051:  
2025-02-21 18:01:13.687259: Epoch 447 
2025-02-21 18:01:13.687365: Current learning rate: 0.00587 
2025-02-21 18:01:46.009870: train_loss -0.9347 
2025-02-21 18:01:46.010393: val_loss -0.956 
2025-02-21 18:01:46.010458: Pseudo dice [0.9828] 
2025-02-21 18:01:46.010513: Epoch time: 32.32 s 
2025-02-21 18:01:46.815732:  
2025-02-21 18:01:46.815892: Epoch 448 
2025-02-21 18:01:46.815966: Current learning rate: 0.00586 
2025-02-21 18:02:18.931171: train_loss -0.943 
2025-02-21 18:02:18.931824: val_loss -0.9493 
2025-02-21 18:02:18.931875: Pseudo dice [0.979] 
2025-02-21 18:02:18.931920: Epoch time: 32.12 s 
2025-02-21 18:02:19.631612:  
2025-02-21 18:02:19.631783: Epoch 449 
2025-02-21 18:02:19.631895: Current learning rate: 0.00585 
2025-02-21 18:02:52.094063: train_loss -0.9261 
2025-02-21 18:02:52.094891: val_loss -0.9429 
2025-02-21 18:02:52.094973: Pseudo dice [0.979] 
2025-02-21 18:02:52.095032: Epoch time: 32.46 s 
2025-02-21 18:02:53.370086:  
2025-02-21 18:02:53.370250: Epoch 450 
2025-02-21 18:02:53.370326: Current learning rate: 0.00584 
2025-02-21 18:03:26.401515: train_loss -0.9247 
2025-02-21 18:03:26.402157: val_loss -0.9463 
2025-02-21 18:03:26.402200: Pseudo dice [0.9793] 
2025-02-21 18:03:26.402240: Epoch time: 33.03 s 
2025-02-21 18:03:27.173982:  
2025-02-21 18:03:27.174146: Epoch 451 
2025-02-21 18:03:27.174222: Current learning rate: 0.00583 
2025-02-21 18:04:00.306640: train_loss -0.9211 
2025-02-21 18:04:00.306946: val_loss -0.9348 
2025-02-21 18:04:00.306998: Pseudo dice [0.974] 
2025-02-21 18:04:00.307055: Epoch time: 33.13 s 
2025-02-21 18:04:01.096756:  
2025-02-21 18:04:01.096941: Epoch 452 
2025-02-21 18:04:01.097028: Current learning rate: 0.00582 
2025-02-21 18:04:33.235977: train_loss -0.9348 
2025-02-21 18:04:33.236356: val_loss -0.9594 
2025-02-21 18:04:33.236395: Pseudo dice [0.9832] 
2025-02-21 18:04:33.236435: Epoch time: 32.14 s 
2025-02-21 18:04:33.961730:  
2025-02-21 18:04:33.961958: Epoch 453 
2025-02-21 18:04:33.962026: Current learning rate: 0.00581 
2025-02-21 18:05:06.356436: train_loss -0.9468 
2025-02-21 18:05:06.356619: val_loss -0.9528 
2025-02-21 18:05:06.356718: Pseudo dice [0.9826] 
2025-02-21 18:05:06.356761: Epoch time: 32.4 s 
2025-02-21 18:05:07.052335:  
2025-02-21 18:05:07.052479: Epoch 454 
2025-02-21 18:05:07.052562: Current learning rate: 0.0058 
2025-02-21 18:05:40.219883: train_loss -0.9494 
2025-02-21 18:05:40.220198: val_loss -0.9456 
2025-02-21 18:05:40.220258: Pseudo dice [0.9789] 
2025-02-21 18:05:40.220618: Epoch time: 33.17 s 
2025-02-21 18:05:41.139563:  
2025-02-21 18:05:41.139786: Epoch 455 
2025-02-21 18:05:41.139910: Current learning rate: 0.00579 
2025-02-21 18:06:13.545759: train_loss -0.9437 
2025-02-21 18:06:13.546647: val_loss -0.9478 
2025-02-21 18:06:13.546697: Pseudo dice [0.9788] 
2025-02-21 18:06:13.546739: Epoch time: 32.41 s 
2025-02-21 18:06:14.268771:  
2025-02-21 18:06:14.268976: Epoch 456 
2025-02-21 18:06:14.269054: Current learning rate: 0.00578 
2025-02-21 18:06:47.755663: train_loss -0.9416 
2025-02-21 18:06:47.756105: val_loss -0.9526 
2025-02-21 18:06:47.756185: Pseudo dice [0.9824] 
2025-02-21 18:06:47.756261: Epoch time: 33.49 s 
2025-02-21 18:06:48.592762:  
2025-02-21 18:06:48.592964: Epoch 457 
2025-02-21 18:06:48.593044: Current learning rate: 0.00577 
2025-02-21 18:07:20.933217: train_loss -0.9303 
2025-02-21 18:07:20.933611: val_loss -0.9544 
2025-02-21 18:07:20.933666: Pseudo dice [0.9822] 
2025-02-21 18:07:20.933707: Epoch time: 32.34 s 
2025-02-21 18:07:22.307995:  
2025-02-21 18:07:22.308197: Epoch 458 
2025-02-21 18:07:22.308266: Current learning rate: 0.00576 
2025-02-21 18:07:54.734639: train_loss -0.9295 
2025-02-21 18:07:54.735196: val_loss -0.9508 
2025-02-21 18:07:54.735243: Pseudo dice [0.9811] 
2025-02-21 18:07:54.735284: Epoch time: 32.43 s 
2025-02-21 18:07:55.419074:  
2025-02-21 18:07:55.419231: Epoch 459 
2025-02-21 18:07:55.419323: Current learning rate: 0.00575 
2025-02-21 18:08:26.949335: train_loss -0.9467 
2025-02-21 18:08:26.949488: val_loss -0.957 
2025-02-21 18:08:26.949529: Pseudo dice [0.9832] 
2025-02-21 18:08:26.949569: Epoch time: 31.53 s 
2025-02-21 18:08:27.631415:  
2025-02-21 18:08:27.631598: Epoch 460 
2025-02-21 18:08:27.631642: Current learning rate: 0.00574 
2025-02-21 18:08:59.227195: train_loss -0.9333 
2025-02-21 18:08:59.227361: val_loss -0.9543 
2025-02-21 18:08:59.227415: Pseudo dice [0.9822] 
2025-02-21 18:08:59.227457: Epoch time: 31.6 s 
2025-02-21 18:08:59.921897:  
2025-02-21 18:08:59.922116: Epoch 461 
2025-02-21 18:08:59.922165: Current learning rate: 0.00573 
2025-02-21 18:09:31.296188: train_loss -0.9284 
2025-02-21 18:09:31.296337: val_loss -0.9442 
2025-02-21 18:09:31.296376: Pseudo dice [0.9779] 
2025-02-21 18:09:31.296416: Epoch time: 31.37 s 
2025-02-21 18:09:31.972517:  
2025-02-21 18:09:31.972692: Epoch 462 
2025-02-21 18:09:31.972736: Current learning rate: 0.00572 
2025-02-21 18:10:03.455874: train_loss -0.9239 
2025-02-21 18:10:03.456072: val_loss -0.9296 
2025-02-21 18:10:03.456112: Pseudo dice [0.9731] 
2025-02-21 18:10:03.456193: Epoch time: 31.48 s 
2025-02-21 18:10:04.157875:  
2025-02-21 18:10:04.158168: Epoch 463 
2025-02-21 18:10:04.158231: Current learning rate: 0.00571 
2025-02-21 18:10:35.666785: train_loss -0.9315 
2025-02-21 18:10:35.666922: val_loss -0.9545 
2025-02-21 18:10:35.667011: Pseudo dice [0.9833] 
2025-02-21 18:10:35.667049: Epoch time: 31.51 s 
2025-02-21 18:10:36.346380:  
2025-02-21 18:10:36.346548: Epoch 464 
2025-02-21 18:10:36.346636: Current learning rate: 0.0057 
2025-02-21 18:11:07.668383: train_loss -0.9274 
2025-02-21 18:11:07.668516: val_loss -0.941 
2025-02-21 18:11:07.668562: Pseudo dice [0.9787] 
2025-02-21 18:11:07.668599: Epoch time: 31.32 s 
2025-02-21 18:11:08.347031:  
2025-02-21 18:11:08.347190: Epoch 465 
2025-02-21 18:11:08.347279: Current learning rate: 0.0057 
2025-02-21 18:11:39.927958: train_loss -0.9292 
2025-02-21 18:11:39.928105: val_loss -0.9631 
2025-02-21 18:11:39.928145: Pseudo dice [0.9851] 
2025-02-21 18:11:39.928185: Epoch time: 31.58 s 
2025-02-21 18:11:40.611305:  
2025-02-21 18:11:40.611506: Epoch 466 
2025-02-21 18:11:40.611552: Current learning rate: 0.00569 
2025-02-21 18:12:12.028578: train_loss -0.9482 
2025-02-21 18:12:12.028723: val_loss -0.9591 
2025-02-21 18:12:12.028759: Pseudo dice [0.9844] 
2025-02-21 18:12:12.028796: Epoch time: 31.42 s 
2025-02-21 18:12:12.719293:  
2025-02-21 18:12:12.719449: Epoch 467 
2025-02-21 18:12:12.719503: Current learning rate: 0.00568 
2025-02-21 18:12:44.119436: train_loss -0.9353 
2025-02-21 18:12:44.119622: val_loss -0.9548 
2025-02-21 18:12:44.119678: Pseudo dice [0.9824] 
2025-02-21 18:12:44.119718: Epoch time: 31.4 s 
2025-02-21 18:12:44.895064:  
2025-02-21 18:12:44.895270: Epoch 468 
2025-02-21 18:12:44.895380: Current learning rate: 0.00567 
2025-02-21 18:13:16.485324: train_loss -0.9284 
2025-02-21 18:13:16.485452: val_loss -0.9567 
2025-02-21 18:13:16.485491: Pseudo dice [0.9826] 
2025-02-21 18:13:16.485528: Epoch time: 31.59 s 
2025-02-21 18:13:17.214392:  
2025-02-21 18:13:17.214584: Epoch 469 
2025-02-21 18:13:17.214678: Current learning rate: 0.00566 
2025-02-21 18:13:48.562051: train_loss -0.9263 
2025-02-21 18:13:48.562197: val_loss -0.9339 
2025-02-21 18:13:48.562234: Pseudo dice [0.9732] 
2025-02-21 18:13:48.562272: Epoch time: 31.35 s 
2025-02-21 18:13:49.246681:  
2025-02-21 18:13:49.246867: Epoch 470 
2025-02-21 18:13:49.246922: Current learning rate: 0.00565 
2025-02-21 18:14:21.141112: train_loss -0.9154 
2025-02-21 18:14:21.141407: val_loss -0.9259 
2025-02-21 18:14:21.141452: Pseudo dice [0.9737] 
2025-02-21 18:14:21.141494: Epoch time: 31.9 s 
2025-02-21 18:14:21.944846:  
2025-02-21 18:14:21.945132: Epoch 471 
2025-02-21 18:14:21.945266: Current learning rate: 0.00564 
2025-02-21 18:14:53.452040: train_loss -0.9253 
2025-02-21 18:14:53.452190: val_loss -0.947 
2025-02-21 18:14:53.452234: Pseudo dice [0.9808] 
2025-02-21 18:14:53.452275: Epoch time: 31.51 s 
2025-02-21 18:14:54.258490:  
2025-02-21 18:14:54.258662: Epoch 472 
2025-02-21 18:14:54.258743: Current learning rate: 0.00563 
2025-02-21 18:15:25.809614: train_loss -0.9355 
2025-02-21 18:15:25.809767: val_loss -0.9474 
2025-02-21 18:15:25.809814: Pseudo dice [0.9802] 
2025-02-21 18:15:25.809858: Epoch time: 31.55 s 
2025-02-21 18:15:26.605626:  
2025-02-21 18:15:26.605796: Epoch 473 
2025-02-21 18:15:26.605911: Current learning rate: 0.00562 
2025-02-21 18:15:58.156565: train_loss -0.9315 
2025-02-21 18:15:58.156723: val_loss -0.9486 
2025-02-21 18:15:58.156764: Pseudo dice [0.98] 
2025-02-21 18:15:58.156803: Epoch time: 31.55 s 
2025-02-21 18:15:58.966585:  
2025-02-21 18:15:58.966715: Epoch 474 
2025-02-21 18:15:58.966789: Current learning rate: 0.00561 
2025-02-21 18:16:31.010947: train_loss -0.9391 
2025-02-21 18:16:31.011081: val_loss -0.9585 
2025-02-21 18:16:31.011118: Pseudo dice [0.9839] 
2025-02-21 18:16:31.011155: Epoch time: 32.05 s 
2025-02-21 18:16:31.695554:  
2025-02-21 18:16:31.695744: Epoch 475 
2025-02-21 18:16:31.695823: Current learning rate: 0.0056 
2025-02-21 18:17:03.569066: train_loss -0.9425 
2025-02-21 18:17:03.569223: val_loss -0.9548 
2025-02-21 18:17:03.569264: Pseudo dice [0.982] 
2025-02-21 18:17:03.569304: Epoch time: 31.87 s 
2025-02-21 18:17:04.858298:  
2025-02-21 18:17:04.858492: Epoch 476 
2025-02-21 18:17:04.858589: Current learning rate: 0.00559 
2025-02-21 18:17:36.595274: train_loss -0.9387 
2025-02-21 18:17:36.595449: val_loss -0.9371 
2025-02-21 18:17:36.595491: Pseudo dice [0.9771] 
2025-02-21 18:17:36.595537: Epoch time: 31.74 s 
2025-02-21 18:17:37.283686:  
2025-02-21 18:17:37.283864: Epoch 477 
2025-02-21 18:17:37.283912: Current learning rate: 0.00558 
2025-02-21 18:18:08.816135: train_loss -0.913 
2025-02-21 18:18:08.816385: val_loss -0.9444 
2025-02-21 18:18:08.816459: Pseudo dice [0.9792] 
2025-02-21 18:18:08.816540: Epoch time: 31.53 s 
2025-02-21 18:18:09.631458:  
2025-02-21 18:18:09.631709: Epoch 478 
2025-02-21 18:18:09.631826: Current learning rate: 0.00557 
2025-02-21 18:18:41.466925: train_loss -0.9256 
2025-02-21 18:18:41.467062: val_loss -0.9413 
2025-02-21 18:18:41.467100: Pseudo dice [0.9781] 
2025-02-21 18:18:41.467148: Epoch time: 31.84 s 
2025-02-21 18:18:42.161577:  
2025-02-21 18:18:42.161783: Epoch 479 
2025-02-21 18:18:42.161869: Current learning rate: 0.00556 
2025-02-21 18:19:14.019723: train_loss -0.934 
2025-02-21 18:19:14.020073: val_loss -0.9546 
2025-02-21 18:19:14.020202: Pseudo dice [0.9832] 
2025-02-21 18:19:14.020319: Epoch time: 31.86 s 
2025-02-21 18:19:14.928345:  
2025-02-21 18:19:14.928541: Epoch 480 
2025-02-21 18:19:14.928610: Current learning rate: 0.00555 
2025-02-21 18:19:46.477981: train_loss -0.9348 
2025-02-21 18:19:46.478229: val_loss -0.9441 
2025-02-21 18:19:46.478289: Pseudo dice [0.9805] 
2025-02-21 18:19:46.478344: Epoch time: 31.55 s 
2025-02-21 18:19:47.329432:  
2025-02-21 18:19:47.329648: Epoch 481 
2025-02-21 18:19:47.329722: Current learning rate: 0.00554 
2025-02-21 18:20:19.091204: train_loss -0.944 
2025-02-21 18:20:19.091336: val_loss -0.9471 
2025-02-21 18:20:19.091379: Pseudo dice [0.9789] 
2025-02-21 18:20:19.091419: Epoch time: 31.76 s 
2025-02-21 18:20:19.795602:  
2025-02-21 18:20:19.795785: Epoch 482 
2025-02-21 18:20:19.795867: Current learning rate: 0.00553 
2025-02-21 18:20:51.955859: train_loss -0.9318 
2025-02-21 18:20:51.956209: val_loss -0.957 
2025-02-21 18:20:51.956296: Pseudo dice [0.9824] 
2025-02-21 18:20:51.956340: Epoch time: 32.16 s 
2025-02-21 18:20:52.667151:  
2025-02-21 18:20:52.667360: Epoch 483 
2025-02-21 18:20:52.667436: Current learning rate: 0.00552 
2025-02-21 18:21:24.325251: train_loss -0.9153 
2025-02-21 18:21:24.325400: val_loss -0.9359 
2025-02-21 18:21:24.325521: Pseudo dice [0.9748] 
2025-02-21 18:21:24.325566: Epoch time: 31.66 s 
2025-02-21 18:21:25.198866:  
2025-02-21 18:21:25.199113: Epoch 484 
2025-02-21 18:21:25.199245: Current learning rate: 0.00551 
2025-02-21 18:21:57.060323: train_loss -0.9402 
2025-02-21 18:21:57.060474: val_loss -0.9282 
2025-02-21 18:21:57.060517: Pseudo dice [0.9749] 
2025-02-21 18:21:57.060554: Epoch time: 31.86 s 
2025-02-21 18:21:57.763542:  
2025-02-21 18:21:57.763762: Epoch 485 
2025-02-21 18:21:57.763860: Current learning rate: 0.0055 
2025-02-21 18:22:29.462758: train_loss -0.93 
2025-02-21 18:22:29.462893: val_loss -0.9569 
2025-02-21 18:22:29.462930: Pseudo dice [0.9838] 
2025-02-21 18:22:29.462968: Epoch time: 31.7 s 
2025-02-21 18:22:30.167759:  
2025-02-21 18:22:30.167981: Epoch 486 
2025-02-21 18:22:30.168056: Current learning rate: 0.00549 
2025-02-21 18:23:02.446549: train_loss -0.9125 
2025-02-21 18:23:02.446755: val_loss -0.9434 
2025-02-21 18:23:02.446834: Pseudo dice [0.9793] 
2025-02-21 18:23:02.446894: Epoch time: 32.28 s 
2025-02-21 18:23:03.427705:  
2025-02-21 18:23:03.427882: Epoch 487 
2025-02-21 18:23:03.427967: Current learning rate: 0.00548 
2025-02-21 18:23:35.554061: train_loss -0.9213 
2025-02-21 18:23:35.554242: val_loss -0.9513 
2025-02-21 18:23:35.554319: Pseudo dice [0.9826] 
2025-02-21 18:23:35.554366: Epoch time: 32.13 s 
2025-02-21 18:23:36.249709:  
2025-02-21 18:23:36.249873: Epoch 488 
2025-02-21 18:23:36.249963: Current learning rate: 0.00547 
2025-02-21 18:24:08.727119: train_loss -0.9428 
2025-02-21 18:24:08.727414: val_loss -0.9489 
2025-02-21 18:24:08.727482: Pseudo dice [0.9807] 
2025-02-21 18:24:08.727555: Epoch time: 32.48 s 
2025-02-21 18:24:09.568647:  
2025-02-21 18:24:09.568808: Epoch 489 
2025-02-21 18:24:09.568933: Current learning rate: 0.00546 
2025-02-21 18:24:41.431873: train_loss -0.947 
2025-02-21 18:24:41.432004: val_loss -0.9511 
2025-02-21 18:24:41.432043: Pseudo dice [0.9814] 
2025-02-21 18:24:41.432080: Epoch time: 31.86 s 
2025-02-21 18:24:42.132099:  
2025-02-21 18:24:42.132274: Epoch 490 
2025-02-21 18:24:42.132327: Current learning rate: 0.00546 
2025-02-21 18:25:14.329942: train_loss -0.9308 
2025-02-21 18:25:14.330298: val_loss -0.9455 
2025-02-21 18:25:14.330343: Pseudo dice [0.9788] 
2025-02-21 18:25:14.330384: Epoch time: 32.2 s 
2025-02-21 18:25:15.031208:  
2025-02-21 18:25:15.031358: Epoch 491 
2025-02-21 18:25:15.031432: Current learning rate: 0.00545 
2025-02-21 18:25:47.087524: train_loss -0.9309 
2025-02-21 18:25:47.087901: val_loss -0.9379 
2025-02-21 18:25:47.087944: Pseudo dice [0.975] 
2025-02-21 18:25:47.087981: Epoch time: 32.06 s 
2025-02-21 18:25:47.862930:  
2025-02-21 18:25:47.863100: Epoch 492 
2025-02-21 18:25:47.863172: Current learning rate: 0.00544 
2025-02-21 18:26:19.613849: train_loss -0.9433 
2025-02-21 18:26:19.614017: val_loss -0.9377 
2025-02-21 18:26:19.614060: Pseudo dice [0.9784] 
2025-02-21 18:26:19.614101: Epoch time: 31.75 s 
2025-02-21 18:26:20.328536:  
2025-02-21 18:26:20.328716: Epoch 493 
2025-02-21 18:26:20.328811: Current learning rate: 0.00543 
2025-02-21 18:26:52.529025: train_loss -0.9275 
2025-02-21 18:26:52.529410: val_loss -0.9493 
2025-02-21 18:26:52.529451: Pseudo dice [0.981] 
2025-02-21 18:26:52.529490: Epoch time: 32.2 s 
2025-02-21 18:26:53.886309:  
2025-02-21 18:26:53.886523: Epoch 494 
2025-02-21 18:26:53.886606: Current learning rate: 0.00542 
2025-02-21 18:27:25.713095: train_loss -0.9341 
2025-02-21 18:27:25.713481: val_loss -0.9512 
2025-02-21 18:27:25.713577: Pseudo dice [0.9808] 
2025-02-21 18:27:25.713682: Epoch time: 31.83 s 
2025-02-21 18:27:26.675010:  
2025-02-21 18:27:26.675246: Epoch 495 
2025-02-21 18:27:26.675363: Current learning rate: 0.00541 
2025-02-21 18:27:59.060395: train_loss -0.9476 
2025-02-21 18:27:59.060910: val_loss -0.947 
2025-02-21 18:27:59.061134: Pseudo dice [0.9797] 
2025-02-21 18:27:59.061379: Epoch time: 32.39 s 
2025-02-21 18:27:59.910148:  
2025-02-21 18:27:59.910388: Epoch 496 
2025-02-21 18:27:59.910462: Current learning rate: 0.0054 
2025-02-21 18:28:32.037160: train_loss -0.938 
2025-02-21 18:28:32.037384: val_loss -0.9239 
2025-02-21 18:28:32.037440: Pseudo dice [0.9736] 
2025-02-21 18:28:32.037482: Epoch time: 32.13 s 
2025-02-21 18:28:32.740318:  
2025-02-21 18:28:32.740485: Epoch 497 
2025-02-21 18:28:32.740548: Current learning rate: 0.00539 
2025-02-21 18:29:04.836509: train_loss -0.94 
2025-02-21 18:29:04.836671: val_loss -0.9417 
2025-02-21 18:29:04.836717: Pseudo dice [0.9794] 
2025-02-21 18:29:04.836756: Epoch time: 32.1 s 
2025-02-21 18:29:05.530615:  
2025-02-21 18:29:05.530743: Epoch 498 
2025-02-21 18:29:05.530864: Current learning rate: 0.00538 
2025-02-21 18:29:37.741947: train_loss -0.9282 
2025-02-21 18:29:37.742124: val_loss -0.9587 
2025-02-21 18:29:37.742165: Pseudo dice [0.9838] 
2025-02-21 18:29:37.742207: Epoch time: 32.21 s 
2025-02-21 18:29:38.447994:  
2025-02-21 18:29:38.448213: Epoch 499 
2025-02-21 18:29:38.448316: Current learning rate: 0.00537 
2025-02-21 18:30:11.031265: train_loss -0.9437 
2025-02-21 18:30:11.031544: val_loss -0.9593 
2025-02-21 18:30:11.031592: Pseudo dice [0.9841] 
2025-02-21 18:30:11.031649: Epoch time: 32.58 s 
2025-02-21 18:30:12.219693:  
2025-02-21 18:30:12.219876: Epoch 500 
2025-02-21 18:30:12.219957: Current learning rate: 0.00536 
2025-02-21 18:30:44.590351: train_loss -0.9345 
2025-02-21 18:30:44.590638: val_loss -0.9442 
2025-02-21 18:30:44.590680: Pseudo dice [0.9788] 
2025-02-21 18:30:44.590719: Epoch time: 32.37 s 
2025-02-21 18:30:45.389467:  
2025-02-21 18:30:45.389740: Epoch 501 
2025-02-21 18:30:45.389829: Current learning rate: 0.00535 
2025-02-21 18:31:17.481704: train_loss -0.933 
2025-02-21 18:31:17.481843: val_loss -0.9589 
2025-02-21 18:31:17.481885: Pseudo dice [0.9829] 
2025-02-21 18:31:17.481924: Epoch time: 32.09 s 
2025-02-21 18:31:18.176342:  
2025-02-21 18:31:18.176504: Epoch 502 
2025-02-21 18:31:18.176550: Current learning rate: 0.00534 
2025-02-21 18:31:50.662834: train_loss -0.9169 
2025-02-21 18:31:50.663331: val_loss -0.9535 
2025-02-21 18:31:50.663531: Pseudo dice [0.9802] 
2025-02-21 18:31:50.663740: Epoch time: 32.49 s 
2025-02-21 18:31:51.654192:  
2025-02-21 18:31:51.654328: Epoch 503 
2025-02-21 18:31:51.654421: Current learning rate: 0.00533 
2025-02-21 18:32:24.836732: train_loss -0.9295 
2025-02-21 18:32:24.837080: val_loss -0.9413 
2025-02-21 18:32:24.837121: Pseudo dice [0.9794] 
2025-02-21 18:32:24.837160: Epoch time: 33.18 s 
2025-02-21 18:32:25.609664:  
2025-02-21 18:32:25.609865: Epoch 504 
2025-02-21 18:32:25.609986: Current learning rate: 0.00532 
2025-02-21 18:32:59.047541: train_loss -0.9375 
2025-02-21 18:32:59.047995: val_loss -0.9576 
2025-02-21 18:32:59.048047: Pseudo dice [0.9829] 
2025-02-21 18:32:59.048097: Epoch time: 33.44 s 
2025-02-21 18:32:59.848605:  
2025-02-21 18:32:59.848758: Epoch 505 
2025-02-21 18:32:59.848838: Current learning rate: 0.00531 
2025-02-21 18:33:32.018096: train_loss -0.9174 
2025-02-21 18:33:32.018318: val_loss -0.9478 
2025-02-21 18:33:32.018362: Pseudo dice [0.9833] 
2025-02-21 18:33:32.018403: Epoch time: 32.17 s 
2025-02-21 18:33:32.724747:  
2025-02-21 18:33:32.724925: Epoch 506 
2025-02-21 18:33:32.725006: Current learning rate: 0.0053 
2025-02-21 18:34:05.345382: train_loss -0.9449 
2025-02-21 18:34:05.345656: val_loss -0.9503 
2025-02-21 18:34:05.345696: Pseudo dice [0.9812] 
2025-02-21 18:34:05.345734: Epoch time: 32.62 s 
2025-02-21 18:34:06.059244:  
2025-02-21 18:34:06.059436: Epoch 507 
2025-02-21 18:34:06.059510: Current learning rate: 0.00529 
2025-02-21 18:34:39.063123: train_loss -0.9369 
2025-02-21 18:34:39.063425: val_loss -0.9282 
2025-02-21 18:34:39.063467: Pseudo dice [0.9692] 
2025-02-21 18:34:39.063506: Epoch time: 33.0 s 
2025-02-21 18:34:39.948936:  
2025-02-21 18:34:39.949111: Epoch 508 
2025-02-21 18:34:39.949184: Current learning rate: 0.00528 
2025-02-21 18:35:12.556787: train_loss -0.9354 
2025-02-21 18:35:12.556999: val_loss -0.9511 
2025-02-21 18:35:12.557048: Pseudo dice [0.9792] 
2025-02-21 18:35:12.557089: Epoch time: 32.61 s 
2025-02-21 18:35:13.269886:  
2025-02-21 18:35:13.270069: Epoch 509 
2025-02-21 18:35:13.270138: Current learning rate: 0.00527 
2025-02-21 18:35:46.275727: train_loss -0.9288 
2025-02-21 18:35:46.276201: val_loss -0.9479 
2025-02-21 18:35:46.276272: Pseudo dice [0.9805] 
2025-02-21 18:35:46.276334: Epoch time: 33.01 s 
2025-02-21 18:35:47.217780:  
2025-02-21 18:35:47.217908: Epoch 510 
2025-02-21 18:35:47.217983: Current learning rate: 0.00526 
2025-02-21 18:36:19.254654: train_loss -0.938 
2025-02-21 18:36:19.254992: val_loss -0.9421 
2025-02-21 18:36:19.255040: Pseudo dice [0.9771] 
2025-02-21 18:36:19.255081: Epoch time: 32.04 s 
2025-02-21 18:36:19.985670:  
2025-02-21 18:36:19.985781: Epoch 511 
2025-02-21 18:36:19.985862: Current learning rate: 0.00525 
2025-02-21 18:36:53.556754: train_loss -0.9243 
2025-02-21 18:36:53.557653: val_loss -0.9489 
2025-02-21 18:36:53.557738: Pseudo dice [0.9796] 
2025-02-21 18:36:53.557793: Epoch time: 33.57 s 
2025-02-21 18:36:55.144053:  
2025-02-21 18:36:55.144290: Epoch 512 
2025-02-21 18:36:55.144406: Current learning rate: 0.00524 
2025-02-21 18:37:27.074213: train_loss -0.929 
2025-02-21 18:37:27.074569: val_loss -0.9563 
2025-02-21 18:37:27.074621: Pseudo dice [0.9835] 
2025-02-21 18:37:27.074666: Epoch time: 31.93 s 
2025-02-21 18:37:27.780125:  
2025-02-21 18:37:27.780299: Epoch 513 
2025-02-21 18:37:27.780372: Current learning rate: 0.00523 
2025-02-21 18:38:00.500656: train_loss -0.934 
2025-02-21 18:38:00.500814: val_loss -0.9412 
2025-02-21 18:38:00.500859: Pseudo dice [0.9771] 
2025-02-21 18:38:00.500898: Epoch time: 32.72 s 
2025-02-21 18:38:01.207835:  
2025-02-21 18:38:01.208027: Epoch 514 
2025-02-21 18:38:01.208078: Current learning rate: 0.00522 
2025-02-21 18:38:35.616838: train_loss -0.9326 
2025-02-21 18:38:35.617200: val_loss -0.947 
2025-02-21 18:38:35.617250: Pseudo dice [0.9802] 
2025-02-21 18:38:35.617302: Epoch time: 34.41 s 
2025-02-21 18:38:36.495281:  
2025-02-21 18:38:36.495459: Epoch 515 
2025-02-21 18:38:36.495536: Current learning rate: 0.00521 
2025-02-21 18:39:09.279623: train_loss -0.9255 
2025-02-21 18:39:09.279900: val_loss -0.9476 
2025-02-21 18:39:09.279948: Pseudo dice [0.9789] 
2025-02-21 18:39:09.279989: Epoch time: 32.79 s 
2025-02-21 18:39:09.993464:  
2025-02-21 18:39:09.993664: Epoch 516 
2025-02-21 18:39:09.993741: Current learning rate: 0.0052 
2025-02-21 18:39:41.383376: train_loss -0.9449 
2025-02-21 18:39:41.383502: val_loss -0.9542 
2025-02-21 18:39:41.383536: Pseudo dice [0.9823] 
2025-02-21 18:39:41.383570: Epoch time: 31.39 s 
2025-02-21 18:39:42.074073:  
2025-02-21 18:39:42.074226: Epoch 517 
2025-02-21 18:39:42.074297: Current learning rate: 0.00519 
2025-02-21 18:40:13.542854: train_loss -0.9475 
2025-02-21 18:40:13.542982: val_loss -0.9544 
2025-02-21 18:40:13.543019: Pseudo dice [0.9821] 
2025-02-21 18:40:13.543055: Epoch time: 31.47 s 
2025-02-21 18:40:14.250181:  
2025-02-21 18:40:14.250410: Epoch 518 
2025-02-21 18:40:14.250487: Current learning rate: 0.00518 
2025-02-21 18:40:45.715434: train_loss -0.9391 
2025-02-21 18:40:45.715560: val_loss -0.9504 
2025-02-21 18:40:45.715598: Pseudo dice [0.9813] 
2025-02-21 18:40:45.715635: Epoch time: 31.47 s 
2025-02-21 18:40:46.409631:  
2025-02-21 18:40:46.409842: Epoch 519 
2025-02-21 18:40:46.409904: Current learning rate: 0.00518 
2025-02-21 18:41:18.006022: train_loss -0.9499 
2025-02-21 18:41:18.006197: val_loss -0.9417 
2025-02-21 18:41:18.006241: Pseudo dice [0.9776] 
2025-02-21 18:41:18.006283: Epoch time: 31.6 s 
2025-02-21 18:41:18.708982:  
2025-02-21 18:41:18.709224: Epoch 520 
2025-02-21 18:41:18.709307: Current learning rate: 0.00517 
2025-02-21 18:41:50.148918: train_loss -0.9448 
2025-02-21 18:41:50.149107: val_loss -0.9496 
2025-02-21 18:41:50.149150: Pseudo dice [0.9801] 
2025-02-21 18:41:50.149196: Epoch time: 31.44 s 
2025-02-21 18:41:50.853784:  
2025-02-21 18:41:50.853995: Epoch 521 
2025-02-21 18:41:50.854071: Current learning rate: 0.00516 
2025-02-21 18:42:22.202066: train_loss -0.935 
2025-02-21 18:42:22.202199: val_loss -0.9548 
2025-02-21 18:42:22.202237: Pseudo dice [0.9844] 
2025-02-21 18:42:22.202275: Epoch time: 31.35 s 
2025-02-21 18:42:22.905930:  
2025-02-21 18:42:22.906139: Epoch 522 
2025-02-21 18:42:22.906238: Current learning rate: 0.00515 
2025-02-21 18:42:54.280303: train_loss -0.9399 
2025-02-21 18:42:54.280451: val_loss -0.9542 
2025-02-21 18:42:54.280489: Pseudo dice [0.9825] 
2025-02-21 18:42:54.280528: Epoch time: 31.38 s 
2025-02-21 18:42:54.982658:  
2025-02-21 18:42:54.982857: Epoch 523 
2025-02-21 18:42:54.982937: Current learning rate: 0.00514 
2025-02-21 18:43:26.570149: train_loss -0.9293 
2025-02-21 18:43:26.570298: val_loss -0.9408 
2025-02-21 18:43:26.570339: Pseudo dice [0.976] 
2025-02-21 18:43:26.570378: Epoch time: 31.59 s 
2025-02-21 18:43:27.265066:  
2025-02-21 18:43:27.265294: Epoch 524 
2025-02-21 18:43:27.265378: Current learning rate: 0.00513 
2025-02-21 18:43:58.660623: train_loss -0.9315 
2025-02-21 18:43:58.660900: val_loss -0.948 
2025-02-21 18:43:58.660945: Pseudo dice [0.9805] 
2025-02-21 18:43:58.660984: Epoch time: 31.4 s 
2025-02-21 18:43:59.360380:  
2025-02-21 18:43:59.360548: Epoch 525 
2025-02-21 18:43:59.360602: Current learning rate: 0.00512 
2025-02-21 18:44:30.775753: train_loss -0.9386 
2025-02-21 18:44:30.775886: val_loss -0.951 
2025-02-21 18:44:30.775953: Pseudo dice [0.9845] 
2025-02-21 18:44:30.775991: Epoch time: 31.42 s 
2025-02-21 18:44:31.485554:  
2025-02-21 18:44:31.485789: Epoch 526 
2025-02-21 18:44:31.485934: Current learning rate: 0.00511 
2025-02-21 18:45:02.971640: train_loss -0.9444 
2025-02-21 18:45:02.971783: val_loss -0.956 
2025-02-21 18:45:02.971825: Pseudo dice [0.9813] 
2025-02-21 18:45:02.971864: Epoch time: 31.49 s 
2025-02-21 18:45:03.665622:  
2025-02-21 18:45:03.665786: Epoch 527 
2025-02-21 18:45:03.665853: Current learning rate: 0.0051 
2025-02-21 18:45:35.020952: train_loss -0.936 
2025-02-21 18:45:35.021118: val_loss -0.9424 
2025-02-21 18:45:35.021192: Pseudo dice [0.9775] 
2025-02-21 18:45:35.021248: Epoch time: 31.36 s 
2025-02-21 18:45:35.719772:  
2025-02-21 18:45:35.720049: Epoch 528 
2025-02-21 18:45:35.720183: Current learning rate: 0.00509 
2025-02-21 18:46:07.340132: train_loss -0.9253 
2025-02-21 18:46:07.340312: val_loss -0.9569 
2025-02-21 18:46:07.340348: Pseudo dice [0.9845] 
2025-02-21 18:46:07.340382: Epoch time: 31.62 s 
2025-02-21 18:46:08.045602:  
2025-02-21 18:46:08.045799: Epoch 529 
2025-02-21 18:46:08.045886: Current learning rate: 0.00508 
2025-02-21 18:46:39.589132: train_loss -0.929 
2025-02-21 18:46:39.589290: val_loss -0.9446 
2025-02-21 18:46:39.589366: Pseudo dice [0.9793] 
2025-02-21 18:46:39.589409: Epoch time: 31.54 s 
2025-02-21 18:46:40.939137:  
2025-02-21 18:46:40.939354: Epoch 530 
2025-02-21 18:46:40.939432: Current learning rate: 0.00507 
2025-02-21 18:47:12.455542: train_loss -0.9151 
2025-02-21 18:47:12.455688: val_loss -0.9301 
2025-02-21 18:47:12.455724: Pseudo dice [0.9775] 
2025-02-21 18:47:12.455762: Epoch time: 31.52 s 
2025-02-21 18:47:13.161413:  
2025-02-21 18:47:13.161611: Epoch 531 
2025-02-21 18:47:13.161671: Current learning rate: 0.00506 
2025-02-21 18:47:44.753141: train_loss -0.9261 
2025-02-21 18:47:44.753283: val_loss -0.952 
2025-02-21 18:47:44.753322: Pseudo dice [0.9825] 
2025-02-21 18:47:44.753362: Epoch time: 31.59 s 
2025-02-21 18:47:45.460226:  
2025-02-21 18:47:45.460440: Epoch 532 
2025-02-21 18:47:45.460516: Current learning rate: 0.00505 
2025-02-21 18:48:17.231264: train_loss -0.9236 
2025-02-21 18:48:17.231408: val_loss -0.9508 
2025-02-21 18:48:17.231448: Pseudo dice [0.9807] 
2025-02-21 18:48:17.231488: Epoch time: 31.77 s 
2025-02-21 18:48:17.933607:  
2025-02-21 18:48:17.933785: Epoch 533 
2025-02-21 18:48:17.933927: Current learning rate: 0.00504 
2025-02-21 18:48:49.335723: train_loss -0.9397 
2025-02-21 18:48:49.335890: val_loss -0.955 
2025-02-21 18:48:49.335928: Pseudo dice [0.983] 
2025-02-21 18:48:49.335964: Epoch time: 31.4 s 
2025-02-21 18:48:50.036716:  
2025-02-21 18:48:50.036923: Epoch 534 
2025-02-21 18:48:50.036985: Current learning rate: 0.00503 
2025-02-21 18:49:21.599443: train_loss -0.9278 
2025-02-21 18:49:21.599577: val_loss -0.9474 
2025-02-21 18:49:21.599621: Pseudo dice [0.9813] 
2025-02-21 18:49:21.599665: Epoch time: 31.56 s 
2025-02-21 18:49:22.300122:  
2025-02-21 18:49:22.300290: Epoch 535 
2025-02-21 18:49:22.300386: Current learning rate: 0.00502 
2025-02-21 18:49:53.868823: train_loss -0.9405 
2025-02-21 18:49:53.869075: val_loss -0.9551 
2025-02-21 18:49:53.869116: Pseudo dice [0.9832] 
2025-02-21 18:49:53.869159: Epoch time: 31.57 s 
2025-02-21 18:49:54.607115:  
2025-02-21 18:49:54.607285: Epoch 536 
2025-02-21 18:49:54.607373: Current learning rate: 0.00501 
2025-02-21 18:50:26.058121: train_loss -0.9386 
2025-02-21 18:50:26.058267: val_loss -0.9345 
2025-02-21 18:50:26.058307: Pseudo dice [0.9749] 
2025-02-21 18:50:26.058350: Epoch time: 31.45 s 
2025-02-21 18:50:26.757416:  
2025-02-21 18:50:26.757553: Epoch 537 
2025-02-21 18:50:26.757631: Current learning rate: 0.005 
2025-02-21 18:50:58.465812: train_loss -0.9432 
2025-02-21 18:50:58.465962: val_loss -0.9579 
2025-02-21 18:50:58.466003: Pseudo dice [0.9832] 
2025-02-21 18:50:58.466042: Epoch time: 31.71 s 
2025-02-21 18:50:59.178104:  
2025-02-21 18:50:59.178318: Epoch 538 
2025-02-21 18:50:59.178393: Current learning rate: 0.00499 
2025-02-21 18:51:30.584485: train_loss -0.9274 
2025-02-21 18:51:30.584638: val_loss -0.9478 
2025-02-21 18:51:30.584705: Pseudo dice [0.9802] 
2025-02-21 18:51:30.584746: Epoch time: 31.41 s 
2025-02-21 18:51:31.282752:  
2025-02-21 18:51:31.282932: Epoch 539 
2025-02-21 18:51:31.283004: Current learning rate: 0.00498 
2025-02-21 18:52:02.869611: train_loss -0.9244 
2025-02-21 18:52:02.869745: val_loss -0.9467 
2025-02-21 18:52:02.869784: Pseudo dice [0.9789] 
2025-02-21 18:52:02.869829: Epoch time: 31.59 s 
2025-02-21 18:52:03.590497:  
2025-02-21 18:52:03.590678: Epoch 540 
2025-02-21 18:52:03.590751: Current learning rate: 0.00497 
2025-02-21 18:52:35.114602: train_loss -0.9344 
2025-02-21 18:52:35.114747: val_loss -0.9569 
2025-02-21 18:52:35.114784: Pseudo dice [0.9834] 
2025-02-21 18:52:35.114831: Epoch time: 31.52 s 
2025-02-21 18:52:35.813773:  
2025-02-21 18:52:35.813959: Epoch 541 
2025-02-21 18:52:35.814046: Current learning rate: 0.00496 
2025-02-21 18:53:07.269400: train_loss -0.9413 
2025-02-21 18:53:07.269534: val_loss -0.9454 
2025-02-21 18:53:07.269572: Pseudo dice [0.9787] 
2025-02-21 18:53:07.269611: Epoch time: 31.46 s 
2025-02-21 18:53:07.991614:  
2025-02-21 18:53:07.991827: Epoch 542 
2025-02-21 18:53:07.991912: Current learning rate: 0.00495 
2025-02-21 18:53:39.578393: train_loss -0.949 
2025-02-21 18:53:39.578530: val_loss -0.948 
2025-02-21 18:53:39.578568: Pseudo dice [0.9812] 
2025-02-21 18:53:39.578604: Epoch time: 31.59 s 
2025-02-21 18:53:40.282144:  
2025-02-21 18:53:40.282309: Epoch 543 
2025-02-21 18:53:40.282417: Current learning rate: 0.00494 
2025-02-21 18:54:11.812092: train_loss -0.9319 
2025-02-21 18:54:11.812256: val_loss -0.9539 
2025-02-21 18:54:11.812331: Pseudo dice [0.9838] 
2025-02-21 18:54:11.812375: Epoch time: 31.53 s 
2025-02-21 18:54:12.517983:  
2025-02-21 18:54:12.518180: Epoch 544 
2025-02-21 18:54:12.518257: Current learning rate: 0.00493 
2025-02-21 18:54:44.030246: train_loss -0.9388 
2025-02-21 18:54:44.030389: val_loss -0.954 
2025-02-21 18:54:44.030430: Pseudo dice [0.9825] 
2025-02-21 18:54:44.030470: Epoch time: 31.51 s 
2025-02-21 18:54:44.738344:  
2025-02-21 18:54:44.738550: Epoch 545 
2025-02-21 18:54:44.738626: Current learning rate: 0.00492 
2025-02-21 18:55:16.344755: train_loss -0.9477 
2025-02-21 18:55:16.344899: val_loss -0.9467 
2025-02-21 18:55:16.344938: Pseudo dice [0.979] 
2025-02-21 18:55:16.344974: Epoch time: 31.61 s 
2025-02-21 18:55:17.047644:  
2025-02-21 18:55:17.047833: Epoch 546 
2025-02-21 18:55:17.047940: Current learning rate: 0.00491 
2025-02-21 18:55:48.661760: train_loss -0.9367 
2025-02-21 18:55:48.661986: val_loss -0.951 
2025-02-21 18:55:48.662030: Pseudo dice [0.9811] 
2025-02-21 18:55:48.662074: Epoch time: 31.61 s 
2025-02-21 18:55:49.376578:  
2025-02-21 18:55:49.376749: Epoch 547 
2025-02-21 18:55:49.376847: Current learning rate: 0.0049 
2025-02-21 18:56:20.847981: train_loss -0.9488 
2025-02-21 18:56:20.848118: val_loss -0.9466 
2025-02-21 18:56:20.848158: Pseudo dice [0.9792] 
2025-02-21 18:56:20.848195: Epoch time: 31.47 s 
2025-02-21 18:56:22.194797:  
2025-02-21 18:56:22.195038: Epoch 548 
2025-02-21 18:56:22.195127: Current learning rate: 0.00489 
2025-02-21 18:56:53.733984: train_loss -0.9393 
2025-02-21 18:56:53.734135: val_loss -0.9434 
2025-02-21 18:56:53.734174: Pseudo dice [0.9783] 
2025-02-21 18:56:53.734213: Epoch time: 31.54 s 
2025-02-21 18:56:54.444398:  
2025-02-21 18:56:54.444596: Epoch 549 
2025-02-21 18:56:54.444659: Current learning rate: 0.00488 
2025-02-21 18:57:26.079522: train_loss -0.9338 
2025-02-21 18:57:26.079700: val_loss -0.9474 
2025-02-21 18:57:26.079745: Pseudo dice [0.98] 
2025-02-21 18:57:26.079785: Epoch time: 31.64 s 
2025-02-21 18:57:27.141171:  
2025-02-21 18:57:27.141347: Epoch 550 
2025-02-21 18:57:27.141423: Current learning rate: 0.00487 
2025-02-21 18:57:58.601023: train_loss -0.931 
2025-02-21 18:57:58.601223: val_loss -0.9519 
2025-02-21 18:57:58.601265: Pseudo dice [0.9831] 
2025-02-21 18:57:58.601309: Epoch time: 31.46 s 
2025-02-21 18:57:59.308496:  
2025-02-21 18:57:59.308709: Epoch 551 
2025-02-21 18:57:59.308795: Current learning rate: 0.00486 
2025-02-21 18:58:31.021230: train_loss -0.9348 
2025-02-21 18:58:31.021363: val_loss -0.9514 
2025-02-21 18:58:31.021398: Pseudo dice [0.9806] 
2025-02-21 18:58:31.021451: Epoch time: 31.71 s 
2025-02-21 18:58:31.721491:  
2025-02-21 18:58:31.721648: Epoch 552 
2025-02-21 18:58:31.721722: Current learning rate: 0.00485 
2025-02-21 18:59:03.177989: train_loss -0.9448 
2025-02-21 18:59:03.178135: val_loss -0.9595 
2025-02-21 18:59:03.178175: Pseudo dice [0.9858] 
2025-02-21 18:59:03.178215: Epoch time: 31.46 s 
2025-02-21 18:59:03.886256:  
2025-02-21 18:59:03.886508: Epoch 553 
2025-02-21 18:59:03.886586: Current learning rate: 0.00484 
2025-02-21 18:59:35.452710: train_loss -0.9452 
2025-02-21 18:59:35.452919: val_loss -0.9513 
2025-02-21 18:59:35.452962: Pseudo dice [0.9813] 
2025-02-21 18:59:35.453008: Epoch time: 31.57 s 
2025-02-21 18:59:36.178708:  
2025-02-21 18:59:36.178928: Epoch 554 
2025-02-21 18:59:36.179024: Current learning rate: 0.00484 
2025-02-21 19:00:07.715998: train_loss -0.9293 
2025-02-21 19:00:07.716238: val_loss -0.9459 
2025-02-21 19:00:07.716281: Pseudo dice [0.9805] 
2025-02-21 19:00:07.716323: Epoch time: 31.54 s 
2025-02-21 19:00:08.416249:  
2025-02-21 19:00:08.416432: Epoch 555 
2025-02-21 19:00:08.416545: Current learning rate: 0.00483 
2025-02-21 19:00:40.195929: train_loss -0.942 
2025-02-21 19:00:40.196071: val_loss -0.961 
2025-02-21 19:00:40.196108: Pseudo dice [0.9829] 
2025-02-21 19:00:40.196145: Epoch time: 31.78 s 
2025-02-21 19:00:40.900705:  
2025-02-21 19:00:40.900872: Epoch 556 
2025-02-21 19:00:40.900944: Current learning rate: 0.00482 
2025-02-21 19:01:12.367694: train_loss -0.9458 
2025-02-21 19:01:12.367851: val_loss -0.9391 
2025-02-21 19:01:12.367894: Pseudo dice [0.9762] 
2025-02-21 19:01:12.367935: Epoch time: 31.47 s 
2025-02-21 19:01:13.070840:  
2025-02-21 19:01:13.071062: Epoch 557 
2025-02-21 19:01:13.071138: Current learning rate: 0.00481 
2025-02-21 19:01:44.541910: train_loss -0.9343 
2025-02-21 19:01:44.542051: val_loss -0.952 
2025-02-21 19:01:44.542087: Pseudo dice [0.9816] 
2025-02-21 19:01:44.542123: Epoch time: 31.47 s 
2025-02-21 19:01:45.245114:  
2025-02-21 19:01:45.245342: Epoch 558 
2025-02-21 19:01:45.245442: Current learning rate: 0.0048 
2025-02-21 19:02:16.863574: train_loss -0.9346 
2025-02-21 19:02:16.863735: val_loss -0.9557 
2025-02-21 19:02:16.863773: Pseudo dice [0.9824] 
2025-02-21 19:02:16.863817: Epoch time: 31.62 s 
2025-02-21 19:02:17.568312:  
2025-02-21 19:02:17.568521: Epoch 559 
2025-02-21 19:02:17.568592: Current learning rate: 0.00479 
2025-02-21 19:02:48.991636: train_loss -0.9449 
2025-02-21 19:02:48.991779: val_loss -0.9523 
2025-02-21 19:02:48.991822: Pseudo dice [0.9802] 
2025-02-21 19:02:48.991864: Epoch time: 31.42 s 
2025-02-21 19:02:49.696877:  
2025-02-21 19:02:49.697051: Epoch 560 
2025-02-21 19:02:49.697132: Current learning rate: 0.00478 
2025-02-21 19:03:21.404472: train_loss -0.9288 
2025-02-21 19:03:21.404628: val_loss -0.9527 
2025-02-21 19:03:21.404704: Pseudo dice [0.9827] 
2025-02-21 19:03:21.404746: Epoch time: 31.71 s 
2025-02-21 19:03:22.117570:  
2025-02-21 19:03:22.117735: Epoch 561 
2025-02-21 19:03:22.117816: Current learning rate: 0.00477 
2025-02-21 19:03:53.565006: train_loss -0.9385 
2025-02-21 19:03:53.565170: val_loss -0.9566 
2025-02-21 19:03:53.565210: Pseudo dice [0.9825] 
2025-02-21 19:03:53.565249: Epoch time: 31.45 s 
2025-02-21 19:03:54.263586:  
2025-02-21 19:03:54.263738: Epoch 562 
2025-02-21 19:03:54.263817: Current learning rate: 0.00476 
2025-02-21 19:04:25.703347: train_loss -0.9457 
2025-02-21 19:04:25.703565: val_loss -0.9537 
2025-02-21 19:04:25.703617: Pseudo dice [0.9829] 
2025-02-21 19:04:25.703665: Epoch time: 31.44 s 
2025-02-21 19:04:26.444992:  
2025-02-21 19:04:26.445146: Epoch 563 
2025-02-21 19:04:26.445237: Current learning rate: 0.00475 
2025-02-21 19:04:57.980584: train_loss -0.9132 
2025-02-21 19:04:57.980742: val_loss -0.9519 
2025-02-21 19:04:57.980803: Pseudo dice [0.9821] 
2025-02-21 19:04:57.980872: Epoch time: 31.54 s 
2025-02-21 19:04:58.690240:  
2025-02-21 19:04:58.690455: Epoch 564 
2025-02-21 19:04:58.690531: Current learning rate: 0.00474 
2025-02-21 19:05:30.087762: train_loss -0.9397 
2025-02-21 19:05:30.087940: val_loss -0.9628 
2025-02-21 19:05:30.087987: Pseudo dice [0.9859] 
2025-02-21 19:05:30.088030: Epoch time: 31.4 s 
2025-02-21 19:05:30.088060: Yayy! New best EMA pseudo Dice: 0.9819 
2025-02-21 19:05:31.772480:  
2025-02-21 19:05:31.772625: Epoch 565 
2025-02-21 19:05:31.772742: Current learning rate: 0.00473 
2025-02-21 19:06:03.694994: train_loss -0.9454 
2025-02-21 19:06:03.695239: val_loss -0.9296 
2025-02-21 19:06:03.695322: Pseudo dice [0.9757] 
2025-02-21 19:06:03.695370: Epoch time: 31.92 s 
2025-02-21 19:06:04.391783:  
2025-02-21 19:06:04.392000: Epoch 566 
2025-02-21 19:06:04.392079: Current learning rate: 0.00472 
2025-02-21 19:06:35.921937: train_loss -0.9367 
2025-02-21 19:06:35.922111: val_loss -0.9503 
2025-02-21 19:06:35.922152: Pseudo dice [0.9797] 
2025-02-21 19:06:35.922189: Epoch time: 31.53 s 
2025-02-21 19:06:36.633694:  
2025-02-21 19:06:36.633914: Epoch 567 
2025-02-21 19:06:36.633997: Current learning rate: 0.00471 
2025-02-21 19:07:08.128135: train_loss -0.9374 
2025-02-21 19:07:08.128272: val_loss -0.9406 
2025-02-21 19:07:08.128311: Pseudo dice [0.975] 
2025-02-21 19:07:08.128348: Epoch time: 31.5 s 
2025-02-21 19:07:08.832852:  
2025-02-21 19:07:08.833052: Epoch 568 
2025-02-21 19:07:08.833107: Current learning rate: 0.0047 
2025-02-21 19:07:40.355083: train_loss -0.9342 
2025-02-21 19:07:40.355220: val_loss -0.9363 
2025-02-21 19:07:40.355256: Pseudo dice [0.9762] 
2025-02-21 19:07:40.355293: Epoch time: 31.52 s 
2025-02-21 19:07:41.057214:  
2025-02-21 19:07:41.057384: Epoch 569 
2025-02-21 19:07:41.057461: Current learning rate: 0.00469 
2025-02-21 19:08:12.611824: train_loss -0.9404 
2025-02-21 19:08:12.611959: val_loss -0.9467 
2025-02-21 19:08:12.611996: Pseudo dice [0.9796] 
2025-02-21 19:08:12.612033: Epoch time: 31.56 s 
2025-02-21 19:08:13.315927:  
2025-02-21 19:08:13.316158: Epoch 570 
2025-02-21 19:08:13.316233: Current learning rate: 0.00468 
2025-02-21 19:08:44.862091: train_loss -0.9449 
2025-02-21 19:08:44.862229: val_loss -0.9535 
2025-02-21 19:08:44.862267: Pseudo dice [0.9824] 
2025-02-21 19:08:44.862307: Epoch time: 31.55 s 
2025-02-21 19:08:45.578679:  
2025-02-21 19:08:45.578878: Epoch 571 
2025-02-21 19:08:45.578962: Current learning rate: 0.00467 
2025-02-21 19:09:17.189416: train_loss -0.9413 
2025-02-21 19:09:17.189559: val_loss -0.9568 
2025-02-21 19:09:17.189597: Pseudo dice [0.9835] 
2025-02-21 19:09:17.189635: Epoch time: 31.61 s 
2025-02-21 19:09:17.892136:  
2025-02-21 19:09:17.892348: Epoch 572 
2025-02-21 19:09:17.892427: Current learning rate: 0.00466 
2025-02-21 19:09:49.481250: train_loss -0.9496 
2025-02-21 19:09:49.481397: val_loss -0.9567 
2025-02-21 19:09:49.481435: Pseudo dice [0.9839] 
2025-02-21 19:09:49.481472: Epoch time: 31.59 s 
2025-02-21 19:09:50.214266:  
2025-02-21 19:09:50.214455: Epoch 573 
2025-02-21 19:09:50.214561: Current learning rate: 0.00465 
2025-02-21 19:10:21.704070: train_loss -0.9315 
2025-02-21 19:10:21.704211: val_loss -0.9453 
2025-02-21 19:10:21.704248: Pseudo dice [0.9802] 
2025-02-21 19:10:21.704284: Epoch time: 31.49 s 
2025-02-21 19:10:22.417425:  
2025-02-21 19:10:22.417619: Epoch 574 
2025-02-21 19:10:22.417698: Current learning rate: 0.00464 
2025-02-21 19:10:54.142089: train_loss -0.9412 
2025-02-21 19:10:54.142229: val_loss -0.9377 
2025-02-21 19:10:54.142268: Pseudo dice [0.9766] 
2025-02-21 19:10:54.142306: Epoch time: 31.73 s 
2025-02-21 19:10:54.860492:  
2025-02-21 19:10:54.860677: Epoch 575 
2025-02-21 19:10:54.860751: Current learning rate: 0.00463 
2025-02-21 19:11:26.447268: train_loss -0.9331 
2025-02-21 19:11:26.447404: val_loss -0.9433 
2025-02-21 19:11:26.447442: Pseudo dice [0.9778] 
2025-02-21 19:11:26.447478: Epoch time: 31.59 s 
2025-02-21 19:11:27.163577:  
2025-02-21 19:11:27.163781: Epoch 576 
2025-02-21 19:11:27.163862: Current learning rate: 0.00462 
2025-02-21 19:11:58.743787: train_loss -0.9489 
2025-02-21 19:11:58.743991: val_loss -0.9531 
2025-02-21 19:11:58.744031: Pseudo dice [0.9818] 
2025-02-21 19:11:58.744070: Epoch time: 31.58 s 
2025-02-21 19:11:59.469553:  
2025-02-21 19:11:59.469718: Epoch 577 
2025-02-21 19:11:59.469797: Current learning rate: 0.00461 
2025-02-21 19:12:30.947467: train_loss -0.9408 
2025-02-21 19:12:30.947631: val_loss -0.9519 
2025-02-21 19:12:30.947672: Pseudo dice [0.9821] 
2025-02-21 19:12:30.947712: Epoch time: 31.48 s 
2025-02-21 19:12:31.677419:  
2025-02-21 19:12:31.677593: Epoch 578 
2025-02-21 19:12:31.677670: Current learning rate: 0.0046 
2025-02-21 19:13:03.113494: train_loss -0.9527 
2025-02-21 19:13:03.113641: val_loss -0.9479 
2025-02-21 19:13:03.113681: Pseudo dice [0.9781] 
2025-02-21 19:13:03.113721: Epoch time: 31.44 s 
2025-02-21 19:13:03.819195:  
2025-02-21 19:13:03.819358: Epoch 579 
2025-02-21 19:13:03.819430: Current learning rate: 0.00459 
2025-02-21 19:13:35.442856: train_loss -0.9386 
2025-02-21 19:13:35.443006: val_loss -0.9578 
2025-02-21 19:13:35.443049: Pseudo dice [0.9833] 
2025-02-21 19:13:35.443089: Epoch time: 31.62 s 
2025-02-21 19:13:36.155279:  
2025-02-21 19:13:36.155442: Epoch 580 
2025-02-21 19:13:36.155517: Current learning rate: 0.00458 
2025-02-21 19:14:07.853715: train_loss -0.9501 
2025-02-21 19:14:07.853865: val_loss -0.9554 
2025-02-21 19:14:07.853906: Pseudo dice [0.9812] 
2025-02-21 19:14:07.853947: Epoch time: 31.7 s 
2025-02-21 19:14:08.564349:  
2025-02-21 19:14:08.564513: Epoch 581 
2025-02-21 19:14:08.564616: Current learning rate: 0.00457 
2025-02-21 19:14:39.941816: train_loss -0.9406 
2025-02-21 19:14:39.942009: val_loss -0.9481 
2025-02-21 19:14:39.942052: Pseudo dice [0.9811] 
2025-02-21 19:14:39.942094: Epoch time: 31.38 s 
2025-02-21 19:14:40.685987:  
2025-02-21 19:14:40.686151: Epoch 582 
2025-02-21 19:14:40.686225: Current learning rate: 0.00456 
2025-02-21 19:15:12.239433: train_loss -0.9363 
2025-02-21 19:15:12.239569: val_loss -0.9572 
2025-02-21 19:15:12.239605: Pseudo dice [0.9842] 
2025-02-21 19:15:12.239642: Epoch time: 31.55 s 
2025-02-21 19:15:13.610555:  
2025-02-21 19:15:13.610770: Epoch 583 
2025-02-21 19:15:13.610852: Current learning rate: 0.00455 
2025-02-21 19:15:45.145255: train_loss -0.9469 
2025-02-21 19:15:45.145385: val_loss -0.9605 
2025-02-21 19:15:45.145421: Pseudo dice [0.9843] 
2025-02-21 19:15:45.145459: Epoch time: 31.54 s 
2025-02-21 19:15:45.865401:  
2025-02-21 19:15:45.865701: Epoch 584 
2025-02-21 19:15:45.865841: Current learning rate: 0.00454 
2025-02-21 19:16:17.610451: train_loss -0.9384 
2025-02-21 19:16:17.610627: val_loss -0.9537 
2025-02-21 19:16:17.610666: Pseudo dice [0.9805] 
2025-02-21 19:16:17.610706: Epoch time: 31.75 s 
2025-02-21 19:16:18.323642:  
2025-02-21 19:16:18.323880: Epoch 585 
2025-02-21 19:16:18.323986: Current learning rate: 0.00453 
2025-02-21 19:16:49.884257: train_loss -0.9348 
2025-02-21 19:16:49.884384: val_loss -0.93 
2025-02-21 19:16:49.884419: Pseudo dice [0.9746] 
2025-02-21 19:16:49.884455: Epoch time: 31.56 s 
2025-02-21 19:16:50.609398:  
2025-02-21 19:16:50.609574: Epoch 586 
2025-02-21 19:16:50.609715: Current learning rate: 0.00452 
2025-02-21 19:17:22.059532: train_loss -0.9323 
2025-02-21 19:17:22.059690: val_loss -0.9571 
2025-02-21 19:17:22.059731: Pseudo dice [0.9838] 
2025-02-21 19:17:22.059813: Epoch time: 31.45 s 
2025-02-21 19:17:22.772026:  
2025-02-21 19:17:22.772246: Epoch 587 
2025-02-21 19:17:22.772326: Current learning rate: 0.00451 
2025-02-21 19:17:54.297777: train_loss -0.92 
2025-02-21 19:17:54.297972: val_loss -0.9423 
2025-02-21 19:17:54.298017: Pseudo dice [0.9785] 
2025-02-21 19:17:54.298062: Epoch time: 31.53 s 
2025-02-21 19:17:55.022776:  
2025-02-21 19:17:55.022995: Epoch 588 
2025-02-21 19:17:55.023088: Current learning rate: 0.0045 
2025-02-21 19:18:26.410027: train_loss -0.9342 
2025-02-21 19:18:26.410202: val_loss -0.9555 
2025-02-21 19:18:26.410242: Pseudo dice [0.9845] 
2025-02-21 19:18:26.410284: Epoch time: 31.39 s 
2025-02-21 19:18:27.129630:  
2025-02-21 19:18:27.129820: Epoch 589 
2025-02-21 19:18:27.129901: Current learning rate: 0.00449 
2025-02-21 19:18:58.897084: train_loss -0.9247 
2025-02-21 19:18:58.897267: val_loss -0.9577 
2025-02-21 19:18:58.897305: Pseudo dice [0.984] 
2025-02-21 19:18:58.897345: Epoch time: 31.77 s 
2025-02-21 19:18:59.615261:  
2025-02-21 19:18:59.615418: Epoch 590 
2025-02-21 19:18:59.615517: Current learning rate: 0.00448 
2025-02-21 19:19:31.174066: train_loss -0.9478 
2025-02-21 19:19:31.174349: val_loss -0.9508 
2025-02-21 19:19:31.174413: Pseudo dice [0.9817] 
2025-02-21 19:19:31.174468: Epoch time: 31.56 s 
2025-02-21 19:19:31.928864:  
2025-02-21 19:19:31.929060: Epoch 591 
2025-02-21 19:19:31.929135: Current learning rate: 0.00447 
2025-02-21 19:20:03.551154: train_loss -0.9202 
2025-02-21 19:20:03.551307: val_loss -0.9549 
2025-02-21 19:20:03.551347: Pseudo dice [0.9833] 
2025-02-21 19:20:03.551387: Epoch time: 31.62 s 
2025-02-21 19:20:04.261276:  
2025-02-21 19:20:04.261428: Epoch 592 
2025-02-21 19:20:04.261521: Current learning rate: 0.00446 
2025-02-21 19:20:35.937063: train_loss -0.9409 
2025-02-21 19:20:35.937223: val_loss -0.9539 
2025-02-21 19:20:35.937264: Pseudo dice [0.9819] 
2025-02-21 19:20:35.937302: Epoch time: 31.68 s 
2025-02-21 19:20:36.659486:  
2025-02-21 19:20:36.659668: Epoch 593 
2025-02-21 19:20:36.659745: Current learning rate: 0.00445 
2025-02-21 19:21:08.108613: train_loss -0.9221 
2025-02-21 19:21:08.108743: val_loss -0.9483 
2025-02-21 19:21:08.108778: Pseudo dice [0.9815] 
2025-02-21 19:21:08.108827: Epoch time: 31.45 s 
2025-02-21 19:21:08.822491:  
2025-02-21 19:21:08.822672: Epoch 594 
2025-02-21 19:21:08.822745: Current learning rate: 0.00444 
2025-02-21 19:21:40.451788: train_loss -0.9315 
2025-02-21 19:21:40.451941: val_loss -0.9517 
2025-02-21 19:21:40.451978: Pseudo dice [0.9823] 
2025-02-21 19:21:40.452018: Epoch time: 31.63 s 
2025-02-21 19:21:41.159989:  
2025-02-21 19:21:41.160177: Epoch 595 
2025-02-21 19:21:41.160250: Current learning rate: 0.00443 
2025-02-21 19:22:12.691163: train_loss -0.9411 
2025-02-21 19:22:12.691348: val_loss -0.9528 
2025-02-21 19:22:12.691392: Pseudo dice [0.9825] 
2025-02-21 19:22:12.691439: Epoch time: 31.53 s 
2025-02-21 19:22:13.417810:  
2025-02-21 19:22:13.418029: Epoch 596 
2025-02-21 19:22:13.418106: Current learning rate: 0.00442 
2025-02-21 19:22:44.885610: train_loss -0.9232 
2025-02-21 19:22:44.885756: val_loss -0.9559 
2025-02-21 19:22:44.885795: Pseudo dice [0.9825] 
2025-02-21 19:22:44.885850: Epoch time: 31.47 s 
2025-02-21 19:22:45.593796:  
2025-02-21 19:22:45.593963: Epoch 597 
2025-02-21 19:22:45.594038: Current learning rate: 0.00441 
2025-02-21 19:23:18.307833: train_loss -0.9442 
2025-02-21 19:23:18.307973: val_loss -0.947 
2025-02-21 19:23:18.308010: Pseudo dice [0.9806] 
2025-02-21 19:23:18.308047: Epoch time: 32.71 s 
2025-02-21 19:23:19.018524:  
2025-02-21 19:23:19.018651: Epoch 598 
2025-02-21 19:23:19.018736: Current learning rate: 0.0044 
2025-02-21 19:23:50.829338: train_loss -0.9288 
2025-02-21 19:23:50.829560: val_loss -0.9459 
2025-02-21 19:23:50.829601: Pseudo dice [0.977] 
2025-02-21 19:23:50.829642: Epoch time: 31.81 s 
2025-02-21 19:23:51.593982:  
2025-02-21 19:23:51.594189: Epoch 599 
2025-02-21 19:23:51.594260: Current learning rate: 0.00439 
2025-02-21 19:24:23.020306: train_loss -0.9328 
2025-02-21 19:24:23.020478: val_loss -0.9595 
2025-02-21 19:24:23.020526: Pseudo dice [0.9852] 
2025-02-21 19:24:23.020565: Epoch time: 31.43 s 
2025-02-21 19:24:24.690517:  
2025-02-21 19:24:24.690706: Epoch 600 
2025-02-21 19:24:24.690778: Current learning rate: 0.00438 
2025-02-21 19:24:56.298786: train_loss -0.9273 
2025-02-21 19:24:56.298930: val_loss -0.9454 
2025-02-21 19:24:56.298996: Pseudo dice [0.9809] 
2025-02-21 19:24:56.299036: Epoch time: 31.61 s 
2025-02-21 19:24:57.003731:  
2025-02-21 19:24:57.003954: Epoch 601 
2025-02-21 19:24:57.004029: Current learning rate: 0.00437 
2025-02-21 19:25:28.652363: train_loss -0.9367 
2025-02-21 19:25:28.652501: val_loss -0.9557 
2025-02-21 19:25:28.652539: Pseudo dice [0.983] 
2025-02-21 19:25:28.652575: Epoch time: 31.65 s 
2025-02-21 19:25:29.368281:  
2025-02-21 19:25:29.368492: Epoch 602 
2025-02-21 19:25:29.368572: Current learning rate: 0.00436 
2025-02-21 19:26:00.810801: train_loss -0.9436 
2025-02-21 19:26:00.810934: val_loss -0.9575 
2025-02-21 19:26:00.810971: Pseudo dice [0.9848] 
2025-02-21 19:26:00.811009: Epoch time: 31.44 s 
2025-02-21 19:26:00.811038: Yayy! New best EMA pseudo Dice: 0.982 
2025-02-21 19:26:01.933748:  
2025-02-21 19:26:01.933928: Epoch 603 
2025-02-21 19:26:01.934048: Current learning rate: 0.00435 
2025-02-21 19:26:33.538726: train_loss -0.9515 
2025-02-21 19:26:33.538883: val_loss -0.952 
2025-02-21 19:26:33.538923: Pseudo dice [0.9816] 
2025-02-21 19:26:33.538959: Epoch time: 31.61 s 
2025-02-21 19:26:34.249051:  
2025-02-21 19:26:34.249227: Epoch 604 
2025-02-21 19:26:34.249307: Current learning rate: 0.00434 
2025-02-21 19:27:05.836126: train_loss -0.9305 
2025-02-21 19:27:05.836270: val_loss -0.9521 
2025-02-21 19:27:05.836306: Pseudo dice [0.9797] 
2025-02-21 19:27:05.836342: Epoch time: 31.59 s 
2025-02-21 19:27:06.547233:  
2025-02-21 19:27:06.547384: Epoch 605 
2025-02-21 19:27:06.547458: Current learning rate: 0.00433 
2025-02-21 19:27:37.968611: train_loss -0.931 
2025-02-21 19:27:37.968770: val_loss -0.9524 
2025-02-21 19:27:37.968812: Pseudo dice [0.9821] 
2025-02-21 19:27:37.968858: Epoch time: 31.42 s 
2025-02-21 19:27:38.682194:  
2025-02-21 19:27:38.682367: Epoch 606 
2025-02-21 19:27:38.682436: Current learning rate: 0.00432 
2025-02-21 19:28:10.331838: train_loss -0.9502 
2025-02-21 19:28:10.331977: val_loss -0.9603 
2025-02-21 19:28:10.332014: Pseudo dice [0.985] 
2025-02-21 19:28:10.332053: Epoch time: 31.65 s 
2025-02-21 19:28:10.332081: Yayy! New best EMA pseudo Dice: 0.9821 
2025-02-21 19:28:11.402788:  
2025-02-21 19:28:11.403000: Epoch 607 
2025-02-21 19:28:11.403120: Current learning rate: 0.00431 
2025-02-21 19:28:43.151464: train_loss -0.9296 
2025-02-21 19:28:43.151627: val_loss -0.9453 
2025-02-21 19:28:43.151667: Pseudo dice [0.9789] 
2025-02-21 19:28:43.151707: Epoch time: 31.75 s 
2025-02-21 19:28:43.873090:  
2025-02-21 19:28:43.873262: Epoch 608 
2025-02-21 19:28:43.873329: Current learning rate: 0.0043 
2025-02-21 19:29:15.403647: train_loss -0.9335 
2025-02-21 19:29:15.403830: val_loss -0.949 
2025-02-21 19:29:15.403906: Pseudo dice [0.9808] 
2025-02-21 19:29:15.403964: Epoch time: 31.53 s 
2025-02-21 19:29:16.128786:  
2025-02-21 19:29:16.128997: Epoch 609 
2025-02-21 19:29:16.129098: Current learning rate: 0.00429 
2025-02-21 19:29:47.676186: train_loss -0.904 
2025-02-21 19:29:47.676349: val_loss -0.9421 
2025-02-21 19:29:47.676390: Pseudo dice [0.9795] 
2025-02-21 19:29:47.676431: Epoch time: 31.55 s 
2025-02-21 19:29:48.395600:  
2025-02-21 19:29:48.395769: Epoch 610 
2025-02-21 19:29:48.395852: Current learning rate: 0.00429 
2025-02-21 19:30:20.038408: train_loss -0.9362 
2025-02-21 19:30:20.039007: val_loss -0.9427 
2025-02-21 19:30:20.039069: Pseudo dice [0.9775] 
2025-02-21 19:30:20.039141: Epoch time: 31.64 s 
2025-02-21 19:30:20.770593:  
2025-02-21 19:30:20.770735: Epoch 611 
2025-02-21 19:30:20.770819: Current learning rate: 0.00428 
2025-02-21 19:30:52.162726: train_loss -0.9431 
2025-02-21 19:30:52.162865: val_loss -0.9407 
2025-02-21 19:30:52.162904: Pseudo dice [0.9786] 
2025-02-21 19:30:52.162939: Epoch time: 31.39 s 
2025-02-21 19:30:52.878119:  
2025-02-21 19:30:52.878309: Epoch 612 
2025-02-21 19:30:52.878386: Current learning rate: 0.00427 
2025-02-21 19:31:24.579466: train_loss -0.934 
2025-02-21 19:31:24.579681: val_loss -0.9484 
2025-02-21 19:31:24.579720: Pseudo dice [0.981] 
2025-02-21 19:31:24.579758: Epoch time: 31.7 s 
2025-02-21 19:31:25.295878:  
2025-02-21 19:31:25.296101: Epoch 613 
2025-02-21 19:31:25.296184: Current learning rate: 0.00426 
2025-02-21 19:31:56.741919: train_loss -0.9361 
2025-02-21 19:31:56.742062: val_loss -0.9534 
2025-02-21 19:31:56.742101: Pseudo dice [0.9821] 
2025-02-21 19:31:56.742139: Epoch time: 31.45 s 
2025-02-21 19:31:57.463336:  
2025-02-21 19:31:57.463541: Epoch 614 
2025-02-21 19:31:57.463622: Current learning rate: 0.00425 
2025-02-21 19:32:28.965221: train_loss -0.9369 
2025-02-21 19:32:28.965353: val_loss -0.9519 
2025-02-21 19:32:28.965389: Pseudo dice [0.9831] 
2025-02-21 19:32:28.965428: Epoch time: 31.5 s 
2025-02-21 19:32:29.672412:  
2025-02-21 19:32:29.672563: Epoch 615 
2025-02-21 19:32:29.672631: Current learning rate: 0.00424 
2025-02-21 19:33:01.289304: train_loss -0.9309 
2025-02-21 19:33:01.289473: val_loss -0.951 
2025-02-21 19:33:01.289514: Pseudo dice [0.9821] 
2025-02-21 19:33:01.289557: Epoch time: 31.62 s 
2025-02-21 19:33:02.020114:  
2025-02-21 19:33:02.020262: Epoch 616 
2025-02-21 19:33:02.020380: Current learning rate: 0.00423 
2025-02-21 19:33:33.393382: train_loss -0.9205 
2025-02-21 19:33:33.393518: val_loss -0.9557 
2025-02-21 19:33:33.393560: Pseudo dice [0.9834] 
2025-02-21 19:33:33.393599: Epoch time: 31.37 s 
2025-02-21 19:33:34.702059:  
2025-02-21 19:33:34.702255: Epoch 617 
2025-02-21 19:33:34.702329: Current learning rate: 0.00422 
2025-02-21 19:34:06.558045: train_loss -0.9435 
2025-02-21 19:34:06.558188: val_loss -0.9545 
2025-02-21 19:34:06.558226: Pseudo dice [0.9826] 
2025-02-21 19:34:06.558263: Epoch time: 31.86 s 
2025-02-21 19:34:07.271508:  
2025-02-21 19:34:07.271718: Epoch 618 
2025-02-21 19:34:07.271791: Current learning rate: 0.00421 
2025-02-21 19:34:38.784890: train_loss -0.9429 
2025-02-21 19:34:38.785052: val_loss -0.9541 
2025-02-21 19:34:38.785096: Pseudo dice [0.9828] 
2025-02-21 19:34:38.785138: Epoch time: 31.51 s 
2025-02-21 19:34:39.505453:  
2025-02-21 19:34:39.505670: Epoch 619 
2025-02-21 19:34:39.505736: Current learning rate: 0.0042 
2025-02-21 19:35:11.148587: train_loss -0.9393 
2025-02-21 19:35:11.148736: val_loss -0.9558 
2025-02-21 19:35:11.148798: Pseudo dice [0.9824] 
2025-02-21 19:35:11.148878: Epoch time: 31.64 s 
2025-02-21 19:35:11.868095:  
2025-02-21 19:35:11.868337: Epoch 620 
2025-02-21 19:35:11.868410: Current learning rate: 0.00419 
2025-02-21 19:35:43.593240: train_loss -0.9392 
2025-02-21 19:35:43.593436: val_loss -0.9581 
2025-02-21 19:35:43.593473: Pseudo dice [0.9841] 
2025-02-21 19:35:43.593513: Epoch time: 31.73 s 
2025-02-21 19:35:44.316801:  
2025-02-21 19:35:44.316994: Epoch 621 
2025-02-21 19:35:44.317084: Current learning rate: 0.00418 
2025-02-21 19:36:15.883920: train_loss -0.9239 
2025-02-21 19:36:15.884096: val_loss -0.951 
2025-02-21 19:36:15.884137: Pseudo dice [0.9816] 
2025-02-21 19:36:15.884177: Epoch time: 31.57 s 
2025-02-21 19:36:16.593371:  
2025-02-21 19:36:16.593534: Epoch 622 
2025-02-21 19:36:16.593604: Current learning rate: 0.00417 
2025-02-21 19:36:48.339398: train_loss -0.9443 
2025-02-21 19:36:48.339638: val_loss -0.9581 
2025-02-21 19:36:48.339694: Pseudo dice [0.9846] 
2025-02-21 19:36:48.339747: Epoch time: 31.75 s 
2025-02-21 19:36:48.339788: Yayy! New best EMA pseudo Dice: 0.9822 
2025-02-21 19:36:49.574639:  
2025-02-21 19:36:49.574781: Epoch 623 
2025-02-21 19:36:49.574890: Current learning rate: 0.00416 
2025-02-21 19:37:21.629554: train_loss -0.9413 
2025-02-21 19:37:21.629701: val_loss -0.9436 
2025-02-21 19:37:21.629740: Pseudo dice [0.9813] 
2025-02-21 19:37:21.629779: Epoch time: 32.06 s 
2025-02-21 19:37:22.358265:  
2025-02-21 19:37:22.358437: Epoch 624 
2025-02-21 19:37:22.358563: Current learning rate: 0.00415 
2025-02-21 19:37:54.017084: train_loss -0.9426 
2025-02-21 19:37:54.017236: val_loss -0.9539 
2025-02-21 19:37:54.017273: Pseudo dice [0.9816] 
2025-02-21 19:37:54.017309: Epoch time: 31.66 s 
2025-02-21 19:37:54.735393:  
2025-02-21 19:37:54.735595: Epoch 625 
2025-02-21 19:37:54.735662: Current learning rate: 0.00414 
2025-02-21 19:38:26.436934: train_loss -0.9409 
2025-02-21 19:38:26.437079: val_loss -0.9531 
2025-02-21 19:38:26.437118: Pseudo dice [0.9816] 
2025-02-21 19:38:26.437159: Epoch time: 31.7 s 
2025-02-21 19:38:27.151450:  
2025-02-21 19:38:27.151589: Epoch 626 
2025-02-21 19:38:27.151660: Current learning rate: 0.00413 
2025-02-21 19:38:58.658838: train_loss -0.9434 
2025-02-21 19:38:58.659014: val_loss -0.9484 
2025-02-21 19:38:58.659057: Pseudo dice [0.979] 
2025-02-21 19:38:58.659101: Epoch time: 31.51 s 
2025-02-21 19:38:59.384374:  
2025-02-21 19:38:59.384524: Epoch 627 
2025-02-21 19:38:59.384584: Current learning rate: 0.00412 
2025-02-21 19:39:30.836178: train_loss -0.9348 
2025-02-21 19:39:30.836342: val_loss -0.9471 
2025-02-21 19:39:30.836383: Pseudo dice [0.9777] 
2025-02-21 19:39:30.836424: Epoch time: 31.45 s 
2025-02-21 19:39:31.556585:  
2025-02-21 19:39:31.556729: Epoch 628 
2025-02-21 19:39:31.556805: Current learning rate: 0.00411 
2025-02-21 19:40:03.244940: train_loss -0.9365 
2025-02-21 19:40:03.245095: val_loss -0.9431 
2025-02-21 19:40:03.245134: Pseudo dice [0.9777] 
2025-02-21 19:40:03.245180: Epoch time: 31.69 s 
2025-02-21 19:40:03.981908:  
2025-02-21 19:40:03.982068: Epoch 629 
2025-02-21 19:40:03.982143: Current learning rate: 0.0041 
2025-02-21 19:40:35.407190: train_loss -0.9289 
2025-02-21 19:40:35.407351: val_loss -0.954 
2025-02-21 19:40:35.407392: Pseudo dice [0.9813] 
2025-02-21 19:40:35.407428: Epoch time: 31.43 s 
2025-02-21 19:40:36.121283:  
2025-02-21 19:40:36.121456: Epoch 630 
2025-02-21 19:40:36.121529: Current learning rate: 0.00409 
2025-02-21 19:41:07.596143: train_loss -0.9234 
2025-02-21 19:41:07.596268: val_loss -0.9459 
2025-02-21 19:41:07.596305: Pseudo dice [0.9814] 
2025-02-21 19:41:07.596342: Epoch time: 31.48 s 
2025-02-21 19:41:08.307513:  
2025-02-21 19:41:08.307655: Epoch 631 
2025-02-21 19:41:08.307722: Current learning rate: 0.00408 
2025-02-21 19:41:39.825934: train_loss -0.9311 
2025-02-21 19:41:39.826083: val_loss -0.953 
2025-02-21 19:41:39.826120: Pseudo dice [0.983] 
2025-02-21 19:41:39.826155: Epoch time: 31.52 s 
2025-02-21 19:41:40.538924:  
2025-02-21 19:41:40.539104: Epoch 632 
2025-02-21 19:41:40.539207: Current learning rate: 0.00407 
2025-02-21 19:42:12.048574: train_loss -0.9217 
2025-02-21 19:42:12.048752: val_loss -0.9573 
2025-02-21 19:42:12.048791: Pseudo dice [0.9837] 
2025-02-21 19:42:12.048846: Epoch time: 31.51 s 
2025-02-21 19:42:12.764513:  
2025-02-21 19:42:12.764631: Epoch 633 
2025-02-21 19:42:12.764735: Current learning rate: 0.00406 
2025-02-21 19:42:44.381671: train_loss -0.9351 
2025-02-21 19:42:44.381803: val_loss -0.9503 
2025-02-21 19:42:44.381853: Pseudo dice [0.9811] 
2025-02-21 19:42:44.381891: Epoch time: 31.62 s 
2025-02-21 19:42:45.925844:  
2025-02-21 19:42:45.926099: Epoch 634 
2025-02-21 19:42:45.926201: Current learning rate: 0.00405 
2025-02-21 19:43:17.572510: train_loss -0.9428 
2025-02-21 19:43:17.572670: val_loss -0.9562 
2025-02-21 19:43:17.572710: Pseudo dice [0.9827] 
2025-02-21 19:43:17.572750: Epoch time: 31.65 s 
2025-02-21 19:43:18.345020:  
2025-02-21 19:43:18.345221: Epoch 635 
2025-02-21 19:43:18.345311: Current learning rate: 0.00404 
2025-02-21 19:43:49.879673: train_loss -0.9322 
2025-02-21 19:43:49.879822: val_loss -0.966 
2025-02-21 19:43:49.879862: Pseudo dice [0.9866] 
2025-02-21 19:43:49.879900: Epoch time: 31.54 s 
2025-02-21 19:43:50.648713:  
2025-02-21 19:43:50.648933: Epoch 636 
2025-02-21 19:43:50.649018: Current learning rate: 0.00403 
2025-02-21 19:44:22.157134: train_loss -0.9294 
2025-02-21 19:44:22.157295: val_loss -0.9486 
2025-02-21 19:44:22.157332: Pseudo dice [0.9796] 
2025-02-21 19:44:22.157370: Epoch time: 31.51 s 
2025-02-21 19:44:22.871777:  
2025-02-21 19:44:22.871943: Epoch 637 
2025-02-21 19:44:22.872057: Current learning rate: 0.00402 
2025-02-21 19:44:54.521154: train_loss -0.9487 
2025-02-21 19:44:54.521329: val_loss -0.954 
2025-02-21 19:44:54.521366: Pseudo dice [0.9812] 
2025-02-21 19:44:54.521404: Epoch time: 31.65 s 
2025-02-21 19:44:55.265727:  
2025-02-21 19:44:55.265944: Epoch 638 
2025-02-21 19:44:55.266021: Current learning rate: 0.00401 
2025-02-21 19:45:27.038100: train_loss -0.9299 
2025-02-21 19:45:27.038249: val_loss -0.951 
2025-02-21 19:45:27.038307: Pseudo dice [0.9808] 
2025-02-21 19:45:27.038347: Epoch time: 31.77 s 
2025-02-21 19:45:27.754455:  
2025-02-21 19:45:27.754690: Epoch 639 
2025-02-21 19:45:27.754778: Current learning rate: 0.004 
2025-02-21 19:45:59.216948: train_loss -0.9377 
2025-02-21 19:45:59.217104: val_loss -0.9564 
2025-02-21 19:45:59.217143: Pseudo dice [0.9832] 
2025-02-21 19:45:59.217182: Epoch time: 31.46 s 
2025-02-21 19:45:59.931343:  
2025-02-21 19:45:59.931520: Epoch 640 
2025-02-21 19:45:59.931592: Current learning rate: 0.00399 
2025-02-21 19:46:31.582340: train_loss -0.9369 
2025-02-21 19:46:31.582482: val_loss -0.9585 
2025-02-21 19:46:31.582520: Pseudo dice [0.9837] 
2025-02-21 19:46:31.582560: Epoch time: 31.65 s 
2025-02-21 19:46:32.303177:  
2025-02-21 19:46:32.303346: Epoch 641 
2025-02-21 19:46:32.303431: Current learning rate: 0.00398 
2025-02-21 19:47:03.979096: train_loss -0.95 
2025-02-21 19:47:03.979237: val_loss -0.9614 
2025-02-21 19:47:03.979275: Pseudo dice [0.9844] 
2025-02-21 19:47:03.979313: Epoch time: 31.68 s 
2025-02-21 19:47:03.979342: Yayy! New best EMA pseudo Dice: 0.9822 
2025-02-21 19:47:05.057775:  
2025-02-21 19:47:05.057933: Epoch 642 
2025-02-21 19:47:05.057997: Current learning rate: 0.00397 
2025-02-21 19:47:36.489634: train_loss -0.9438 
2025-02-21 19:47:36.489777: val_loss -0.9555 
2025-02-21 19:47:36.489818: Pseudo dice [0.9817] 
2025-02-21 19:47:36.489858: Epoch time: 31.43 s 
2025-02-21 19:47:37.212211:  
2025-02-21 19:47:37.212456: Epoch 643 
2025-02-21 19:47:37.212537: Current learning rate: 0.00396 
2025-02-21 19:48:09.150003: train_loss -0.9481 
2025-02-21 19:48:09.150143: val_loss -0.9565 
2025-02-21 19:48:09.150182: Pseudo dice [0.9839] 
2025-02-21 19:48:09.150222: Epoch time: 31.94 s 
2025-02-21 19:48:09.150249: Yayy! New best EMA pseudo Dice: 0.9824 
2025-02-21 19:48:10.224606:  
2025-02-21 19:48:10.224805: Epoch 644 
2025-02-21 19:48:10.224881: Current learning rate: 0.00395 
2025-02-21 19:48:41.682130: train_loss -0.9351 
2025-02-21 19:48:41.682262: val_loss -0.9468 
2025-02-21 19:48:41.682299: Pseudo dice [0.9777] 
2025-02-21 19:48:41.682396: Epoch time: 31.46 s 
2025-02-21 19:48:42.393134:  
2025-02-21 19:48:42.393335: Epoch 645 
2025-02-21 19:48:42.393442: Current learning rate: 0.00394 
2025-02-21 19:49:13.999639: train_loss -0.9371 
2025-02-21 19:49:13.999781: val_loss -0.9604 
2025-02-21 19:49:13.999827: Pseudo dice [0.9852] 
2025-02-21 19:49:13.999865: Epoch time: 31.61 s 
2025-02-21 19:49:14.715724:  
2025-02-21 19:49:14.715930: Epoch 646 
2025-02-21 19:49:14.716009: Current learning rate: 0.00393 
2025-02-21 19:49:46.241440: train_loss -0.9242 
2025-02-21 19:49:46.241577: val_loss -0.952 
2025-02-21 19:49:46.241615: Pseudo dice [0.9819] 
2025-02-21 19:49:46.241651: Epoch time: 31.53 s 
2025-02-21 19:49:46.957798:  
2025-02-21 19:49:46.957985: Epoch 647 
2025-02-21 19:49:46.958072: Current learning rate: 0.00392 
2025-02-21 19:50:18.520504: train_loss -0.9427 
2025-02-21 19:50:18.520639: val_loss -0.9512 
2025-02-21 19:50:18.520677: Pseudo dice [0.9808] 
2025-02-21 19:50:18.520718: Epoch time: 31.56 s 
2025-02-21 19:50:19.232280:  
2025-02-21 19:50:19.232418: Epoch 648 
2025-02-21 19:50:19.232483: Current learning rate: 0.00391 
2025-02-21 19:50:50.994286: train_loss -0.9524 
2025-02-21 19:50:50.994487: val_loss -0.959 
2025-02-21 19:50:50.994529: Pseudo dice [0.9836] 
2025-02-21 19:50:50.994572: Epoch time: 31.76 s 
2025-02-21 19:50:51.716945:  
2025-02-21 19:50:51.717103: Epoch 649 
2025-02-21 19:50:51.717179: Current learning rate: 0.0039 
2025-02-21 19:51:23.190139: train_loss -0.9326 
2025-02-21 19:51:23.190273: val_loss -0.9614 
2025-02-21 19:51:23.190310: Pseudo dice [0.9843] 
2025-02-21 19:51:23.190350: Epoch time: 31.47 s 
2025-02-21 19:51:23.531375: Yayy! New best EMA pseudo Dice: 0.9824 
2025-02-21 19:51:25.199665:  
2025-02-21 19:51:25.199836: Epoch 650 
2025-02-21 19:51:25.199931: Current learning rate: 0.00389 
2025-02-21 19:51:56.715095: train_loss -0.9454 
2025-02-21 19:51:56.715258: val_loss -0.9239 
2025-02-21 19:51:56.715333: Pseudo dice [0.9699] 
2025-02-21 19:51:56.715389: Epoch time: 31.52 s 
2025-02-21 19:51:57.441319:  
2025-02-21 19:51:57.441556: Epoch 651 
2025-02-21 19:51:57.441631: Current learning rate: 0.00388 
2025-02-21 19:52:28.969020: train_loss -0.9177 
2025-02-21 19:52:28.969181: val_loss -0.9671 
2025-02-21 19:52:28.969240: Pseudo dice [0.987] 
2025-02-21 19:52:28.969280: Epoch time: 31.53 s 
2025-02-21 19:52:29.709764:  
2025-02-21 19:52:29.710104: Epoch 652 
2025-02-21 19:52:29.710187: Current learning rate: 0.00387 
2025-02-21 19:53:01.173766: train_loss -0.9377 
2025-02-21 19:53:01.173985: val_loss -0.9458 
2025-02-21 19:53:01.174040: Pseudo dice [0.98] 
2025-02-21 19:53:01.174084: Epoch time: 31.46 s 
2025-02-21 19:53:01.913309:  
2025-02-21 19:53:01.913510: Epoch 653 
2025-02-21 19:53:01.913587: Current learning rate: 0.00386 
2025-02-21 19:53:33.556915: train_loss -0.9422 
2025-02-21 19:53:33.557055: val_loss -0.9484 
2025-02-21 19:53:33.557093: Pseudo dice [0.9798] 
2025-02-21 19:53:33.557158: Epoch time: 31.64 s 
2025-02-21 19:53:34.277844:  
2025-02-21 19:53:34.278019: Epoch 654 
2025-02-21 19:53:34.278073: Current learning rate: 0.00385 
2025-02-21 19:54:05.855476: train_loss -0.9308 
2025-02-21 19:54:05.855606: val_loss -0.9539 
2025-02-21 19:54:05.855644: Pseudo dice [0.9811] 
2025-02-21 19:54:05.855679: Epoch time: 31.58 s 
2025-02-21 19:54:06.566460:  
2025-02-21 19:54:06.566609: Epoch 655 
2025-02-21 19:54:06.566698: Current learning rate: 0.00384 
2025-02-21 19:54:37.998258: train_loss -0.9326 
2025-02-21 19:54:37.998412: val_loss -0.9569 
2025-02-21 19:54:37.998451: Pseudo dice [0.9839] 
2025-02-21 19:54:37.998490: Epoch time: 31.43 s 
2025-02-21 19:54:38.709959:  
2025-02-21 19:54:38.710131: Epoch 656 
2025-02-21 19:54:38.710209: Current learning rate: 0.00383 
2025-02-21 19:55:10.584414: train_loss -0.9426 
2025-02-21 19:55:10.584574: val_loss -0.9584 
2025-02-21 19:55:10.584619: Pseudo dice [0.9841] 
2025-02-21 19:55:10.584658: Epoch time: 31.88 s 
2025-02-21 19:55:11.315244:  
2025-02-21 19:55:11.315390: Epoch 657 
2025-02-21 19:55:11.315547: Current learning rate: 0.00382 
2025-02-21 19:55:42.886851: train_loss -0.936 
2025-02-21 19:55:42.887010: val_loss -0.9558 
2025-02-21 19:55:42.887045: Pseudo dice [0.9842] 
2025-02-21 19:55:42.887084: Epoch time: 31.57 s 
2025-02-21 19:55:43.600129:  
2025-02-21 19:55:43.600307: Epoch 658 
2025-02-21 19:55:43.600384: Current learning rate: 0.00381 
2025-02-21 19:56:15.868639: train_loss -0.939 
2025-02-21 19:56:15.868905: val_loss -0.958 
2025-02-21 19:56:15.868952: Pseudo dice [0.983] 
2025-02-21 19:56:15.868992: Epoch time: 32.27 s 
2025-02-21 19:56:16.675711:  
2025-02-21 19:56:16.675898: Epoch 659 
2025-02-21 19:56:16.675968: Current learning rate: 0.0038 
2025-02-21 19:56:48.534386: train_loss -0.9553 
2025-02-21 19:56:48.534559: val_loss -0.9613 
2025-02-21 19:56:48.534602: Pseudo dice [0.9842] 
2025-02-21 19:56:48.534643: Epoch time: 31.86 s 
2025-02-21 19:56:49.244626:  
2025-02-21 19:56:49.244821: Epoch 660 
2025-02-21 19:56:49.244897: Current learning rate: 0.00379 
2025-02-21 19:57:20.846967: train_loss -0.9556 
2025-02-21 19:57:20.847143: val_loss -0.938 
2025-02-21 19:57:20.847180: Pseudo dice [0.9763] 
2025-02-21 19:57:20.847220: Epoch time: 31.6 s 
2025-02-21 19:57:21.608930:  
2025-02-21 19:57:21.609086: Epoch 661 
2025-02-21 19:57:21.609180: Current learning rate: 0.00378 
2025-02-21 19:57:53.301962: train_loss -0.9452 
2025-02-21 19:57:53.302104: val_loss -0.9563 
2025-02-21 19:57:53.302140: Pseudo dice [0.9834] 
2025-02-21 19:57:53.302180: Epoch time: 31.69 s 
2025-02-21 19:57:54.015775:  
2025-02-21 19:57:54.015946: Epoch 662 
2025-02-21 19:57:54.016032: Current learning rate: 0.00377 
2025-02-21 19:58:25.555131: train_loss -0.9451 
2025-02-21 19:58:25.555285: val_loss -0.9564 
2025-02-21 19:58:25.555323: Pseudo dice [0.9825] 
2025-02-21 19:58:25.555362: Epoch time: 31.54 s 
2025-02-21 19:58:26.269240:  
2025-02-21 19:58:26.269446: Epoch 663 
2025-02-21 19:58:26.269516: Current learning rate: 0.00376 
2025-02-21 19:58:57.797986: train_loss -0.9326 
2025-02-21 19:58:57.798174: val_loss -0.9504 
2025-02-21 19:58:57.798216: Pseudo dice [0.981] 
2025-02-21 19:58:57.798257: Epoch time: 31.53 s 
2025-02-21 19:58:58.511445:  
2025-02-21 19:58:58.511575: Epoch 664 
2025-02-21 19:58:58.511634: Current learning rate: 0.00375 
2025-02-21 19:59:30.206947: train_loss -0.9383 
2025-02-21 19:59:30.207100: val_loss -0.9551 
2025-02-21 19:59:30.207144: Pseudo dice [0.9827] 
2025-02-21 19:59:30.207187: Epoch time: 31.7 s 
2025-02-21 19:59:30.936922:  
2025-02-21 19:59:30.937133: Epoch 665 
2025-02-21 19:59:30.937212: Current learning rate: 0.00374 
2025-02-21 20:00:02.581598: train_loss -0.9408 
2025-02-21 20:00:02.581728: val_loss -0.9559 
2025-02-21 20:00:02.581765: Pseudo dice [0.9816] 
2025-02-21 20:00:02.581803: Epoch time: 31.65 s 
2025-02-21 20:00:03.296961:  
2025-02-21 20:00:03.297141: Epoch 666 
2025-02-21 20:00:03.297228: Current learning rate: 0.00373 
2025-02-21 20:00:35.345272: train_loss -0.9503 
2025-02-21 20:00:35.345414: val_loss -0.9549 
2025-02-21 20:00:35.345454: Pseudo dice [0.9827] 
2025-02-21 20:00:35.345494: Epoch time: 32.05 s 
2025-02-21 20:00:36.061575:  
2025-02-21 20:00:36.061775: Epoch 667 
2025-02-21 20:00:36.061851: Current learning rate: 0.00372 
2025-02-21 20:01:07.715857: train_loss -0.9442 
2025-02-21 20:01:07.716039: val_loss -0.9605 
2025-02-21 20:01:07.716077: Pseudo dice [0.9846] 
2025-02-21 20:01:07.716119: Epoch time: 31.65 s 
2025-02-21 20:01:09.102789:  
2025-02-21 20:01:09.103041: Epoch 668 
2025-02-21 20:01:09.103113: Current learning rate: 0.00371 
2025-02-21 20:01:40.492238: train_loss -0.9235 
2025-02-21 20:01:40.492453: val_loss -0.9357 
2025-02-21 20:01:40.492531: Pseudo dice [0.9761] 
2025-02-21 20:01:40.492583: Epoch time: 31.39 s 
2025-02-21 20:01:41.234880:  
2025-02-21 20:01:41.235095: Epoch 669 
2025-02-21 20:01:41.235148: Current learning rate: 0.0037 
2025-02-21 20:02:13.039989: train_loss -0.9434 
2025-02-21 20:02:13.040135: val_loss -0.9597 
2025-02-21 20:02:13.040173: Pseudo dice [0.9851] 
2025-02-21 20:02:13.040211: Epoch time: 31.81 s 
2025-02-21 20:02:13.776622:  
2025-02-21 20:02:13.776859: Epoch 670 
2025-02-21 20:02:13.776954: Current learning rate: 0.00369 
2025-02-21 20:02:45.249026: train_loss -0.9493 
2025-02-21 20:02:45.249192: val_loss -0.9637 
2025-02-21 20:02:45.249227: Pseudo dice [0.9855] 
2025-02-21 20:02:45.249267: Epoch time: 31.47 s 
2025-02-21 20:02:45.981189:  
2025-02-21 20:02:45.981386: Epoch 671 
2025-02-21 20:02:45.981462: Current learning rate: 0.00368 
2025-02-21 20:03:17.424401: train_loss -0.9392 
2025-02-21 20:03:17.424546: val_loss -0.9577 
2025-02-21 20:03:17.424587: Pseudo dice [0.9839] 
2025-02-21 20:03:17.424624: Epoch time: 31.44 s 
2025-02-21 20:03:17.424653: Yayy! New best EMA pseudo Dice: 0.9825 
2025-02-21 20:03:18.474208:  
2025-02-21 20:03:18.474374: Epoch 672 
2025-02-21 20:03:18.474463: Current learning rate: 0.00367 
2025-02-21 20:03:49.912836: train_loss -0.9472 
2025-02-21 20:03:49.912969: val_loss -0.9486 
2025-02-21 20:03:49.913006: Pseudo dice [0.9804] 
2025-02-21 20:03:49.913043: Epoch time: 31.44 s 
2025-02-21 20:03:50.646149:  
2025-02-21 20:03:50.646349: Epoch 673 
2025-02-21 20:03:50.646425: Current learning rate: 0.00366 
2025-02-21 20:04:22.301874: train_loss -0.9401 
2025-02-21 20:04:22.302068: val_loss -0.9517 
2025-02-21 20:04:22.302118: Pseudo dice [0.9812] 
2025-02-21 20:04:22.302161: Epoch time: 31.66 s 
2025-02-21 20:04:23.057535:  
2025-02-21 20:04:23.057723: Epoch 674 
2025-02-21 20:04:23.057837: Current learning rate: 0.00365 
2025-02-21 20:04:54.495310: train_loss -0.9534 
2025-02-21 20:04:54.495460: val_loss -0.9431 
2025-02-21 20:04:54.495499: Pseudo dice [0.9809] 
2025-02-21 20:04:54.495595: Epoch time: 31.44 s 
2025-02-21 20:04:55.225776:  
2025-02-21 20:04:55.225943: Epoch 675 
2025-02-21 20:04:55.226057: Current learning rate: 0.00364 
2025-02-21 20:05:26.697597: train_loss -0.9409 
2025-02-21 20:05:26.697721: val_loss -0.9606 
2025-02-21 20:05:26.697758: Pseudo dice [0.985] 
2025-02-21 20:05:26.697797: Epoch time: 31.47 s 
2025-02-21 20:05:27.431873:  
2025-02-21 20:05:27.432068: Epoch 676 
2025-02-21 20:05:27.432145: Current learning rate: 0.00363 
2025-02-21 20:05:58.898036: train_loss -0.9385 
2025-02-21 20:05:58.898173: val_loss -0.9618 
2025-02-21 20:05:58.898209: Pseudo dice [0.9847] 
2025-02-21 20:05:58.898247: Epoch time: 31.47 s 
2025-02-21 20:05:58.898275: Yayy! New best EMA pseudo Dice: 0.9826 
2025-02-21 20:05:59.969533:  
2025-02-21 20:05:59.969686: Epoch 677 
2025-02-21 20:05:59.969786: Current learning rate: 0.00362 
2025-02-21 20:06:31.387328: train_loss -0.9472 
2025-02-21 20:06:31.387486: val_loss -0.9428 
2025-02-21 20:06:31.387583: Pseudo dice [0.9781] 
2025-02-21 20:06:31.387625: Epoch time: 31.42 s 
2025-02-21 20:06:32.113145:  
2025-02-21 20:06:32.113289: Epoch 678 
2025-02-21 20:06:32.113374: Current learning rate: 0.00361 
2025-02-21 20:07:03.611839: train_loss -0.9483 
2025-02-21 20:07:03.611962: val_loss -0.9622 
2025-02-21 20:07:03.611996: Pseudo dice [0.9861] 
2025-02-21 20:07:03.612032: Epoch time: 31.5 s 
2025-02-21 20:07:04.329870:  
2025-02-21 20:07:04.330058: Epoch 679 
2025-02-21 20:07:04.330129: Current learning rate: 0.0036 
2025-02-21 20:07:35.592132: train_loss -0.9486 
2025-02-21 20:07:35.592272: val_loss -0.9544 
2025-02-21 20:07:35.592309: Pseudo dice [0.9828] 
2025-02-21 20:07:35.592344: Epoch time: 31.26 s 
2025-02-21 20:07:36.319039:  
2025-02-21 20:07:36.319224: Epoch 680 
2025-02-21 20:07:36.319300: Current learning rate: 0.00359 
2025-02-21 20:08:07.707422: train_loss -0.9482 
2025-02-21 20:08:07.707553: val_loss -0.9599 
2025-02-21 20:08:07.707592: Pseudo dice [0.9844] 
2025-02-21 20:08:07.707631: Epoch time: 31.39 s 
2025-02-21 20:08:07.707660: Yayy! New best EMA pseudo Dice: 0.9827 
2025-02-21 20:08:08.779170:  
2025-02-21 20:08:08.779379: Epoch 681 
2025-02-21 20:08:08.779450: Current learning rate: 0.00358 
2025-02-21 20:08:40.164454: train_loss -0.9309 
2025-02-21 20:08:40.164600: val_loss -0.9624 
2025-02-21 20:08:40.164638: Pseudo dice [0.9849] 
2025-02-21 20:08:40.164676: Epoch time: 31.39 s 
2025-02-21 20:08:40.164705: Yayy! New best EMA pseudo Dice: 0.983 
2025-02-21 20:08:41.239620:  
2025-02-21 20:08:41.239799: Epoch 682 
2025-02-21 20:08:41.239911: Current learning rate: 0.00357 
2025-02-21 20:09:12.733624: train_loss -0.9309 
2025-02-21 20:09:12.733780: val_loss -0.9572 
2025-02-21 20:09:12.733828: Pseudo dice [0.984] 
2025-02-21 20:09:12.733873: Epoch time: 31.49 s 
2025-02-21 20:09:12.733903: Yayy! New best EMA pseudo Dice: 0.9831 
2025-02-21 20:09:13.808856:  
2025-02-21 20:09:13.809083: Epoch 683 
2025-02-21 20:09:13.809159: Current learning rate: 0.00356 
2025-02-21 20:09:45.562026: train_loss -0.9532 
2025-02-21 20:09:45.562209: val_loss -0.9666 
2025-02-21 20:09:45.562263: Pseudo dice [0.9867] 
2025-02-21 20:09:45.562305: Epoch time: 31.75 s 
2025-02-21 20:09:45.562333: Yayy! New best EMA pseudo Dice: 0.9834 
2025-02-21 20:09:47.335101:  
2025-02-21 20:09:47.335358: Epoch 684 
2025-02-21 20:09:47.335434: Current learning rate: 0.00355 
2025-02-21 20:10:18.895552: train_loss -0.9496 
2025-02-21 20:10:18.895685: val_loss -0.9585 
2025-02-21 20:10:18.895729: Pseudo dice [0.9829] 
2025-02-21 20:10:18.895769: Epoch time: 31.56 s 
2025-02-21 20:10:19.625484:  
2025-02-21 20:10:19.625689: Epoch 685 
2025-02-21 20:10:19.625792: Current learning rate: 0.00354 
2025-02-21 20:10:51.102400: train_loss -0.9399 
2025-02-21 20:10:51.102568: val_loss -0.9647 
2025-02-21 20:10:51.102626: Pseudo dice [0.9858] 
2025-02-21 20:10:51.102668: Epoch time: 31.48 s 
2025-02-21 20:10:51.102699: Yayy! New best EMA pseudo Dice: 0.9836 
2025-02-21 20:10:52.176931:  
2025-02-21 20:10:52.177127: Epoch 686 
2025-02-21 20:10:52.177201: Current learning rate: 0.00353 
2025-02-21 20:11:23.815915: train_loss -0.95 
2025-02-21 20:11:23.816045: val_loss -0.9507 
2025-02-21 20:11:23.816082: Pseudo dice [0.9819] 
2025-02-21 20:11:23.816118: Epoch time: 31.64 s 
2025-02-21 20:11:24.544041:  
2025-02-21 20:11:24.544231: Epoch 687 
2025-02-21 20:11:24.544339: Current learning rate: 0.00352 
2025-02-21 20:11:56.064476: train_loss -0.9479 
2025-02-21 20:11:56.064607: val_loss -0.952 
2025-02-21 20:11:56.064644: Pseudo dice [0.9825] 
2025-02-21 20:11:56.064680: Epoch time: 31.52 s 
2025-02-21 20:11:56.794144:  
2025-02-21 20:11:56.794334: Epoch 688 
2025-02-21 20:11:56.794414: Current learning rate: 0.00351 
2025-02-21 20:12:28.436188: train_loss -0.9395 
2025-02-21 20:12:28.436366: val_loss -0.9472 
2025-02-21 20:12:28.436407: Pseudo dice [0.9803] 
2025-02-21 20:12:28.436450: Epoch time: 31.64 s 
2025-02-21 20:12:29.161695:  
2025-02-21 20:12:29.161915: Epoch 689 
2025-02-21 20:12:29.161989: Current learning rate: 0.0035 
2025-02-21 20:13:00.711390: train_loss -0.9425 
2025-02-21 20:13:00.711540: val_loss -0.9577 
2025-02-21 20:13:00.711579: Pseudo dice [0.9837] 
2025-02-21 20:13:00.711619: Epoch time: 31.55 s 
2025-02-21 20:13:01.436013:  
2025-02-21 20:13:01.436168: Epoch 690 
2025-02-21 20:13:01.436240: Current learning rate: 0.00349 
2025-02-21 20:13:32.919726: train_loss -0.9293 
2025-02-21 20:13:32.919887: val_loss -0.9533 
2025-02-21 20:13:32.919934: Pseudo dice [0.9838] 
2025-02-21 20:13:32.919973: Epoch time: 31.48 s 
2025-02-21 20:13:33.656976:  
2025-02-21 20:13:33.657144: Epoch 691 
2025-02-21 20:13:33.657226: Current learning rate: 0.00348 
2025-02-21 20:14:05.206999: train_loss -0.9426 
2025-02-21 20:14:05.207198: val_loss -0.9617 
2025-02-21 20:14:05.207238: Pseudo dice [0.985] 
2025-02-21 20:14:05.207278: Epoch time: 31.55 s 
2025-02-21 20:14:05.937601:  
2025-02-21 20:14:05.937858: Epoch 692 
2025-02-21 20:14:05.937951: Current learning rate: 0.00346 
2025-02-21 20:14:37.634791: train_loss -0.9451 
2025-02-21 20:14:37.634937: val_loss -0.9585 
2025-02-21 20:14:37.634974: Pseudo dice [0.9836] 
2025-02-21 20:14:37.635013: Epoch time: 31.7 s 
2025-02-21 20:14:38.363428:  
2025-02-21 20:14:38.363625: Epoch 693 
2025-02-21 20:14:38.363716: Current learning rate: 0.00345 
2025-02-21 20:15:09.742438: train_loss -0.9284 
2025-02-21 20:15:09.742568: val_loss -0.9384 
2025-02-21 20:15:09.742604: Pseudo dice [0.9771] 
2025-02-21 20:15:09.742640: Epoch time: 31.38 s 
2025-02-21 20:15:10.495491:  
2025-02-21 20:15:10.495669: Epoch 694 
2025-02-21 20:15:10.495759: Current learning rate: 0.00344 
2025-02-21 20:15:42.037278: train_loss -0.9422 
2025-02-21 20:15:42.037416: val_loss -0.9572 
2025-02-21 20:15:42.037452: Pseudo dice [0.9838] 
2025-02-21 20:15:42.037492: Epoch time: 31.54 s 
2025-02-21 20:15:42.768838:  
2025-02-21 20:15:42.768996: Epoch 695 
2025-02-21 20:15:42.769097: Current learning rate: 0.00343 
2025-02-21 20:16:14.252279: train_loss -0.942 
2025-02-21 20:16:14.252421: val_loss -0.9627 
2025-02-21 20:16:14.252497: Pseudo dice [0.9853] 
2025-02-21 20:16:14.252536: Epoch time: 31.48 s 
2025-02-21 20:16:14.975394:  
2025-02-21 20:16:14.975561: Epoch 696 
2025-02-21 20:16:14.975642: Current learning rate: 0.00342 
2025-02-21 20:16:47.170232: train_loss -0.9265 
2025-02-21 20:16:47.170418: val_loss -0.9541 
2025-02-21 20:16:47.170455: Pseudo dice [0.9827] 
2025-02-21 20:16:47.170506: Epoch time: 32.2 s 
2025-02-21 20:16:47.930071:  
2025-02-21 20:16:47.930240: Epoch 697 
2025-02-21 20:16:47.930327: Current learning rate: 0.00341 
2025-02-21 20:17:19.879397: train_loss -0.9332 
2025-02-21 20:17:19.879547: val_loss -0.9573 
2025-02-21 20:17:19.879586: Pseudo dice [0.9828] 
2025-02-21 20:17:19.879627: Epoch time: 31.95 s 
2025-02-21 20:17:20.600543:  
2025-02-21 20:17:20.600726: Epoch 698 
2025-02-21 20:17:20.600801: Current learning rate: 0.0034 
2025-02-21 20:17:52.178870: train_loss -0.9378 
2025-02-21 20:17:52.178993: val_loss -0.9443 
2025-02-21 20:17:52.179031: Pseudo dice [0.9796] 
2025-02-21 20:17:52.179067: Epoch time: 31.58 s 
2025-02-21 20:17:52.897427:  
2025-02-21 20:17:52.897603: Epoch 699 
2025-02-21 20:17:52.897675: Current learning rate: 0.00339 
2025-02-21 20:18:24.448368: train_loss -0.9348 
2025-02-21 20:18:24.448517: val_loss -0.9444 
2025-02-21 20:18:24.448558: Pseudo dice [0.9786] 
2025-02-21 20:18:24.448597: Epoch time: 31.55 s 
2025-02-21 20:18:26.096270:  
2025-02-21 20:18:26.096483: Epoch 700 
2025-02-21 20:18:26.096572: Current learning rate: 0.00338 
2025-02-21 20:18:57.815064: train_loss -0.9209 
2025-02-21 20:18:57.815202: val_loss -0.9576 
2025-02-21 20:18:57.815240: Pseudo dice [0.9831] 
2025-02-21 20:18:57.815303: Epoch time: 31.72 s 
2025-02-21 20:18:58.543729:  
2025-02-21 20:18:58.543899: Epoch 701 
2025-02-21 20:18:58.543995: Current learning rate: 0.00337 
2025-02-21 20:19:30.392196: train_loss -0.9369 
2025-02-21 20:19:30.392342: val_loss -0.9552 
2025-02-21 20:19:30.392379: Pseudo dice [0.9834] 
2025-02-21 20:19:30.392419: Epoch time: 31.85 s 
2025-02-21 20:19:31.122349:  
2025-02-21 20:19:31.122545: Epoch 702 
2025-02-21 20:19:31.122637: Current learning rate: 0.00336 
2025-02-21 20:20:03.057580: train_loss -0.9401 
2025-02-21 20:20:03.057786: val_loss -0.9525 
2025-02-21 20:20:03.057840: Pseudo dice [0.9806] 
2025-02-21 20:20:03.057884: Epoch time: 31.94 s 
2025-02-21 20:20:03.881838:  
2025-02-21 20:20:03.882058: Epoch 703 
2025-02-21 20:20:03.882136: Current learning rate: 0.00335 
2025-02-21 20:20:35.666128: train_loss -0.9303 
2025-02-21 20:20:35.666265: val_loss -0.9608 
2025-02-21 20:20:35.666305: Pseudo dice [0.9853] 
2025-02-21 20:20:35.666343: Epoch time: 31.79 s 
2025-02-21 20:20:36.384364:  
2025-02-21 20:20:36.384517: Epoch 704 
2025-02-21 20:20:36.384595: Current learning rate: 0.00334 
2025-02-21 20:21:07.929634: train_loss -0.9308 
2025-02-21 20:21:07.929984: val_loss -0.9487 
2025-02-21 20:21:07.930107: Pseudo dice [0.9797] 
2025-02-21 20:21:07.930158: Epoch time: 31.55 s 
2025-02-21 20:21:08.864538:  
2025-02-21 20:21:08.864727: Epoch 705 
2025-02-21 20:21:08.864780: Current learning rate: 0.00333 
2025-02-21 20:21:40.502142: train_loss -0.9377 
2025-02-21 20:21:40.502281: val_loss -0.9583 
2025-02-21 20:21:40.502318: Pseudo dice [0.9828] 
2025-02-21 20:21:40.502358: Epoch time: 31.64 s 
2025-02-21 20:21:41.226736:  
2025-02-21 20:21:41.226929: Epoch 706 
2025-02-21 20:21:41.227029: Current learning rate: 0.00332 
2025-02-21 20:22:12.590003: train_loss -0.9413 
2025-02-21 20:22:12.590161: val_loss -0.9552 
2025-02-21 20:22:12.590203: Pseudo dice [0.9825] 
2025-02-21 20:22:12.590244: Epoch time: 31.36 s 
2025-02-21 20:22:13.311049:  
2025-02-21 20:22:13.311205: Epoch 707 
2025-02-21 20:22:13.311282: Current learning rate: 0.00331 
2025-02-21 20:22:44.690613: train_loss -0.9453 
2025-02-21 20:22:44.690746: val_loss -0.9562 
2025-02-21 20:22:44.690783: Pseudo dice [0.9824] 
2025-02-21 20:22:44.690826: Epoch time: 31.38 s 
2025-02-21 20:22:45.412151:  
2025-02-21 20:22:45.412305: Epoch 708 
2025-02-21 20:22:45.412381: Current learning rate: 0.0033 
2025-02-21 20:23:17.154673: train_loss -0.9431 
2025-02-21 20:23:17.154823: val_loss -0.9608 
2025-02-21 20:23:17.154869: Pseudo dice [0.9839] 
2025-02-21 20:23:17.154908: Epoch time: 31.74 s 
2025-02-21 20:23:17.885785:  
2025-02-21 20:23:17.885993: Epoch 709 
2025-02-21 20:23:17.886087: Current learning rate: 0.00329 
2025-02-21 20:23:49.305429: train_loss -0.9528 
2025-02-21 20:23:49.305557: val_loss -0.9626 
2025-02-21 20:23:49.305597: Pseudo dice [0.9862] 
2025-02-21 20:23:49.305634: Epoch time: 31.42 s 
2025-02-21 20:23:50.036320:  
2025-02-21 20:23:50.036484: Epoch 710 
2025-02-21 20:23:50.036570: Current learning rate: 0.00328 
2025-02-21 20:24:21.412240: train_loss -0.9423 
2025-02-21 20:24:21.412395: val_loss -0.9477 
2025-02-21 20:24:21.412434: Pseudo dice [0.9786] 
2025-02-21 20:24:21.412474: Epoch time: 31.38 s 
2025-02-21 20:24:22.138075:  
2025-02-21 20:24:22.138270: Epoch 711 
2025-02-21 20:24:22.138341: Current learning rate: 0.00327 
2025-02-21 20:24:53.593702: train_loss -0.9483 
2025-02-21 20:24:53.593844: val_loss -0.958 
2025-02-21 20:24:53.593881: Pseudo dice [0.9835] 
2025-02-21 20:24:53.593919: Epoch time: 31.46 s 
2025-02-21 20:24:54.312566:  
2025-02-21 20:24:54.312742: Epoch 712 
2025-02-21 20:24:54.312819: Current learning rate: 0.00326 
2025-02-21 20:25:25.987610: train_loss -0.9493 
2025-02-21 20:25:25.987748: val_loss -0.9578 
2025-02-21 20:25:25.987784: Pseudo dice [0.9828] 
2025-02-21 20:25:25.987828: Epoch time: 31.68 s 
2025-02-21 20:25:26.720384:  
2025-02-21 20:25:26.720638: Epoch 713 
2025-02-21 20:25:26.720742: Current learning rate: 0.00325 
2025-02-21 20:25:58.239310: train_loss -0.9382 
2025-02-21 20:25:58.239670: val_loss -0.9563 
2025-02-21 20:25:58.239760: Pseudo dice [0.9846] 
2025-02-21 20:25:58.239841: Epoch time: 31.52 s 
2025-02-21 20:25:58.981143:  
2025-02-21 20:25:58.981345: Epoch 714 
2025-02-21 20:25:58.981432: Current learning rate: 0.00324 
2025-02-21 20:26:30.456341: train_loss -0.9496 
2025-02-21 20:26:30.456503: val_loss -0.9675 
2025-02-21 20:26:30.456545: Pseudo dice [0.9861] 
2025-02-21 20:26:30.456584: Epoch time: 31.48 s 
2025-02-21 20:26:31.178010:  
2025-02-21 20:26:31.178177: Epoch 715 
2025-02-21 20:26:31.178247: Current learning rate: 0.00323 
2025-02-21 20:27:02.639081: train_loss -0.9536 
2025-02-21 20:27:02.639220: val_loss -0.9613 
2025-02-21 20:27:02.639254: Pseudo dice [0.9845] 
2025-02-21 20:27:02.639290: Epoch time: 31.46 s 
2025-02-21 20:27:03.361573:  
2025-02-21 20:27:03.361734: Epoch 716 
2025-02-21 20:27:03.361785: Current learning rate: 0.00322 
2025-02-21 20:27:34.823397: train_loss -0.9355 
2025-02-21 20:27:34.823542: val_loss -0.9539 
2025-02-21 20:27:34.823592: Pseudo dice [0.9823] 
2025-02-21 20:27:34.823630: Epoch time: 31.46 s 
2025-02-21 20:27:36.156558:  
2025-02-21 20:27:36.156756: Epoch 717 
2025-02-21 20:27:36.156888: Current learning rate: 0.00321 
2025-02-21 20:28:07.636315: train_loss -0.9534 
2025-02-21 20:28:07.636475: val_loss -0.9622 
2025-02-21 20:28:07.636519: Pseudo dice [0.9857] 
2025-02-21 20:28:07.636561: Epoch time: 31.48 s 
2025-02-21 20:28:08.366664:  
2025-02-21 20:28:08.366874: Epoch 718 
2025-02-21 20:28:08.366954: Current learning rate: 0.0032 
2025-02-21 20:28:40.129855: train_loss -0.9451 
2025-02-21 20:28:40.129987: val_loss -0.9517 
2025-02-21 20:28:40.130024: Pseudo dice [0.9834] 
2025-02-21 20:28:40.130064: Epoch time: 31.76 s 
2025-02-21 20:28:40.850922:  
2025-02-21 20:28:40.851105: Epoch 719 
2025-02-21 20:28:40.851229: Current learning rate: 0.00319 
2025-02-21 20:29:12.397305: train_loss -0.9443 
2025-02-21 20:29:12.397436: val_loss -0.9641 
2025-02-21 20:29:12.397474: Pseudo dice [0.9865] 
2025-02-21 20:29:12.397511: Epoch time: 31.55 s 
2025-02-21 20:29:12.397540: Yayy! New best EMA pseudo Dice: 0.9837 
2025-02-21 20:29:13.430820:  
2025-02-21 20:29:13.431008: Epoch 720 
2025-02-21 20:29:13.431055: Current learning rate: 0.00318 
2025-02-21 20:29:44.912697: train_loss -0.9424 
2025-02-21 20:29:44.912848: val_loss -0.951 
2025-02-21 20:29:44.912890: Pseudo dice [0.9796] 
2025-02-21 20:29:44.912952: Epoch time: 31.48 s 
2025-02-21 20:29:45.642441:  
2025-02-21 20:29:45.642622: Epoch 721 
2025-02-21 20:29:45.642740: Current learning rate: 0.00317 
2025-02-21 20:30:17.191990: train_loss -0.9542 
2025-02-21 20:30:17.192132: val_loss -0.9627 
2025-02-21 20:30:17.192170: Pseudo dice [0.9858] 
2025-02-21 20:30:17.192209: Epoch time: 31.55 s 
2025-02-21 20:30:17.920228:  
2025-02-21 20:30:17.920398: Epoch 722 
2025-02-21 20:30:17.920484: Current learning rate: 0.00316 
2025-02-21 20:30:49.530186: train_loss -0.9383 
2025-02-21 20:30:49.530402: val_loss -0.951 
2025-02-21 20:30:49.530463: Pseudo dice [0.9809] 
2025-02-21 20:30:49.530509: Epoch time: 31.61 s 
2025-02-21 20:30:50.328421:  
2025-02-21 20:30:50.328658: Epoch 723 
2025-02-21 20:30:50.328763: Current learning rate: 0.00315 
2025-02-21 20:31:21.931422: train_loss -0.9554 
2025-02-21 20:31:21.931603: val_loss -0.9637 
2025-02-21 20:31:21.931651: Pseudo dice [0.9858] 
2025-02-21 20:31:21.931695: Epoch time: 31.6 s 
2025-02-21 20:31:22.659643:  
2025-02-21 20:31:22.659872: Epoch 724 
2025-02-21 20:31:22.659946: Current learning rate: 0.00314 
2025-02-21 20:31:54.063135: train_loss -0.9527 
2025-02-21 20:31:54.063264: val_loss -0.9602 
2025-02-21 20:31:54.063310: Pseudo dice [0.9841] 
2025-02-21 20:31:54.063348: Epoch time: 31.4 s 
2025-02-21 20:31:54.799416:  
2025-02-21 20:31:54.799616: Epoch 725 
2025-02-21 20:31:54.799689: Current learning rate: 0.00313 
2025-02-21 20:32:26.199312: train_loss -0.9306 
2025-02-21 20:32:26.199456: val_loss -0.9635 
2025-02-21 20:32:26.199491: Pseudo dice [0.9853] 
2025-02-21 20:32:26.199529: Epoch time: 31.4 s 
2025-02-21 20:32:26.199608: Yayy! New best EMA pseudo Dice: 0.9838 
2025-02-21 20:32:27.264625:  
2025-02-21 20:32:27.264800: Epoch 726 
2025-02-21 20:32:27.264889: Current learning rate: 0.00312 
2025-02-21 20:32:58.814302: train_loss -0.9487 
2025-02-21 20:32:58.814472: val_loss -0.9612 
2025-02-21 20:32:58.814518: Pseudo dice [0.9839] 
2025-02-21 20:32:58.814558: Epoch time: 31.55 s 
2025-02-21 20:32:58.814588: Yayy! New best EMA pseudo Dice: 0.9838 
2025-02-21 20:32:59.898241:  
2025-02-21 20:32:59.898473: Epoch 727 
2025-02-21 20:32:59.898551: Current learning rate: 0.00311 
2025-02-21 20:33:31.654951: train_loss -0.9341 
2025-02-21 20:33:31.655118: val_loss -0.9648 
2025-02-21 20:33:31.655155: Pseudo dice [0.9868] 
2025-02-21 20:33:31.655190: Epoch time: 31.76 s 
2025-02-21 20:33:31.655218: Yayy! New best EMA pseudo Dice: 0.9841 
2025-02-21 20:33:32.766924:  
2025-02-21 20:33:32.767079: Epoch 728 
2025-02-21 20:33:32.767176: Current learning rate: 0.0031 
2025-02-21 20:34:04.409854: train_loss -0.9336 
2025-02-21 20:34:04.410021: val_loss -0.948 
2025-02-21 20:34:04.410061: Pseudo dice [0.9806] 
2025-02-21 20:34:04.410100: Epoch time: 31.64 s 
2025-02-21 20:34:05.145484:  
2025-02-21 20:34:05.145639: Epoch 729 
2025-02-21 20:34:05.145707: Current learning rate: 0.00309 
2025-02-21 20:34:36.706705: train_loss -0.9512 
2025-02-21 20:34:36.706884: val_loss -0.9676 
2025-02-21 20:34:36.706946: Pseudo dice [0.9873] 
2025-02-21 20:34:36.706994: Epoch time: 31.56 s 
2025-02-21 20:34:36.707025: Yayy! New best EMA pseudo Dice: 0.9841 
2025-02-21 20:34:37.809978:  
2025-02-21 20:34:37.810293: Epoch 730 
2025-02-21 20:34:37.810379: Current learning rate: 0.00308 
2025-02-21 20:35:09.570437: train_loss -0.9522 
2025-02-21 20:35:09.570580: val_loss -0.9521 
2025-02-21 20:35:09.570621: Pseudo dice [0.9818] 
2025-02-21 20:35:09.570661: Epoch time: 31.76 s 
2025-02-21 20:35:10.303164:  
2025-02-21 20:35:10.303302: Epoch 731 
2025-02-21 20:35:10.303430: Current learning rate: 0.00307 
2025-02-21 20:35:42.108996: train_loss -0.9393 
2025-02-21 20:35:42.109164: val_loss -0.9561 
2025-02-21 20:35:42.109230: Pseudo dice [0.9841] 
2025-02-21 20:35:42.109274: Epoch time: 31.81 s 
2025-02-21 20:35:42.871024:  
2025-02-21 20:35:42.871200: Epoch 732 
2025-02-21 20:35:42.871294: Current learning rate: 0.00306 
2025-02-21 20:36:14.361447: train_loss -0.9517 
2025-02-21 20:36:14.361592: val_loss -0.9616 
2025-02-21 20:36:14.361636: Pseudo dice [0.9867] 
2025-02-21 20:36:14.361675: Epoch time: 31.49 s 
2025-02-21 20:36:14.361703: Yayy! New best EMA pseudo Dice: 0.9842 
2025-02-21 20:36:15.575357:  
2025-02-21 20:36:15.575546: Epoch 733 
2025-02-21 20:36:15.575645: Current learning rate: 0.00305 
2025-02-21 20:36:49.474860: train_loss -0.9484 
2025-02-21 20:36:49.475179: val_loss -0.9589 
2025-02-21 20:36:49.475221: Pseudo dice [0.9842] 
2025-02-21 20:36:49.475262: Epoch time: 33.9 s 
2025-02-21 20:36:49.475291: Yayy! New best EMA pseudo Dice: 0.9842 
2025-02-21 20:36:50.517489:  
2025-02-21 20:36:50.517677: Epoch 734 
2025-02-21 20:36:50.517768: Current learning rate: 0.00304 
2025-02-21 20:37:22.016886: train_loss -0.948 
2025-02-21 20:37:22.017038: val_loss -0.9628 
2025-02-21 20:37:22.017077: Pseudo dice [0.9847] 
2025-02-21 20:37:22.017117: Epoch time: 31.5 s 
2025-02-21 20:37:22.017146: Yayy! New best EMA pseudo Dice: 0.9842 
2025-02-21 20:37:23.105319:  
2025-02-21 20:37:23.105520: Epoch 735 
2025-02-21 20:37:23.105593: Current learning rate: 0.00303 
2025-02-21 20:37:54.747633: train_loss -0.947 
2025-02-21 20:37:54.747767: val_loss -0.9616 
2025-02-21 20:37:54.747803: Pseudo dice [0.9853] 
2025-02-21 20:37:54.747851: Epoch time: 31.64 s 
2025-02-21 20:37:54.747880: Yayy! New best EMA pseudo Dice: 0.9843 
2025-02-21 20:37:55.820066:  
2025-02-21 20:37:55.820257: Epoch 736 
2025-02-21 20:37:55.820351: Current learning rate: 0.00302 
2025-02-21 20:38:27.522258: train_loss -0.9359 
2025-02-21 20:38:27.522424: val_loss -0.9562 
2025-02-21 20:38:27.522467: Pseudo dice [0.9829] 
2025-02-21 20:38:27.522511: Epoch time: 31.7 s 
2025-02-21 20:38:28.399503:  
2025-02-21 20:38:28.399662: Epoch 737 
2025-02-21 20:38:28.399815: Current learning rate: 0.00301 
2025-02-21 20:39:00.387705: train_loss -0.9381 
2025-02-21 20:39:00.387878: val_loss -0.9641 
2025-02-21 20:39:00.387918: Pseudo dice [0.9866] 
2025-02-21 20:39:00.387958: Epoch time: 31.99 s 
2025-02-21 20:39:00.387987: Yayy! New best EMA pseudo Dice: 0.9844 
2025-02-21 20:39:01.431608:  
2025-02-21 20:39:01.431791: Epoch 738 
2025-02-21 20:39:01.431896: Current learning rate: 0.003 
2025-02-21 20:39:33.339031: train_loss -0.9425 
2025-02-21 20:39:33.339361: val_loss -0.9558 
2025-02-21 20:39:33.339409: Pseudo dice [0.9818] 
2025-02-21 20:39:33.339449: Epoch time: 31.91 s 
2025-02-21 20:39:34.126816:  
2025-02-21 20:39:34.127016: Epoch 739 
2025-02-21 20:39:34.127093: Current learning rate: 0.00299 
2025-02-21 20:40:06.020280: train_loss -0.9415 
2025-02-21 20:40:06.020416: val_loss -0.9519 
2025-02-21 20:40:06.020455: Pseudo dice [0.9813] 
2025-02-21 20:40:06.020494: Epoch time: 31.89 s 
2025-02-21 20:40:06.752055:  
2025-02-21 20:40:06.752238: Epoch 740 
2025-02-21 20:40:06.752289: Current learning rate: 0.00297 
2025-02-21 20:40:38.634965: train_loss -0.95 
2025-02-21 20:40:38.635128: val_loss -0.958 
2025-02-21 20:40:38.635170: Pseudo dice [0.9836] 
2025-02-21 20:40:38.635209: Epoch time: 31.88 s 
2025-02-21 20:40:39.366293:  
2025-02-21 20:40:39.366472: Epoch 741 
2025-02-21 20:40:39.366579: Current learning rate: 0.00296 
2025-02-21 20:41:11.145344: train_loss -0.9572 
2025-02-21 20:41:11.145602: val_loss -0.9607 
2025-02-21 20:41:11.145652: Pseudo dice [0.9847] 
2025-02-21 20:41:11.145723: Epoch time: 31.78 s 
2025-02-21 20:41:11.885056:  
2025-02-21 20:41:11.885267: Epoch 742 
2025-02-21 20:41:11.885337: Current learning rate: 0.00295 
2025-02-21 20:41:43.610870: train_loss -0.9466 
2025-02-21 20:41:43.611007: val_loss -0.9655 
2025-02-21 20:41:43.611043: Pseudo dice [0.9859] 
2025-02-21 20:41:43.611082: Epoch time: 31.73 s 
2025-02-21 20:41:44.347699:  
2025-02-21 20:41:44.347885: Epoch 743 
2025-02-21 20:41:44.347939: Current learning rate: 0.00294 
2025-02-21 20:42:16.577746: train_loss -0.9527 
2025-02-21 20:42:16.578129: val_loss -0.9518 
2025-02-21 20:42:16.578183: Pseudo dice [0.9797] 
2025-02-21 20:42:16.578228: Epoch time: 32.23 s 
2025-02-21 20:42:17.323480:  
2025-02-21 20:42:17.323651: Epoch 744 
2025-02-21 20:42:17.323720: Current learning rate: 0.00293 
2025-02-21 20:42:48.804257: train_loss -0.9428 
2025-02-21 20:42:48.804420: val_loss -0.9607 
2025-02-21 20:42:48.804468: Pseudo dice [0.9835] 
2025-02-21 20:42:48.804510: Epoch time: 31.48 s 
2025-02-21 20:42:49.539886:  
2025-02-21 20:42:49.540089: Epoch 745 
2025-02-21 20:42:49.540166: Current learning rate: 0.00292 
2025-02-21 20:43:21.955237: train_loss -0.9286 
2025-02-21 20:43:21.955680: val_loss -0.9653 
2025-02-21 20:43:21.955764: Pseudo dice [0.986] 
2025-02-21 20:43:21.955851: Epoch time: 32.42 s 
2025-02-21 20:43:22.892376:  
2025-02-21 20:43:22.892576: Epoch 746 
2025-02-21 20:43:22.892732: Current learning rate: 0.00291 
2025-02-21 20:43:55.320030: train_loss -0.9529 
2025-02-21 20:43:55.320220: val_loss -0.9663 
2025-02-21 20:43:55.320284: Pseudo dice [0.9864] 
2025-02-21 20:43:55.320359: Epoch time: 32.43 s 
2025-02-21 20:43:56.087670:  
2025-02-21 20:43:56.087884: Epoch 747 
2025-02-21 20:43:56.087969: Current learning rate: 0.0029 
2025-02-21 20:44:27.770133: train_loss -0.9413 
2025-02-21 20:44:27.770380: val_loss -0.9487 
2025-02-21 20:44:27.770434: Pseudo dice [0.9821] 
2025-02-21 20:44:27.770476: Epoch time: 31.68 s 
2025-02-21 20:44:28.569557:  
2025-02-21 20:44:28.569700: Epoch 748 
2025-02-21 20:44:28.569783: Current learning rate: 0.00289 
2025-02-21 20:45:00.571498: train_loss -0.9463 
2025-02-21 20:45:00.571626: val_loss -0.9586 
2025-02-21 20:45:00.571668: Pseudo dice [0.9845] 
2025-02-21 20:45:00.571725: Epoch time: 32.0 s 
2025-02-21 20:45:01.304827:  
2025-02-21 20:45:01.304989: Epoch 749 
2025-02-21 20:45:01.305069: Current learning rate: 0.00288 
2025-02-21 20:45:33.272401: train_loss -0.9431 
2025-02-21 20:45:33.272575: val_loss -0.9606 
2025-02-21 20:45:33.272668: Pseudo dice [0.9851] 
2025-02-21 20:45:33.272714: Epoch time: 31.97 s 
2025-02-21 20:45:34.971094:  
2025-02-21 20:45:34.971317: Epoch 750 
2025-02-21 20:45:34.971413: Current learning rate: 0.00287 
2025-02-21 20:46:06.384831: train_loss -0.9501 
2025-02-21 20:46:06.384979: val_loss -0.9468 
2025-02-21 20:46:06.385021: Pseudo dice [0.9798] 
2025-02-21 20:46:06.385062: Epoch time: 31.41 s 
2025-02-21 20:46:07.119223:  
2025-02-21 20:46:07.119488: Epoch 751 
2025-02-21 20:46:07.119556: Current learning rate: 0.00286 
2025-02-21 20:46:38.614089: train_loss -0.9496 
2025-02-21 20:46:38.614222: val_loss -0.9531 
2025-02-21 20:46:38.614268: Pseudo dice [0.9803] 
2025-02-21 20:46:38.614311: Epoch time: 31.5 s 
2025-02-21 20:46:39.334934:  
2025-02-21 20:46:39.335127: Epoch 752 
2025-02-21 20:46:39.335219: Current learning rate: 0.00285 
2025-02-21 20:47:10.673422: train_loss -0.9537 
2025-02-21 20:47:10.673564: val_loss -0.9657 
2025-02-21 20:47:10.673601: Pseudo dice [0.9867] 
2025-02-21 20:47:10.673651: Epoch time: 31.34 s 
2025-02-21 20:47:11.392135:  
2025-02-21 20:47:11.392344: Epoch 753 
2025-02-21 20:47:11.392420: Current learning rate: 0.00284 
2025-02-21 20:47:42.886803: train_loss -0.9451 
2025-02-21 20:47:42.886942: val_loss -0.9573 
2025-02-21 20:47:42.886978: Pseudo dice [0.9826] 
2025-02-21 20:47:42.887015: Epoch time: 31.5 s 
2025-02-21 20:47:43.614111:  
2025-02-21 20:47:43.614292: Epoch 754 
2025-02-21 20:47:43.614360: Current learning rate: 0.00283 
2025-02-21 20:48:14.985463: train_loss -0.9405 
2025-02-21 20:48:14.985696: val_loss -0.9601 
2025-02-21 20:48:14.985740: Pseudo dice [0.9845] 
2025-02-21 20:48:14.985783: Epoch time: 31.37 s 
2025-02-21 20:48:15.734782:  
2025-02-21 20:48:15.735082: Epoch 755 
2025-02-21 20:48:15.735171: Current learning rate: 0.00282 
2025-02-21 20:48:47.103499: train_loss -0.9483 
2025-02-21 20:48:47.103653: val_loss -0.9643 
2025-02-21 20:48:47.103691: Pseudo dice [0.9856] 
2025-02-21 20:48:47.103729: Epoch time: 31.37 s 
2025-02-21 20:48:47.835805:  
2025-02-21 20:48:47.836010: Epoch 756 
2025-02-21 20:48:47.836141: Current learning rate: 0.00281 
2025-02-21 20:49:19.233064: train_loss -0.9524 
2025-02-21 20:49:19.233195: val_loss -0.9601 
2025-02-21 20:49:19.233232: Pseudo dice [0.9838] 
2025-02-21 20:49:19.233270: Epoch time: 31.4 s 
2025-02-21 20:49:19.959249:  
2025-02-21 20:49:19.959454: Epoch 757 
2025-02-21 20:49:19.959535: Current learning rate: 0.0028 
2025-02-21 20:49:51.396930: train_loss -0.9535 
2025-02-21 20:49:51.397180: val_loss -0.9575 
2025-02-21 20:49:51.397241: Pseudo dice [0.9828] 
2025-02-21 20:49:51.397287: Epoch time: 31.44 s 
2025-02-21 20:49:52.182293:  
2025-02-21 20:49:52.182502: Epoch 758 
2025-02-21 20:49:52.182585: Current learning rate: 0.00279 
2025-02-21 20:50:23.786850: train_loss -0.9422 
2025-02-21 20:50:23.786981: val_loss -0.9619 
2025-02-21 20:50:23.787018: Pseudo dice [0.983] 
2025-02-21 20:50:23.787053: Epoch time: 31.61 s 
2025-02-21 20:50:24.520479:  
2025-02-21 20:50:24.520670: Epoch 759 
2025-02-21 20:50:24.520745: Current learning rate: 0.00278 
2025-02-21 20:50:55.928707: train_loss -0.948 
2025-02-21 20:50:55.928905: val_loss -0.9663 
2025-02-21 20:50:55.928953: Pseudo dice [0.9867] 
2025-02-21 20:50:55.928995: Epoch time: 31.41 s 
2025-02-21 20:50:56.667035:  
2025-02-21 20:50:56.667270: Epoch 760 
2025-02-21 20:50:56.667353: Current learning rate: 0.00277 
2025-02-21 20:51:28.062867: train_loss -0.9404 
2025-02-21 20:51:28.062985: val_loss -0.9612 
2025-02-21 20:51:28.063023: Pseudo dice [0.9846] 
2025-02-21 20:51:28.063060: Epoch time: 31.4 s 
2025-02-21 20:51:28.790017:  
2025-02-21 20:51:28.790199: Epoch 761 
2025-02-21 20:51:28.790277: Current learning rate: 0.00276 
2025-02-21 20:52:00.318491: train_loss -0.9291 
2025-02-21 20:52:00.318635: val_loss -0.9627 
2025-02-21 20:52:00.318673: Pseudo dice [0.9861] 
2025-02-21 20:52:00.318712: Epoch time: 31.53 s 
2025-02-21 20:52:01.041969:  
2025-02-21 20:52:01.042134: Epoch 762 
2025-02-21 20:52:01.042208: Current learning rate: 0.00275 
2025-02-21 20:52:32.412408: train_loss -0.9523 
2025-02-21 20:52:32.412560: val_loss -0.967 
2025-02-21 20:52:32.412599: Pseudo dice [0.9875] 
2025-02-21 20:52:32.412642: Epoch time: 31.37 s 
2025-02-21 20:52:32.412671: Yayy! New best EMA pseudo Dice: 0.9846 
2025-02-21 20:52:33.458109:  
2025-02-21 20:52:33.458257: Epoch 763 
2025-02-21 20:52:33.458346: Current learning rate: 0.00274 
2025-02-21 20:53:05.094286: train_loss -0.9551 
2025-02-21 20:53:05.094430: val_loss -0.9643 
2025-02-21 20:53:05.094485: Pseudo dice [0.9859] 
2025-02-21 20:53:05.094524: Epoch time: 31.64 s 
2025-02-21 20:53:05.094553: Yayy! New best EMA pseudo Dice: 0.9847 
2025-02-21 20:53:06.176183:  
2025-02-21 20:53:06.176366: Epoch 764 
2025-02-21 20:53:06.176452: Current learning rate: 0.00273 
2025-02-21 20:53:37.532579: train_loss -0.9501 
2025-02-21 20:53:37.532734: val_loss -0.9611 
2025-02-21 20:53:37.532778: Pseudo dice [0.9839] 
2025-02-21 20:53:37.532822: Epoch time: 31.36 s 
2025-02-21 20:53:38.259792:  
2025-02-21 20:53:38.259955: Epoch 765 
2025-02-21 20:53:38.260031: Current learning rate: 0.00272 
2025-02-21 20:54:09.713083: train_loss -0.9364 
2025-02-21 20:54:09.713305: val_loss -0.9611 
2025-02-21 20:54:09.713355: Pseudo dice [0.9854] 
2025-02-21 20:54:09.713396: Epoch time: 31.45 s 
2025-02-21 20:54:11.256963:  
2025-02-21 20:54:11.257159: Epoch 766 
2025-02-21 20:54:11.257266: Current learning rate: 0.00271 
2025-02-21 20:54:42.753191: train_loss -0.9513 
2025-02-21 20:54:42.753347: val_loss -0.9497 
2025-02-21 20:54:42.753388: Pseudo dice [0.9804] 
2025-02-21 20:54:42.753427: Epoch time: 31.5 s 
2025-02-21 20:54:43.488499:  
2025-02-21 20:54:43.488737: Epoch 767 
2025-02-21 20:54:43.488816: Current learning rate: 0.0027 
2025-02-21 20:55:14.951216: train_loss -0.9318 
2025-02-21 20:55:14.951403: val_loss -0.9557 
2025-02-21 20:55:14.951440: Pseudo dice [0.9842] 
2025-02-21 20:55:14.951507: Epoch time: 31.46 s 
2025-02-21 20:55:15.819350:  
2025-02-21 20:55:15.819518: Epoch 768 
2025-02-21 20:55:15.819590: Current learning rate: 0.00268 
2025-02-21 20:55:47.529413: train_loss -0.9523 
2025-02-21 20:55:47.529774: val_loss -0.9545 
2025-02-21 20:55:47.529828: Pseudo dice [0.9829] 
2025-02-21 20:55:47.529869: Epoch time: 31.71 s 
2025-02-21 20:55:48.261141:  
2025-02-21 20:55:48.261330: Epoch 769 
2025-02-21 20:55:48.261394: Current learning rate: 0.00267 
2025-02-21 20:56:19.863729: train_loss -0.9475 
2025-02-21 20:56:19.863938: val_loss -0.9566 
2025-02-21 20:56:19.863982: Pseudo dice [0.9838] 
2025-02-21 20:56:19.864022: Epoch time: 31.6 s 
2025-02-21 20:56:20.596363:  
2025-02-21 20:56:20.596521: Epoch 770 
2025-02-21 20:56:20.596594: Current learning rate: 0.00266 
2025-02-21 20:56:52.417673: train_loss -0.958 
2025-02-21 20:56:52.417843: val_loss -0.9554 
2025-02-21 20:56:52.417882: Pseudo dice [0.9828] 
2025-02-21 20:56:52.417922: Epoch time: 31.82 s 
2025-02-21 20:56:53.222421:  
2025-02-21 20:56:53.222609: Epoch 771 
2025-02-21 20:56:53.222698: Current learning rate: 0.00265 
2025-02-21 20:57:24.638678: train_loss -0.9534 
2025-02-21 20:57:24.638898: val_loss -0.9575 
2025-02-21 20:57:24.638945: Pseudo dice [0.9841] 
2025-02-21 20:57:24.638988: Epoch time: 31.42 s 
2025-02-21 20:57:25.414765:  
2025-02-21 20:57:25.414966: Epoch 772 
2025-02-21 20:57:25.415074: Current learning rate: 0.00264 
2025-02-21 20:57:57.720562: train_loss -0.936 
2025-02-21 20:57:57.720839: val_loss -0.9651 
2025-02-21 20:57:57.720892: Pseudo dice [0.9859] 
2025-02-21 20:57:57.720950: Epoch time: 32.31 s 
2025-02-21 20:57:58.481114:  
2025-02-21 20:57:58.481272: Epoch 773 
2025-02-21 20:57:58.481348: Current learning rate: 0.00263 
2025-02-21 20:58:29.861634: train_loss -0.9403 
2025-02-21 20:58:29.861825: val_loss -0.956 
2025-02-21 20:58:29.861877: Pseudo dice [0.9841] 
2025-02-21 20:58:29.861915: Epoch time: 31.38 s 
2025-02-21 20:58:30.747012:  
2025-02-21 20:58:30.747248: Epoch 774 
2025-02-21 20:58:30.747358: Current learning rate: 0.00262 
2025-02-21 20:59:02.324116: train_loss -0.9539 
2025-02-21 20:59:02.324363: val_loss -0.9614 
2025-02-21 20:59:02.324433: Pseudo dice [0.9837] 
2025-02-21 20:59:02.324483: Epoch time: 31.58 s 
2025-02-21 20:59:03.195284:  
2025-02-21 20:59:03.195465: Epoch 775 
2025-02-21 20:59:03.195589: Current learning rate: 0.00261 
2025-02-21 20:59:34.859266: train_loss -0.9539 
2025-02-21 20:59:34.859397: val_loss -0.9566 
2025-02-21 20:59:34.859436: Pseudo dice [0.9835] 
2025-02-21 20:59:34.859474: Epoch time: 31.66 s 
2025-02-21 20:59:35.590800:  
2025-02-21 20:59:35.590979: Epoch 776 
2025-02-21 20:59:35.591056: Current learning rate: 0.0026 
2025-02-21 21:00:07.628255: train_loss -0.9491 
2025-02-21 21:00:07.628481: val_loss -0.9649 
2025-02-21 21:00:07.628525: Pseudo dice [0.9854] 
2025-02-21 21:00:07.628563: Epoch time: 32.04 s 
2025-02-21 21:00:08.376067:  
2025-02-21 21:00:08.376251: Epoch 777 
2025-02-21 21:00:08.376324: Current learning rate: 0.00259 
2025-02-21 21:00:40.027664: train_loss -0.9533 
2025-02-21 21:00:40.027791: val_loss -0.956 
2025-02-21 21:00:40.027839: Pseudo dice [0.9822] 
2025-02-21 21:00:40.027888: Epoch time: 31.65 s 
2025-02-21 21:00:40.763457:  
2025-02-21 21:00:40.763546: Epoch 778 
2025-02-21 21:00:40.763619: Current learning rate: 0.00258 
2025-02-21 21:01:12.188059: train_loss -0.9454 
2025-02-21 21:01:12.188222: val_loss -0.9613 
2025-02-21 21:01:12.188293: Pseudo dice [0.9848] 
2025-02-21 21:01:12.188334: Epoch time: 31.43 s 
2025-02-21 21:01:12.985226:  
2025-02-21 21:01:12.985383: Epoch 779 
2025-02-21 21:01:12.985451: Current learning rate: 0.00257 
2025-02-21 21:01:45.160628: train_loss -0.9568 
2025-02-21 21:01:45.160767: val_loss -0.9505 
2025-02-21 21:01:45.160825: Pseudo dice [0.9821] 
2025-02-21 21:01:45.160879: Epoch time: 32.18 s 
2025-02-21 21:01:45.893559:  
2025-02-21 21:01:45.893763: Epoch 780 
2025-02-21 21:01:45.893838: Current learning rate: 0.00256 
2025-02-21 21:02:17.737841: train_loss -0.9257 
2025-02-21 21:02:17.738045: val_loss -0.9539 
2025-02-21 21:02:17.738110: Pseudo dice [0.9822] 
2025-02-21 21:02:17.738170: Epoch time: 31.84 s 
2025-02-21 21:02:18.536614:  
2025-02-21 21:02:18.536812: Epoch 781 
2025-02-21 21:02:18.536898: Current learning rate: 0.00255 
2025-02-21 21:02:50.210434: train_loss -0.9386 
2025-02-21 21:02:50.210576: val_loss -0.9606 
2025-02-21 21:02:50.210614: Pseudo dice [0.9849] 
2025-02-21 21:02:50.210654: Epoch time: 31.67 s 
2025-02-21 21:02:51.689636:  
2025-02-21 21:02:51.689907: Epoch 782 
2025-02-21 21:02:51.690084: Current learning rate: 0.00254 
2025-02-21 21:03:23.613476: train_loss -0.9368 
2025-02-21 21:03:23.613622: val_loss -0.9465 
2025-02-21 21:03:23.613659: Pseudo dice [0.9796] 
2025-02-21 21:03:23.613696: Epoch time: 31.92 s 
2025-02-21 21:03:24.373013:  
2025-02-21 21:03:24.373239: Epoch 783 
2025-02-21 21:03:24.373315: Current learning rate: 0.00253 
2025-02-21 21:03:56.489458: train_loss -0.9396 
2025-02-21 21:03:56.489857: val_loss -0.9518 
2025-02-21 21:03:56.489899: Pseudo dice [0.9802] 
2025-02-21 21:03:56.489938: Epoch time: 32.12 s 
2025-02-21 21:03:57.221402:  
2025-02-21 21:03:57.221549: Epoch 784 
2025-02-21 21:03:57.221597: Current learning rate: 0.00252 
2025-02-21 21:04:29.348988: train_loss -0.9508 
2025-02-21 21:04:29.349137: val_loss -0.9619 
2025-02-21 21:04:29.349175: Pseudo dice [0.9856] 
2025-02-21 21:04:29.349216: Epoch time: 32.13 s 
2025-02-21 21:04:30.086389:  
2025-02-21 21:04:30.086616: Epoch 785 
2025-02-21 21:04:30.086693: Current learning rate: 0.00251 
2025-02-21 21:05:01.523703: train_loss -0.9521 
2025-02-21 21:05:01.524065: val_loss -0.9482 
2025-02-21 21:05:01.524133: Pseudo dice [0.9805] 
2025-02-21 21:05:01.524179: Epoch time: 31.44 s 
2025-02-21 21:05:02.264446:  
2025-02-21 21:05:02.264604: Epoch 786 
2025-02-21 21:05:02.264684: Current learning rate: 0.0025 
2025-02-21 21:05:34.494532: train_loss -0.9449 
2025-02-21 21:05:34.494710: val_loss -0.959 
2025-02-21 21:05:34.494753: Pseudo dice [0.9845] 
2025-02-21 21:05:34.494793: Epoch time: 32.23 s 
2025-02-21 21:05:35.418691:  
2025-02-21 21:05:35.418864: Epoch 787 
2025-02-21 21:05:35.418964: Current learning rate: 0.00249 
2025-02-21 21:06:07.344791: train_loss -0.9479 
2025-02-21 21:06:07.344939: val_loss -0.9531 
2025-02-21 21:06:07.345018: Pseudo dice [0.9824] 
2025-02-21 21:06:07.345061: Epoch time: 31.93 s 
2025-02-21 21:06:08.093893:  
2025-02-21 21:06:08.094086: Epoch 788 
2025-02-21 21:06:08.094164: Current learning rate: 0.00248 
2025-02-21 21:06:40.156854: train_loss -0.9459 
2025-02-21 21:06:40.157169: val_loss -0.9629 
2025-02-21 21:06:40.157217: Pseudo dice [0.9862] 
2025-02-21 21:06:40.157259: Epoch time: 32.06 s 
2025-02-21 21:06:40.904327:  
2025-02-21 21:06:40.904484: Epoch 789 
2025-02-21 21:06:40.904572: Current learning rate: 0.00247 
2025-02-21 21:07:13.028637: train_loss -0.9342 
2025-02-21 21:07:13.028792: val_loss -0.9471 
2025-02-21 21:07:13.028842: Pseudo dice [0.9783] 
2025-02-21 21:07:13.028881: Epoch time: 32.13 s 
2025-02-21 21:07:13.772325:  
2025-02-21 21:07:13.772506: Epoch 790 
2025-02-21 21:07:13.772582: Current learning rate: 0.00245 
2025-02-21 21:07:45.764412: train_loss -0.9501 
2025-02-21 21:07:45.764652: val_loss -0.9627 
2025-02-21 21:07:45.764696: Pseudo dice [0.9856] 
2025-02-21 21:07:45.764733: Epoch time: 31.99 s 
2025-02-21 21:07:46.650013:  
2025-02-21 21:07:46.650205: Epoch 791 
2025-02-21 21:07:46.650286: Current learning rate: 0.00244 
2025-02-21 21:08:18.726629: train_loss -0.9234 
2025-02-21 21:08:18.726944: val_loss -0.952 
2025-02-21 21:08:18.727011: Pseudo dice [0.982] 
2025-02-21 21:08:18.727068: Epoch time: 32.08 s 
2025-02-21 21:08:19.677029:  
2025-02-21 21:08:19.677166: Epoch 792 
2025-02-21 21:08:19.677241: Current learning rate: 0.00243 
2025-02-21 21:08:51.690363: train_loss -0.9473 
2025-02-21 21:08:51.690512: val_loss -0.946 
2025-02-21 21:08:51.690604: Pseudo dice [0.9792] 
2025-02-21 21:08:51.690646: Epoch time: 32.01 s 
2025-02-21 21:08:52.427871:  
2025-02-21 21:08:52.428065: Epoch 793 
2025-02-21 21:08:52.428139: Current learning rate: 0.00242 
2025-02-21 21:09:24.365508: train_loss -0.9366 
2025-02-21 21:09:24.365750: val_loss -0.9615 
2025-02-21 21:09:24.365793: Pseudo dice [0.9847] 
2025-02-21 21:09:24.365839: Epoch time: 31.94 s 
2025-02-21 21:09:25.102062:  
2025-02-21 21:09:25.102219: Epoch 794 
2025-02-21 21:09:25.102292: Current learning rate: 0.00241 
2025-02-21 21:09:57.962215: train_loss -0.944 
2025-02-21 21:09:57.962548: val_loss -0.9571 
2025-02-21 21:09:57.962590: Pseudo dice [0.9826] 
2025-02-21 21:09:57.962640: Epoch time: 32.86 s 
2025-02-21 21:09:58.939487:  
2025-02-21 21:09:58.939664: Epoch 795 
2025-02-21 21:09:58.939782: Current learning rate: 0.0024 
2025-02-21 21:10:31.867793: train_loss -0.9523 
2025-02-21 21:10:31.868186: val_loss -0.9615 
2025-02-21 21:10:31.868229: Pseudo dice [0.9849] 
2025-02-21 21:10:31.868274: Epoch time: 32.93 s 
2025-02-21 21:10:32.753228:  
2025-02-21 21:10:32.753442: Epoch 796 
2025-02-21 21:10:32.753556: Current learning rate: 0.00239 
2025-02-21 21:11:05.246416: train_loss -0.9552 
2025-02-21 21:11:05.246554: val_loss -0.9626 
2025-02-21 21:11:05.246591: Pseudo dice [0.9845] 
2025-02-21 21:11:05.246634: Epoch time: 32.49 s 
2025-02-21 21:11:05.999944:  
2025-02-21 21:11:06.000173: Epoch 797 
2025-02-21 21:11:06.000251: Current learning rate: 0.00238 
2025-02-21 21:11:38.648571: train_loss -0.947 
2025-02-21 21:11:38.648867: val_loss -0.9604 
2025-02-21 21:11:38.648928: Pseudo dice [0.9834] 
2025-02-21 21:11:38.648971: Epoch time: 32.65 s 
2025-02-21 21:11:39.552073:  
2025-02-21 21:11:39.552286: Epoch 798 
2025-02-21 21:11:39.552402: Current learning rate: 0.00237 
2025-02-21 21:12:11.400376: train_loss -0.9448 
2025-02-21 21:12:11.400722: val_loss -0.9539 
2025-02-21 21:12:11.400765: Pseudo dice [0.9828] 
2025-02-21 21:12:11.400805: Epoch time: 31.85 s 
2025-02-21 21:12:12.965342:  
2025-02-21 21:12:12.965570: Epoch 799 
2025-02-21 21:12:12.965718: Current learning rate: 0.00236 
2025-02-21 21:12:46.461510: train_loss -0.9516 
2025-02-21 21:12:46.461659: val_loss -0.9619 
2025-02-21 21:12:46.461702: Pseudo dice [0.9846] 
2025-02-21 21:12:46.461743: Epoch time: 33.5 s 
2025-02-21 21:12:47.531506:  
2025-02-21 21:12:47.531708: Epoch 800 
2025-02-21 21:12:47.531776: Current learning rate: 0.00235 
2025-02-21 21:13:18.974196: train_loss -0.9494 
2025-02-21 21:13:18.974379: val_loss -0.9573 
2025-02-21 21:13:18.974421: Pseudo dice [0.9841] 
2025-02-21 21:13:18.974463: Epoch time: 31.44 s 
2025-02-21 21:13:19.704477:  
2025-02-21 21:13:19.704682: Epoch 801 
2025-02-21 21:13:19.704752: Current learning rate: 0.00234 
2025-02-21 21:13:51.258038: train_loss -0.9286 
2025-02-21 21:13:51.258177: val_loss -0.9573 
2025-02-21 21:13:51.258263: Pseudo dice [0.9825] 
2025-02-21 21:13:51.258332: Epoch time: 31.55 s 
2025-02-21 21:13:51.990749:  
2025-02-21 21:13:51.990918: Epoch 802 
2025-02-21 21:13:51.991004: Current learning rate: 0.00233 
2025-02-21 21:14:23.384851: train_loss -0.9461 
2025-02-21 21:14:23.385010: val_loss -0.9652 
2025-02-21 21:14:23.385051: Pseudo dice [0.9868] 
2025-02-21 21:14:23.385113: Epoch time: 31.39 s 
2025-02-21 21:14:24.160830:  
2025-02-21 21:14:24.160979: Epoch 803 
2025-02-21 21:14:24.161096: Current learning rate: 0.00232 
2025-02-21 21:14:55.725233: train_loss -0.9547 
2025-02-21 21:14:55.725394: val_loss -0.9629 
2025-02-21 21:14:55.725445: Pseudo dice [0.9858] 
2025-02-21 21:14:55.725482: Epoch time: 31.57 s 
2025-02-21 21:14:56.468605:  
2025-02-21 21:14:56.468785: Epoch 804 
2025-02-21 21:14:56.468905: Current learning rate: 0.00231 
2025-02-21 21:15:27.848769: train_loss -0.925 
2025-02-21 21:15:27.848924: val_loss -0.9605 
2025-02-21 21:15:27.848964: Pseudo dice [0.9859] 
2025-02-21 21:15:27.849007: Epoch time: 31.38 s 
2025-02-21 21:15:28.589387:  
2025-02-21 21:15:28.589612: Epoch 805 
2025-02-21 21:15:28.589683: Current learning rate: 0.0023 
2025-02-21 21:15:59.949616: train_loss -0.9528 
2025-02-21 21:15:59.949745: val_loss -0.9627 
2025-02-21 21:15:59.949783: Pseudo dice [0.9847] 
2025-02-21 21:15:59.949825: Epoch time: 31.36 s 
2025-02-21 21:16:00.683064:  
2025-02-21 21:16:00.683206: Epoch 806 
2025-02-21 21:16:00.683250: Current learning rate: 0.00229 
2025-02-21 21:16:32.102534: train_loss -0.9609 
2025-02-21 21:16:32.102697: val_loss -0.9645 
2025-02-21 21:16:32.102755: Pseudo dice [0.9855] 
2025-02-21 21:16:32.102834: Epoch time: 31.42 s 
2025-02-21 21:16:32.841848:  
2025-02-21 21:16:32.842004: Epoch 807 
2025-02-21 21:16:32.842066: Current learning rate: 0.00228 
2025-02-21 21:17:04.431159: train_loss -0.9389 
2025-02-21 21:17:04.431287: val_loss -0.9538 
2025-02-21 21:17:04.431324: Pseudo dice [0.9824] 
2025-02-21 21:17:04.431361: Epoch time: 31.59 s 
2025-02-21 21:17:05.162883:  
2025-02-21 21:17:05.163070: Epoch 808 
2025-02-21 21:17:05.163140: Current learning rate: 0.00226 
2025-02-21 21:17:36.475067: train_loss -0.9433 
2025-02-21 21:17:36.475239: val_loss -0.9578 
2025-02-21 21:17:36.475276: Pseudo dice [0.9827] 
2025-02-21 21:17:36.475318: Epoch time: 31.31 s 
2025-02-21 21:17:37.211285:  
2025-02-21 21:17:37.211494: Epoch 809 
2025-02-21 21:17:37.211558: Current learning rate: 0.00225 
2025-02-21 21:18:08.640446: train_loss -0.9362 
2025-02-21 21:18:08.640580: val_loss -0.9609 
2025-02-21 21:18:08.640618: Pseudo dice [0.9857] 
2025-02-21 21:18:08.640663: Epoch time: 31.43 s 
2025-02-21 21:18:09.382304:  
2025-02-21 21:18:09.382507: Epoch 810 
2025-02-21 21:18:09.382585: Current learning rate: 0.00224 
2025-02-21 21:18:40.939280: train_loss -0.9507 
2025-02-21 21:18:40.939415: val_loss -0.9659 
2025-02-21 21:18:40.939454: Pseudo dice [0.9868] 
2025-02-21 21:18:40.939492: Epoch time: 31.56 s 
2025-02-21 21:18:41.683815:  
2025-02-21 21:18:41.684009: Epoch 811 
2025-02-21 21:18:41.684109: Current learning rate: 0.00223 
2025-02-21 21:19:13.076574: train_loss -0.9505 
2025-02-21 21:19:13.076733: val_loss -0.9597 
2025-02-21 21:19:13.076777: Pseudo dice [0.9843] 
2025-02-21 21:19:13.076821: Epoch time: 31.39 s 
2025-02-21 21:19:13.815595:  
2025-02-21 21:19:13.815768: Epoch 812 
2025-02-21 21:19:13.815845: Current learning rate: 0.00222 
2025-02-21 21:19:45.783295: train_loss -0.9406 
2025-02-21 21:19:45.783451: val_loss -0.9636 
2025-02-21 21:19:45.783490: Pseudo dice [0.9849] 
2025-02-21 21:19:45.783529: Epoch time: 31.97 s 
2025-02-21 21:19:46.516197:  
2025-02-21 21:19:46.516337: Epoch 813 
2025-02-21 21:19:46.516404: Current learning rate: 0.00221 
2025-02-21 21:20:18.011832: train_loss -0.9548 
2025-02-21 21:20:18.011958: val_loss -0.9642 
2025-02-21 21:20:18.011995: Pseudo dice [0.9862] 
2025-02-21 21:20:18.012053: Epoch time: 31.5 s 
2025-02-21 21:20:18.742881:  
2025-02-21 21:20:18.743057: Epoch 814 
2025-02-21 21:20:18.743134: Current learning rate: 0.0022 
2025-02-21 21:20:50.291488: train_loss -0.9473 
2025-02-21 21:20:50.291653: val_loss -0.9681 
2025-02-21 21:20:50.291708: Pseudo dice [0.9865] 
2025-02-21 21:20:50.291752: Epoch time: 31.55 s 
2025-02-21 21:20:50.291787: Yayy! New best EMA pseudo Dice: 0.9848 
2025-02-21 21:20:51.990163:  
2025-02-21 21:20:51.990343: Epoch 815 
2025-02-21 21:20:51.990423: Current learning rate: 0.00219 
2025-02-21 21:21:23.629722: train_loss -0.9316 
2025-02-21 21:21:23.629938: val_loss -0.952 
2025-02-21 21:21:23.630010: Pseudo dice [0.9827] 
2025-02-21 21:21:23.630072: Epoch time: 31.64 s 
2025-02-21 21:21:24.369684:  
2025-02-21 21:21:24.369855: Epoch 816 
2025-02-21 21:21:24.369980: Current learning rate: 0.00218 
2025-02-21 21:21:56.275501: train_loss -0.9556 
2025-02-21 21:21:56.275671: val_loss -0.9554 
2025-02-21 21:21:56.275711: Pseudo dice [0.9819] 
2025-02-21 21:21:56.275749: Epoch time: 31.91 s 
2025-02-21 21:21:57.016497:  
2025-02-21 21:21:57.016683: Epoch 817 
2025-02-21 21:21:57.016751: Current learning rate: 0.00217 
2025-02-21 21:22:28.663515: train_loss -0.9391 
2025-02-21 21:22:28.663753: val_loss -0.9621 
2025-02-21 21:22:28.663803: Pseudo dice [0.9853] 
2025-02-21 21:22:28.663865: Epoch time: 31.65 s 
2025-02-21 21:22:29.439123:  
2025-02-21 21:22:29.439342: Epoch 818 
2025-02-21 21:22:29.439445: Current learning rate: 0.00216 
2025-02-21 21:23:01.354448: train_loss -0.9487 
2025-02-21 21:23:01.354594: val_loss -0.9507 
2025-02-21 21:23:01.354641: Pseudo dice [0.9804] 
2025-02-21 21:23:01.354681: Epoch time: 31.92 s 
2025-02-21 21:23:02.090591:  
2025-02-21 21:23:02.090782: Epoch 819 
2025-02-21 21:23:02.090860: Current learning rate: 0.00215 
2025-02-21 21:23:34.163920: train_loss -0.9463 
2025-02-21 21:23:34.164057: val_loss -0.9601 
2025-02-21 21:23:34.164096: Pseudo dice [0.9844] 
2025-02-21 21:23:34.164136: Epoch time: 32.07 s 
2025-02-21 21:23:34.869252:  
2025-02-21 21:23:34.869442: Epoch 820 
2025-02-21 21:23:34.869498: Current learning rate: 0.00214 
2025-02-21 21:24:06.671076: train_loss -0.9391 
2025-02-21 21:24:06.671337: val_loss -0.9683 
2025-02-21 21:24:06.671382: Pseudo dice [0.9882] 
2025-02-21 21:24:06.671423: Epoch time: 31.8 s 
2025-02-21 21:24:07.369883:  
2025-02-21 21:24:07.370083: Epoch 821 
2025-02-21 21:24:07.370137: Current learning rate: 0.00213 
2025-02-21 21:24:38.996952: train_loss -0.9491 
2025-02-21 21:24:38.997126: val_loss -0.9699 
2025-02-21 21:24:38.997169: Pseudo dice [0.9876] 
2025-02-21 21:24:38.997212: Epoch time: 31.63 s 
2025-02-21 21:24:39.694244:  
2025-02-21 21:24:39.694410: Epoch 822 
2025-02-21 21:24:39.694479: Current learning rate: 0.00212 
2025-02-21 21:25:11.362682: train_loss -0.9357 
2025-02-21 21:25:11.362821: val_loss -0.9579 
2025-02-21 21:25:11.362863: Pseudo dice [0.984] 
2025-02-21 21:25:11.362900: Epoch time: 31.67 s 
2025-02-21 21:25:12.052899:  
2025-02-21 21:25:12.053071: Epoch 823 
2025-02-21 21:25:12.053139: Current learning rate: 0.0021 
2025-02-21 21:25:43.615962: train_loss -0.937 
2025-02-21 21:25:43.616085: val_loss -0.9604 
2025-02-21 21:25:43.616122: Pseudo dice [0.9853] 
2025-02-21 21:25:43.616163: Epoch time: 31.56 s 
2025-02-21 21:25:44.404800:  
2025-02-21 21:25:44.404965: Epoch 824 
2025-02-21 21:25:44.405094: Current learning rate: 0.00209 
2025-02-21 21:26:16.164803: train_loss -0.9426 
2025-02-21 21:26:16.165130: val_loss -0.9592 
2025-02-21 21:26:16.165229: Pseudo dice [0.9845] 
2025-02-21 21:26:16.165313: Epoch time: 31.76 s 
2025-02-21 21:26:17.001820:  
2025-02-21 21:26:17.002038: Epoch 825 
2025-02-21 21:26:17.002115: Current learning rate: 0.00208 
2025-02-21 21:26:48.831325: train_loss -0.9449 
2025-02-21 21:26:48.831554: val_loss -0.9574 
2025-02-21 21:26:48.831593: Pseudo dice [0.9841] 
2025-02-21 21:26:48.831639: Epoch time: 31.83 s 
2025-02-21 21:26:49.552736:  
2025-02-21 21:26:49.552897: Epoch 826 
2025-02-21 21:26:49.552997: Current learning rate: 0.00207 
2025-02-21 21:27:21.594383: train_loss -0.9529 
2025-02-21 21:27:21.594537: val_loss -0.9601 
2025-02-21 21:27:21.594605: Pseudo dice [0.9846] 
2025-02-21 21:27:21.594676: Epoch time: 32.04 s 
2025-02-21 21:27:22.300839:  
2025-02-21 21:27:22.300982: Epoch 827 
2025-02-21 21:27:22.301048: Current learning rate: 0.00206 
2025-02-21 21:27:54.050472: train_loss -0.9442 
2025-02-21 21:27:54.050622: val_loss -0.962 
2025-02-21 21:27:54.050658: Pseudo dice [0.9844] 
2025-02-21 21:27:54.050699: Epoch time: 31.75 s 
2025-02-21 21:27:54.743538:  
2025-02-21 21:27:54.743686: Epoch 828 
2025-02-21 21:27:54.743785: Current learning rate: 0.00205 
2025-02-21 21:28:26.227335: train_loss -0.9477 
2025-02-21 21:28:26.227489: val_loss -0.9596 
2025-02-21 21:28:26.227526: Pseudo dice [0.9839] 
2025-02-21 21:28:26.227566: Epoch time: 31.48 s 
2025-02-21 21:28:27.055426:  
2025-02-21 21:28:27.055664: Epoch 829 
2025-02-21 21:28:27.055769: Current learning rate: 0.00204 
2025-02-21 21:28:59.524779: train_loss -0.9386 
2025-02-21 21:28:59.525008: val_loss -0.9535 
2025-02-21 21:28:59.525056: Pseudo dice [0.9824] 
2025-02-21 21:28:59.525117: Epoch time: 32.47 s 
2025-02-21 21:29:00.405333:  
2025-02-21 21:29:00.405520: Epoch 830 
2025-02-21 21:29:00.405601: Current learning rate: 0.00203 
2025-02-21 21:29:32.460828: train_loss -0.9478 
2025-02-21 21:29:32.460976: val_loss -0.9593 
2025-02-21 21:29:32.461015: Pseudo dice [0.984] 
2025-02-21 21:29:32.461053: Epoch time: 32.06 s 
2025-02-21 21:29:33.164629:  
2025-02-21 21:29:33.164818: Epoch 831 
2025-02-21 21:29:33.164891: Current learning rate: 0.00202 
2025-02-21 21:30:04.983597: train_loss -0.9551 
2025-02-21 21:30:04.983736: val_loss -0.9686 
2025-02-21 21:30:04.983774: Pseudo dice [0.9866] 
2025-02-21 21:30:04.983813: Epoch time: 31.82 s 
2025-02-21 21:30:06.378038:  
2025-02-21 21:30:06.378222: Epoch 832 
2025-02-21 21:30:06.378317: Current learning rate: 0.00201 
2025-02-21 21:30:38.692664: train_loss -0.9604 
2025-02-21 21:30:38.692978: val_loss -0.9699 
2025-02-21 21:30:38.693052: Pseudo dice [0.9874] 
2025-02-21 21:30:38.693098: Epoch time: 32.32 s 
2025-02-21 21:30:38.693130: Yayy! New best EMA pseudo Dice: 0.9848 
2025-02-21 21:30:39.765794:  
2025-02-21 21:30:39.765999: Epoch 833 
2025-02-21 21:30:39.766069: Current learning rate: 0.002 
2025-02-21 21:31:11.786279: train_loss -0.9486 
2025-02-21 21:31:11.786436: val_loss -0.9572 
2025-02-21 21:31:11.786473: Pseudo dice [0.9832] 
2025-02-21 21:31:11.786511: Epoch time: 32.02 s 
2025-02-21 21:31:12.630925:  
2025-02-21 21:31:12.631089: Epoch 834 
2025-02-21 21:31:12.631207: Current learning rate: 0.00199 
2025-02-21 21:31:44.528479: train_loss -0.9364 
2025-02-21 21:31:44.528645: val_loss -0.954 
2025-02-21 21:31:44.528684: Pseudo dice [0.9833] 
2025-02-21 21:31:44.528723: Epoch time: 31.9 s 
2025-02-21 21:31:45.224497:  
2025-02-21 21:31:45.224646: Epoch 835 
2025-02-21 21:31:45.224730: Current learning rate: 0.00198 
2025-02-21 21:32:17.508652: train_loss -0.9593 
2025-02-21 21:32:17.508814: val_loss -0.9644 
2025-02-21 21:32:17.508860: Pseudo dice [0.9844] 
2025-02-21 21:32:17.508902: Epoch time: 32.28 s 
2025-02-21 21:32:18.206383:  
2025-02-21 21:32:18.206592: Epoch 836 
2025-02-21 21:32:18.206668: Current learning rate: 0.00196 
2025-02-21 21:32:49.860255: train_loss -0.964 
2025-02-21 21:32:49.860414: val_loss -0.9698 
2025-02-21 21:32:49.860452: Pseudo dice [0.9877] 
2025-02-21 21:32:49.860489: Epoch time: 31.65 s 
2025-02-21 21:32:49.860520: Yayy! New best EMA pseudo Dice: 0.9848 
2025-02-21 21:32:51.033960:  
2025-02-21 21:32:51.034092: Epoch 837 
2025-02-21 21:32:51.034163: Current learning rate: 0.00195 
2025-02-21 21:33:23.813962: train_loss -0.9523 
2025-02-21 21:33:23.814196: val_loss -0.9715 
2025-02-21 21:33:23.814277: Pseudo dice [0.9884] 
2025-02-21 21:33:23.814341: Epoch time: 32.78 s 
2025-02-21 21:33:23.814386: Yayy! New best EMA pseudo Dice: 0.9852 
2025-02-21 21:33:25.079308:  
2025-02-21 21:33:25.079502: Epoch 838 
2025-02-21 21:33:25.079607: Current learning rate: 0.00194 
2025-02-21 21:33:57.653603: train_loss -0.9558 
2025-02-21 21:33:57.653745: val_loss -0.9456 
2025-02-21 21:33:57.653781: Pseudo dice [0.9807] 
2025-02-21 21:33:57.653829: Epoch time: 32.58 s 
2025-02-21 21:33:58.360991:  
2025-02-21 21:33:58.361183: Epoch 839 
2025-02-21 21:33:58.361258: Current learning rate: 0.00193 
2025-02-21 21:34:30.694866: train_loss -0.9626 
2025-02-21 21:34:30.695179: val_loss -0.9436 
2025-02-21 21:34:30.695246: Pseudo dice [0.9786] 
2025-02-21 21:34:30.695306: Epoch time: 32.33 s 
2025-02-21 21:34:31.647901:  
2025-02-21 21:34:31.648046: Epoch 840 
2025-02-21 21:34:31.648121: Current learning rate: 0.00192 
2025-02-21 21:35:03.744162: train_loss -0.946 
2025-02-21 21:35:03.744411: val_loss -0.9579 
2025-02-21 21:35:03.744472: Pseudo dice [0.9839] 
2025-02-21 21:35:03.744521: Epoch time: 32.1 s 
2025-02-21 21:35:04.446649:  
2025-02-21 21:35:04.446818: Epoch 841 
2025-02-21 21:35:04.446897: Current learning rate: 0.00191 
2025-02-21 21:35:36.413462: train_loss -0.9462 
2025-02-21 21:35:36.413736: val_loss -0.958 
2025-02-21 21:35:36.413779: Pseudo dice [0.9859] 
2025-02-21 21:35:36.413826: Epoch time: 31.97 s 
2025-02-21 21:35:37.114836:  
2025-02-21 21:35:37.115032: Epoch 842 
2025-02-21 21:35:37.115108: Current learning rate: 0.0019 
2025-02-21 21:36:09.078037: train_loss -0.9453 
2025-02-21 21:36:09.078403: val_loss -0.961 
2025-02-21 21:36:09.078471: Pseudo dice [0.9846] 
2025-02-21 21:36:09.078514: Epoch time: 31.96 s 
2025-02-21 21:36:09.913469:  
2025-02-21 21:36:09.913682: Epoch 843 
2025-02-21 21:36:09.913754: Current learning rate: 0.00189 
2025-02-21 21:36:41.983183: train_loss -0.9447 
2025-02-21 21:36:41.983495: val_loss -0.9644 
2025-02-21 21:36:41.983551: Pseudo dice [0.9862] 
2025-02-21 21:36:41.983593: Epoch time: 32.07 s 
2025-02-21 21:36:42.694099:  
2025-02-21 21:36:42.694285: Epoch 844 
2025-02-21 21:36:42.694361: Current learning rate: 0.00188 
2025-02-21 21:37:14.769244: train_loss -0.959 
2025-02-21 21:37:14.769602: val_loss -0.9606 
2025-02-21 21:37:14.769682: Pseudo dice [0.9836] 
2025-02-21 21:37:14.769766: Epoch time: 32.08 s 
2025-02-21 21:37:15.483223:  
2025-02-21 21:37:15.483468: Epoch 845 
2025-02-21 21:37:15.483544: Current learning rate: 0.00187 
2025-02-21 21:37:47.298704: train_loss -0.9501 
2025-02-21 21:37:47.298888: val_loss -0.9614 
2025-02-21 21:37:47.298929: Pseudo dice [0.9853] 
2025-02-21 21:37:47.298967: Epoch time: 31.82 s 
2025-02-21 21:37:48.005930:  
2025-02-21 21:37:48.006159: Epoch 846 
2025-02-21 21:37:48.006233: Current learning rate: 0.00186 
2025-02-21 21:38:20.715167: train_loss -0.9459 
2025-02-21 21:38:20.715613: val_loss -0.9663 
2025-02-21 21:38:20.715664: Pseudo dice [0.9859] 
2025-02-21 21:38:20.715716: Epoch time: 32.71 s 
2025-02-21 21:38:21.478091:  
2025-02-21 21:38:21.478282: Epoch 847 
2025-02-21 21:38:21.478379: Current learning rate: 0.00185 
2025-02-21 21:38:54.570132: train_loss -0.947 
2025-02-21 21:38:54.570511: val_loss -0.9637 
2025-02-21 21:38:54.570579: Pseudo dice [0.9859] 
2025-02-21 21:38:54.570644: Epoch time: 33.09 s 
2025-02-21 21:38:55.373010:  
2025-02-21 21:38:55.373173: Epoch 848 
2025-02-21 21:38:55.373277: Current learning rate: 0.00184 
2025-02-21 21:39:27.338692: train_loss -0.9581 
2025-02-21 21:39:27.338868: val_loss -0.955 
2025-02-21 21:39:27.338939: Pseudo dice [0.9833] 
2025-02-21 21:39:27.338981: Epoch time: 31.97 s 
2025-02-21 21:39:28.814547:  
2025-02-21 21:39:28.814791: Epoch 849 
2025-02-21 21:39:28.814915: Current learning rate: 0.00182 
2025-02-21 21:40:01.291664: train_loss -0.9571 
2025-02-21 21:40:01.291821: val_loss -0.9671 
2025-02-21 21:40:01.291866: Pseudo dice [0.9868] 
2025-02-21 21:40:01.291908: Epoch time: 32.48 s 
2025-02-21 21:40:02.330123:  
2025-02-21 21:40:02.330321: Epoch 850 
2025-02-21 21:40:02.330399: Current learning rate: 0.00181 
2025-02-21 21:40:34.578437: train_loss -0.9608 
2025-02-21 21:40:34.578973: val_loss -0.9578 
2025-02-21 21:40:34.579013: Pseudo dice [0.9827] 
2025-02-21 21:40:34.579056: Epoch time: 32.25 s 
2025-02-21 21:40:35.293525:  
2025-02-21 21:40:35.293806: Epoch 851 
2025-02-21 21:40:35.293885: Current learning rate: 0.0018 
2025-02-21 21:41:06.813205: train_loss -0.9567 
2025-02-21 21:41:06.813341: val_loss -0.9662 
2025-02-21 21:41:06.813378: Pseudo dice [0.9875] 
2025-02-21 21:41:06.813418: Epoch time: 31.52 s 
2025-02-21 21:41:07.504653:  
2025-02-21 21:41:07.504871: Epoch 852 
2025-02-21 21:41:07.504945: Current learning rate: 0.00179 
2025-02-21 21:41:39.061496: train_loss -0.9416 
2025-02-21 21:41:39.061649: val_loss -0.967 
2025-02-21 21:41:39.061690: Pseudo dice [0.9875] 
2025-02-21 21:41:39.061728: Epoch time: 31.56 s 
2025-02-21 21:41:39.753798:  
2025-02-21 21:41:39.754028: Epoch 853 
2025-02-21 21:41:39.754107: Current learning rate: 0.00178 
2025-02-21 21:42:11.383140: train_loss -0.9482 
2025-02-21 21:42:11.383272: val_loss -0.9599 
2025-02-21 21:42:11.383311: Pseudo dice [0.9844] 
2025-02-21 21:42:11.383349: Epoch time: 31.63 s 
2025-02-21 21:42:12.069197:  
2025-02-21 21:42:12.069355: Epoch 854 
2025-02-21 21:42:12.069427: Current learning rate: 0.00177 
2025-02-21 21:42:43.414812: train_loss -0.9533 
2025-02-21 21:42:43.414957: val_loss -0.963 
2025-02-21 21:42:43.414996: Pseudo dice [0.9869] 
2025-02-21 21:42:43.415035: Epoch time: 31.35 s 
2025-02-21 21:42:43.415064: Yayy! New best EMA pseudo Dice: 0.9853 
2025-02-21 21:42:44.414333:  
2025-02-21 21:42:44.414531: Epoch 855 
2025-02-21 21:42:44.414619: Current learning rate: 0.00176 
2025-02-21 21:43:15.797823: train_loss -0.949 
2025-02-21 21:43:15.798088: val_loss -0.9635 
2025-02-21 21:43:15.798136: Pseudo dice [0.9869] 
2025-02-21 21:43:15.798178: Epoch time: 31.38 s 
2025-02-21 21:43:15.798209: Yayy! New best EMA pseudo Dice: 0.9854 
2025-02-21 21:43:16.833258:  
2025-02-21 21:43:16.833468: Epoch 856 
2025-02-21 21:43:16.833542: Current learning rate: 0.00175 
2025-02-21 21:43:48.405651: train_loss -0.9573 
2025-02-21 21:43:48.405775: val_loss -0.9649 
2025-02-21 21:43:48.405818: Pseudo dice [0.9854] 
2025-02-21 21:43:48.405859: Epoch time: 31.57 s 
2025-02-21 21:43:49.092738:  
2025-02-21 21:43:49.092893: Epoch 857 
2025-02-21 21:43:49.092943: Current learning rate: 0.00174 
2025-02-21 21:44:20.637664: train_loss -0.9553 
2025-02-21 21:44:20.637828: val_loss -0.9646 
2025-02-21 21:44:20.637870: Pseudo dice [0.9868] 
2025-02-21 21:44:20.637907: Epoch time: 31.55 s 
2025-02-21 21:44:20.637935: Yayy! New best EMA pseudo Dice: 0.9856 
2025-02-21 21:44:21.681331:  
2025-02-21 21:44:21.681533: Epoch 858 
2025-02-21 21:44:21.681606: Current learning rate: 0.00173 
2025-02-21 21:44:53.226312: train_loss -0.9609 
2025-02-21 21:44:53.226463: val_loss -0.9623 
2025-02-21 21:44:53.226504: Pseudo dice [0.9857] 
2025-02-21 21:44:53.226586: Epoch time: 31.55 s 
2025-02-21 21:44:53.226640: Yayy! New best EMA pseudo Dice: 0.9856 
2025-02-21 21:44:54.204250:  
2025-02-21 21:44:54.204449: Epoch 859 
2025-02-21 21:44:54.204537: Current learning rate: 0.00172 
2025-02-21 21:45:25.785340: train_loss -0.9616 
2025-02-21 21:45:25.785465: val_loss -0.9592 
2025-02-21 21:45:25.785502: Pseudo dice [0.9843] 
2025-02-21 21:45:25.785540: Epoch time: 31.58 s 
2025-02-21 21:45:26.481128:  
2025-02-21 21:45:26.481264: Epoch 860 
2025-02-21 21:45:26.481354: Current learning rate: 0.0017 
2025-02-21 21:45:58.110317: train_loss -0.9495 
2025-02-21 21:45:58.110560: val_loss -0.9606 
2025-02-21 21:45:58.110608: Pseudo dice [0.9846] 
2025-02-21 21:45:58.110650: Epoch time: 31.63 s 
2025-02-21 21:45:58.816226:  
2025-02-21 21:45:58.816435: Epoch 861 
2025-02-21 21:45:58.816511: Current learning rate: 0.00169 
2025-02-21 21:46:30.501507: train_loss -0.9411 
2025-02-21 21:46:30.501651: val_loss -0.9547 
2025-02-21 21:46:30.501688: Pseudo dice [0.9838] 
2025-02-21 21:46:30.501725: Epoch time: 31.69 s 
2025-02-21 21:46:31.245514:  
2025-02-21 21:46:31.245687: Epoch 862 
2025-02-21 21:46:31.245770: Current learning rate: 0.00168 
2025-02-21 21:47:02.586157: train_loss -0.9573 
2025-02-21 21:47:02.586295: val_loss -0.9585 
2025-02-21 21:47:02.586334: Pseudo dice [0.9837] 
2025-02-21 21:47:02.586370: Epoch time: 31.34 s 
2025-02-21 21:47:03.271525:  
2025-02-21 21:47:03.271677: Epoch 863 
2025-02-21 21:47:03.271748: Current learning rate: 0.00167 
2025-02-21 21:47:35.579130: train_loss -0.9497 
2025-02-21 21:47:35.579340: val_loss -0.9685 
2025-02-21 21:47:35.579397: Pseudo dice [0.9871] 
2025-02-21 21:47:35.579444: Epoch time: 32.31 s 
2025-02-21 21:47:36.309870:  
2025-02-21 21:47:36.310014: Epoch 864 
2025-02-21 21:47:36.310106: Current learning rate: 0.00166 
2025-02-21 21:48:07.771340: train_loss -0.9494 
2025-02-21 21:48:07.771476: val_loss -0.9617 
2025-02-21 21:48:07.771515: Pseudo dice [0.9856] 
2025-02-21 21:48:07.771553: Epoch time: 31.46 s 
2025-02-21 21:48:08.613430:  
2025-02-21 21:48:08.613577: Epoch 865 
2025-02-21 21:48:08.613669: Current learning rate: 0.00165 
2025-02-21 21:48:40.331786: train_loss -0.9579 
2025-02-21 21:48:40.332082: val_loss -0.9706 
2025-02-21 21:48:40.332151: Pseudo dice [0.9873] 
2025-02-21 21:48:40.332197: Epoch time: 31.72 s 
2025-02-21 21:48:41.122934:  
2025-02-21 21:48:41.123037: Epoch 866 
2025-02-21 21:48:41.123097: Current learning rate: 0.00164 
2025-02-21 21:49:12.686078: train_loss -0.9563 
2025-02-21 21:49:12.686240: val_loss -0.9677 
2025-02-21 21:49:12.686278: Pseudo dice [0.9876] 
2025-02-21 21:49:12.686321: Epoch time: 31.56 s 
2025-02-21 21:49:12.686351: Yayy! New best EMA pseudo Dice: 0.9857 
2025-02-21 21:49:14.524902:  
2025-02-21 21:49:14.525107: Epoch 867 
2025-02-21 21:49:14.525194: Current learning rate: 0.00163 
2025-02-21 21:49:46.072445: train_loss -0.9388 
2025-02-21 21:49:46.072704: val_loss -0.9522 
2025-02-21 21:49:46.072744: Pseudo dice [0.981] 
2025-02-21 21:49:46.072788: Epoch time: 31.55 s 
2025-02-21 21:49:46.824530:  
2025-02-21 21:49:46.824798: Epoch 868 
2025-02-21 21:49:46.824918: Current learning rate: 0.00162 
2025-02-21 21:50:18.179706: train_loss -0.9451 
2025-02-21 21:50:18.179860: val_loss -0.9632 
2025-02-21 21:50:18.179904: Pseudo dice [0.986] 
2025-02-21 21:50:18.179942: Epoch time: 31.36 s 
2025-02-21 21:50:18.868646:  
2025-02-21 21:50:18.868857: Epoch 869 
2025-02-21 21:50:18.868928: Current learning rate: 0.00161 
2025-02-21 21:50:50.889295: train_loss -0.9457 
2025-02-21 21:50:50.889490: val_loss -0.9558 
2025-02-21 21:50:50.889555: Pseudo dice [0.9834] 
2025-02-21 21:50:50.889607: Epoch time: 32.02 s 
2025-02-21 21:50:51.738204:  
2025-02-21 21:50:51.738387: Epoch 870 
2025-02-21 21:50:51.738464: Current learning rate: 0.00159 
2025-02-21 21:51:23.637408: train_loss -0.9475 
2025-02-21 21:51:23.637581: val_loss -0.965 
2025-02-21 21:51:23.637618: Pseudo dice [0.9859] 
2025-02-21 21:51:23.637660: Epoch time: 31.9 s 
2025-02-21 21:51:24.322497:  
2025-02-21 21:51:24.322675: Epoch 871 
2025-02-21 21:51:24.322754: Current learning rate: 0.00158 
2025-02-21 21:51:56.101557: train_loss -0.9465 
2025-02-21 21:51:56.101719: val_loss -0.9536 
2025-02-21 21:51:56.101761: Pseudo dice [0.9817] 
2025-02-21 21:51:56.101813: Epoch time: 31.78 s 
2025-02-21 21:51:56.789028:  
2025-02-21 21:51:56.789190: Epoch 872 
2025-02-21 21:51:56.789288: Current learning rate: 0.00157 
2025-02-21 21:52:28.871760: train_loss -0.9638 
2025-02-21 21:52:28.871933: val_loss -0.9642 
2025-02-21 21:52:28.871975: Pseudo dice [0.9858] 
2025-02-21 21:52:28.872014: Epoch time: 32.08 s 
2025-02-21 21:52:29.578157:  
2025-02-21 21:52:29.578371: Epoch 873 
2025-02-21 21:52:29.578449: Current learning rate: 0.00156 
2025-02-21 21:53:01.419976: train_loss -0.9564 
2025-02-21 21:53:01.420142: val_loss -0.9663 
2025-02-21 21:53:01.420178: Pseudo dice [0.9872] 
2025-02-21 21:53:01.420218: Epoch time: 31.84 s 
2025-02-21 21:53:02.117065:  
2025-02-21 21:53:02.117249: Epoch 874 
2025-02-21 21:53:02.117349: Current learning rate: 0.00155 
2025-02-21 21:53:33.859167: train_loss -0.9618 
2025-02-21 21:53:33.859423: val_loss -0.9646 
2025-02-21 21:53:33.859467: Pseudo dice [0.9861] 
2025-02-21 21:53:33.859576: Epoch time: 31.74 s 
2025-02-21 21:53:34.561321:  
2025-02-21 21:53:34.561534: Epoch 875 
2025-02-21 21:53:34.561627: Current learning rate: 0.00154 
2025-02-21 21:54:06.035833: train_loss -0.9623 
2025-02-21 21:54:06.035966: val_loss -0.9588 
2025-02-21 21:54:06.036003: Pseudo dice [0.9845] 
2025-02-21 21:54:06.036043: Epoch time: 31.48 s 
2025-02-21 21:54:06.748001:  
2025-02-21 21:54:06.748206: Epoch 876 
2025-02-21 21:54:06.748280: Current learning rate: 0.00153 
2025-02-21 21:54:39.126018: train_loss -0.9647 
2025-02-21 21:54:39.126526: val_loss -0.9578 
2025-02-21 21:54:39.126891: Pseudo dice [0.9837] 
2025-02-21 21:54:39.127120: Epoch time: 32.38 s 
2025-02-21 21:54:40.140192:  
2025-02-21 21:54:40.140409: Epoch 877 
2025-02-21 21:54:40.140489: Current learning rate: 0.00152 
2025-02-21 21:55:12.266663: train_loss -0.9431 
2025-02-21 21:55:12.266796: val_loss -0.9712 
2025-02-21 21:55:12.266843: Pseudo dice [0.9882] 
2025-02-21 21:55:12.266891: Epoch time: 32.13 s 
2025-02-21 21:55:12.955136:  
2025-02-21 21:55:12.955307: Epoch 878 
2025-02-21 21:55:12.955381: Current learning rate: 0.00151 
2025-02-21 21:55:44.930252: train_loss -0.9436 
2025-02-21 21:55:44.930500: val_loss -0.964 
2025-02-21 21:55:44.930543: Pseudo dice [0.9858] 
2025-02-21 21:55:44.930583: Epoch time: 31.98 s 
2025-02-21 21:55:45.624779:  
2025-02-21 21:55:45.624928: Epoch 879 
2025-02-21 21:55:45.625090: Current learning rate: 0.00149 
2025-02-21 21:56:17.824289: train_loss -0.9498 
2025-02-21 21:56:17.824818: val_loss -0.967 
2025-02-21 21:56:17.824883: Pseudo dice [0.9866] 
2025-02-21 21:56:17.824932: Epoch time: 32.2 s 
2025-02-21 21:56:18.686483:  
2025-02-21 21:56:18.686659: Epoch 880 
2025-02-21 21:56:18.686752: Current learning rate: 0.00148 
2025-02-21 21:56:50.576190: train_loss -0.9245 
2025-02-21 21:56:50.576376: val_loss -0.9621 
2025-02-21 21:56:50.576422: Pseudo dice [0.9853] 
2025-02-21 21:56:50.576471: Epoch time: 31.89 s 
2025-02-21 21:56:51.269842:  
2025-02-21 21:56:51.270022: Epoch 881 
2025-02-21 21:56:51.270094: Current learning rate: 0.00147 
2025-02-21 21:57:23.397571: train_loss -0.9438 
2025-02-21 21:57:23.397855: val_loss -0.955 
2025-02-21 21:57:23.397898: Pseudo dice [0.9854] 
2025-02-21 21:57:23.397939: Epoch time: 32.13 s 
2025-02-21 21:57:24.094493:  
2025-02-21 21:57:24.094640: Epoch 882 
2025-02-21 21:57:24.094715: Current learning rate: 0.00146 
2025-02-21 21:57:56.331581: train_loss -0.9418 
2025-02-21 21:57:56.331889: val_loss -0.9619 
2025-02-21 21:57:56.331929: Pseudo dice [0.9841] 
2025-02-21 21:57:56.331968: Epoch time: 32.24 s 
2025-02-21 21:57:57.149622:  
2025-02-21 21:57:57.149818: Epoch 883 
2025-02-21 21:57:57.149909: Current learning rate: 0.00145 
2025-02-21 21:58:28.883892: train_loss -0.9501 
2025-02-21 21:58:28.884084: val_loss -0.9585 
2025-02-21 21:58:28.884126: Pseudo dice [0.9834] 
2025-02-21 21:58:28.884166: Epoch time: 31.73 s 
2025-02-21 21:58:29.587363:  
2025-02-21 21:58:29.587555: Epoch 884 
2025-02-21 21:58:29.587631: Current learning rate: 0.00144 
2025-02-21 21:59:01.646083: train_loss -0.9505 
2025-02-21 21:59:01.646487: val_loss -0.9671 
2025-02-21 21:59:01.646528: Pseudo dice [0.987] 
2025-02-21 21:59:01.646569: Epoch time: 32.06 s 
2025-02-21 21:59:03.199939:  
2025-02-21 21:59:03.200123: Epoch 885 
2025-02-21 21:59:03.200246: Current learning rate: 0.00143 
2025-02-21 21:59:35.594860: train_loss -0.948 
2025-02-21 21:59:35.595120: val_loss -0.9563 
2025-02-21 21:59:35.595215: Pseudo dice [0.9834] 
2025-02-21 21:59:35.595305: Epoch time: 32.4 s 
2025-02-21 21:59:36.415833:  
2025-02-21 21:59:36.415994: Epoch 886 
2025-02-21 21:59:36.416079: Current learning rate: 0.00142 
2025-02-21 22:00:08.467655: train_loss -0.9514 
2025-02-21 22:00:08.467829: val_loss -0.9615 
2025-02-21 22:00:08.467887: Pseudo dice [0.9848] 
2025-02-21 22:00:08.467932: Epoch time: 32.05 s 
2025-02-21 22:00:09.186732:  
2025-02-21 22:00:09.186895: Epoch 887 
2025-02-21 22:00:09.186992: Current learning rate: 0.00141 
2025-02-21 22:00:41.401227: train_loss -0.9377 
2025-02-21 22:00:41.401389: val_loss -0.9522 
2025-02-21 22:00:41.401428: Pseudo dice [0.9812] 
2025-02-21 22:00:41.401467: Epoch time: 32.22 s 
2025-02-21 22:00:42.098101:  
2025-02-21 22:00:42.098251: Epoch 888 
2025-02-21 22:00:42.098349: Current learning rate: 0.00139 
2025-02-21 22:01:14.594217: train_loss -0.9635 
2025-02-21 22:01:14.594441: val_loss -0.9613 
2025-02-21 22:01:14.594488: Pseudo dice [0.9852] 
2025-02-21 22:01:14.594536: Epoch time: 32.5 s 
2025-02-21 22:01:15.404187:  
2025-02-21 22:01:15.404359: Epoch 889 
2025-02-21 22:01:15.404459: Current learning rate: 0.00138 
2025-02-21 22:01:47.420670: train_loss -0.9566 
2025-02-21 22:01:47.420936: val_loss -0.9695 
2025-02-21 22:01:47.420980: Pseudo dice [0.9867] 
2025-02-21 22:01:47.421020: Epoch time: 32.02 s 
2025-02-21 22:01:48.141862:  
2025-02-21 22:01:48.142011: Epoch 890 
2025-02-21 22:01:48.142077: Current learning rate: 0.00137 
2025-02-21 22:02:20.396801: train_loss -0.9525 
2025-02-21 22:02:20.397130: val_loss -0.9662 
2025-02-21 22:02:20.397175: Pseudo dice [0.9863] 
2025-02-21 22:02:20.397222: Epoch time: 32.26 s 
2025-02-21 22:02:21.108190:  
2025-02-21 22:02:21.108409: Epoch 891 
2025-02-21 22:02:21.108496: Current learning rate: 0.00136 
2025-02-21 22:02:53.712863: train_loss -0.9447 
2025-02-21 22:02:53.713251: val_loss -0.9668 
2025-02-21 22:02:53.713302: Pseudo dice [0.9866] 
2025-02-21 22:02:53.713362: Epoch time: 32.61 s 
2025-02-21 22:02:54.683021:  
2025-02-21 22:02:54.683262: Epoch 892 
2025-02-21 22:02:54.683384: Current learning rate: 0.00135 
2025-02-21 22:03:27.141676: train_loss -0.9448 
2025-02-21 22:03:27.141831: val_loss -0.9582 
2025-02-21 22:03:27.141877: Pseudo dice [0.9841] 
2025-02-21 22:03:27.141918: Epoch time: 32.46 s 
2025-02-21 22:03:27.846591:  
2025-02-21 22:03:27.846802: Epoch 893 
2025-02-21 22:03:27.846905: Current learning rate: 0.00134 
2025-02-21 22:04:00.733029: train_loss -0.9605 
2025-02-21 22:04:00.733476: val_loss -0.9618 
2025-02-21 22:04:00.733610: Pseudo dice [0.9844] 
2025-02-21 22:04:00.733715: Epoch time: 32.89 s 
2025-02-21 22:04:01.678080:  
2025-02-21 22:04:01.678277: Epoch 894 
2025-02-21 22:04:01.678395: Current learning rate: 0.00133 
2025-02-21 22:04:34.821830: train_loss -0.9536 
2025-02-21 22:04:34.822103: val_loss -0.9646 
2025-02-21 22:04:34.822171: Pseudo dice [0.9858] 
2025-02-21 22:04:34.822221: Epoch time: 33.14 s 
2025-02-21 22:04:35.711104:  
2025-02-21 22:04:35.711312: Epoch 895 
2025-02-21 22:04:35.711390: Current learning rate: 0.00132 
2025-02-21 22:05:09.029084: train_loss -0.9546 
2025-02-21 22:05:09.029447: val_loss -0.9587 
2025-02-21 22:05:09.029490: Pseudo dice [0.9834] 
2025-02-21 22:05:09.029536: Epoch time: 33.32 s 
2025-02-21 22:05:09.794440:  
2025-02-21 22:05:09.794659: Epoch 896 
2025-02-21 22:05:09.794780: Current learning rate: 0.0013 
2025-02-21 22:05:42.825767: train_loss -0.9465 
2025-02-21 22:05:42.826314: val_loss -0.9642 
2025-02-21 22:05:42.826362: Pseudo dice [0.9862] 
2025-02-21 22:05:42.826423: Epoch time: 33.03 s 
2025-02-21 22:05:43.617463:  
2025-02-21 22:05:43.617663: Epoch 897 
2025-02-21 22:05:43.617785: Current learning rate: 0.00129 
2025-02-21 22:06:15.644399: train_loss -0.9537 
2025-02-21 22:06:15.644993: val_loss -0.9724 
2025-02-21 22:06:15.645051: Pseudo dice [0.9885] 
2025-02-21 22:06:15.645098: Epoch time: 32.03 s 
2025-02-21 22:06:16.364064:  
2025-02-21 22:06:16.364247: Epoch 898 
2025-02-21 22:06:16.364359: Current learning rate: 0.00128 
2025-02-21 22:06:48.340992: train_loss -0.952 
2025-02-21 22:06:48.341139: val_loss -0.9689 
2025-02-21 22:06:48.341176: Pseudo dice [0.987] 
2025-02-21 22:06:48.341216: Epoch time: 31.98 s 
2025-02-21 22:06:49.070197:  
2025-02-21 22:06:49.070405: Epoch 899 
2025-02-21 22:06:49.070478: Current learning rate: 0.00127 
2025-02-21 22:07:22.911721: train_loss -0.9538 
2025-02-21 22:07:22.912028: val_loss -0.9569 
2025-02-21 22:07:22.912086: Pseudo dice [0.9837] 
2025-02-21 22:07:22.912128: Epoch time: 33.84 s 
2025-02-21 22:07:24.228190:  
2025-02-21 22:07:24.228316: Epoch 900 
2025-02-21 22:07:24.228404: Current learning rate: 0.00126 
2025-02-21 22:07:56.960330: train_loss -0.9522 
2025-02-21 22:07:56.960763: val_loss -0.9706 
2025-02-21 22:07:56.960866: Pseudo dice [0.9883] 
2025-02-21 22:07:56.960959: Epoch time: 32.73 s 
2025-02-21 22:07:57.802131:  
2025-02-21 22:07:57.802327: Epoch 901 
2025-02-21 22:07:57.802443: Current learning rate: 0.00125 
2025-02-21 22:08:30.883260: train_loss -0.9576 
2025-02-21 22:08:30.883639: val_loss -0.9503 
2025-02-21 22:08:30.883678: Pseudo dice [0.9807] 
2025-02-21 22:08:30.883717: Epoch time: 33.08 s 
2025-02-21 22:08:31.686507:  
2025-02-21 22:08:31.686642: Epoch 902 
2025-02-21 22:08:31.686720: Current learning rate: 0.00124 
2025-02-21 22:09:03.792659: train_loss -0.9367 
2025-02-21 22:09:03.793074: val_loss -0.9543 
2025-02-21 22:09:03.793124: Pseudo dice [0.9843] 
2025-02-21 22:09:03.793182: Epoch time: 32.11 s 
2025-02-21 22:09:05.356540:  
2025-02-21 22:09:05.356796: Epoch 903 
2025-02-21 22:09:05.357008: Current learning rate: 0.00122 
2025-02-21 22:09:38.451612: train_loss -0.9563 
2025-02-21 22:09:38.452068: val_loss -0.9652 
2025-02-21 22:09:38.452110: Pseudo dice [0.9866] 
2025-02-21 22:09:38.452150: Epoch time: 33.1 s 
2025-02-21 22:09:39.270894:  
2025-02-21 22:09:39.271092: Epoch 904 
2025-02-21 22:09:39.271169: Current learning rate: 0.00121 
2025-02-21 22:10:14.243099: train_loss -0.9477 
2025-02-21 22:10:14.243573: val_loss -0.9588 
2025-02-21 22:10:14.243619: Pseudo dice [0.9842] 
2025-02-21 22:10:14.243675: Epoch time: 34.97 s 
2025-02-21 22:10:15.056886:  
2025-02-21 22:10:15.057085: Epoch 905 
2025-02-21 22:10:15.057168: Current learning rate: 0.0012 
2025-02-21 22:10:47.195837: train_loss -0.9634 
2025-02-21 22:10:47.196011: val_loss -0.9602 
2025-02-21 22:10:47.196064: Pseudo dice [0.9843] 
2025-02-21 22:10:47.196116: Epoch time: 32.14 s 
2025-02-21 22:10:47.894689:  
2025-02-21 22:10:47.894921: Epoch 906 
2025-02-21 22:10:47.895026: Current learning rate: 0.00119 
2025-02-21 22:11:19.321797: train_loss -0.9629 
2025-02-21 22:11:19.321944: val_loss -0.9483 
2025-02-21 22:11:19.321985: Pseudo dice [0.9806] 
2025-02-21 22:11:19.322022: Epoch time: 31.43 s 
2025-02-21 22:11:20.021828:  
2025-02-21 22:11:20.021992: Epoch 907 
2025-02-21 22:11:20.022068: Current learning rate: 0.00118 
2025-02-21 22:11:51.433944: train_loss -0.9652 
2025-02-21 22:11:51.434090: val_loss -0.9636 
2025-02-21 22:11:51.434129: Pseudo dice [0.9861] 
2025-02-21 22:11:51.434168: Epoch time: 31.41 s 
2025-02-21 22:11:52.117786:  
2025-02-21 22:11:52.117937: Epoch 908 
2025-02-21 22:11:52.118010: Current learning rate: 0.00117 
2025-02-21 22:12:23.555308: train_loss -0.9572 
2025-02-21 22:12:23.555437: val_loss -0.9574 
2025-02-21 22:12:23.555477: Pseudo dice [0.9832] 
2025-02-21 22:12:23.555512: Epoch time: 31.44 s 
2025-02-21 22:12:24.245465:  
2025-02-21 22:12:24.245652: Epoch 909 
2025-02-21 22:12:24.245721: Current learning rate: 0.00116 
2025-02-21 22:12:55.736398: train_loss -0.9297 
2025-02-21 22:12:55.736620: val_loss -0.9605 
2025-02-21 22:12:55.736662: Pseudo dice [0.9841] 
2025-02-21 22:12:55.736707: Epoch time: 31.49 s 
2025-02-21 22:12:56.454566:  
2025-02-21 22:12:56.454790: Epoch 910 
2025-02-21 22:12:56.454876: Current learning rate: 0.00115 
2025-02-21 22:13:27.885724: train_loss -0.9602 
2025-02-21 22:13:27.885876: val_loss -0.9672 
2025-02-21 22:13:27.885918: Pseudo dice [0.9869] 
2025-02-21 22:13:27.885958: Epoch time: 31.43 s 
2025-02-21 22:13:28.571420:  
2025-02-21 22:13:28.571605: Epoch 911 
2025-02-21 22:13:28.571712: Current learning rate: 0.00113 
2025-02-21 22:14:00.025283: train_loss -0.9471 
2025-02-21 22:14:00.025453: val_loss -0.9683 
2025-02-21 22:14:00.025491: Pseudo dice [0.9873] 
2025-02-21 22:14:00.025534: Epoch time: 31.45 s 
2025-02-21 22:14:00.717362:  
2025-02-21 22:14:00.717541: Epoch 912 
2025-02-21 22:14:00.717640: Current learning rate: 0.00112 
2025-02-21 22:14:32.310230: train_loss -0.9585 
2025-02-21 22:14:32.310384: val_loss -0.9666 
2025-02-21 22:14:32.310423: Pseudo dice [0.9874] 
2025-02-21 22:14:32.310461: Epoch time: 31.59 s 
2025-02-21 22:14:33.002022:  
2025-02-21 22:14:33.002217: Epoch 913 
2025-02-21 22:14:33.002295: Current learning rate: 0.00111 
2025-02-21 22:15:04.622600: train_loss -0.9496 
2025-02-21 22:15:04.622769: val_loss -0.9612 
2025-02-21 22:15:04.622813: Pseudo dice [0.9847] 
2025-02-21 22:15:04.622856: Epoch time: 31.62 s 
2025-02-21 22:15:05.344469:  
2025-02-21 22:15:05.344703: Epoch 914 
2025-02-21 22:15:05.344780: Current learning rate: 0.0011 
2025-02-21 22:15:36.736606: train_loss -0.9499 
2025-02-21 22:15:36.736730: val_loss -0.9651 
2025-02-21 22:15:36.736766: Pseudo dice [0.9861] 
2025-02-21 22:15:36.736833: Epoch time: 31.39 s 
2025-02-21 22:15:37.423419:  
2025-02-21 22:15:37.423619: Epoch 915 
2025-02-21 22:15:37.423691: Current learning rate: 0.00109 
2025-02-21 22:16:09.448621: train_loss -0.9427 
2025-02-21 22:16:09.448949: val_loss -0.9554 
2025-02-21 22:16:09.449025: Pseudo dice [0.9836] 
2025-02-21 22:16:09.449087: Epoch time: 32.03 s 
2025-02-21 22:16:10.141663:  
2025-02-21 22:16:10.141831: Epoch 916 
2025-02-21 22:16:10.141908: Current learning rate: 0.00108 
2025-02-21 22:16:41.742418: train_loss -0.9532 
2025-02-21 22:16:41.742566: val_loss -0.965 
2025-02-21 22:16:41.742606: Pseudo dice [0.9862] 
2025-02-21 22:16:41.742645: Epoch time: 31.6 s 
2025-02-21 22:16:42.441439:  
2025-02-21 22:16:42.441667: Epoch 917 
2025-02-21 22:16:42.441744: Current learning rate: 0.00106 
2025-02-21 22:17:14.116497: train_loss -0.9573 
2025-02-21 22:17:14.116705: val_loss -0.9594 
2025-02-21 22:17:14.116745: Pseudo dice [0.9833] 
2025-02-21 22:17:14.116787: Epoch time: 31.68 s 
2025-02-21 22:17:14.848088:  
2025-02-21 22:17:14.848235: Epoch 918 
2025-02-21 22:17:14.848313: Current learning rate: 0.00105 
2025-02-21 22:17:46.541079: train_loss -0.9587 
2025-02-21 22:17:46.541358: val_loss -0.965 
2025-02-21 22:17:46.541399: Pseudo dice [0.9857] 
2025-02-21 22:17:46.541443: Epoch time: 31.69 s 
2025-02-21 22:17:47.369199:  
2025-02-21 22:17:47.369390: Epoch 919 
2025-02-21 22:17:47.369469: Current learning rate: 0.00104 
2025-02-21 22:18:18.935638: train_loss -0.9456 
2025-02-21 22:18:18.936114: val_loss -0.9638 
2025-02-21 22:18:18.936156: Pseudo dice [0.9845] 
2025-02-21 22:18:18.936207: Epoch time: 31.57 s 
2025-02-21 22:18:19.762661:  
2025-02-21 22:18:19.762806: Epoch 920 
2025-02-21 22:18:19.762927: Current learning rate: 0.00103 
2025-02-21 22:18:51.406333: train_loss -0.9571 
2025-02-21 22:18:51.406459: val_loss -0.9565 
2025-02-21 22:18:51.406494: Pseudo dice [0.9823] 
2025-02-21 22:18:51.406529: Epoch time: 31.64 s 
2025-02-21 22:18:52.738518:  
2025-02-21 22:18:52.738759: Epoch 921 
2025-02-21 22:18:52.738847: Current learning rate: 0.00102 
2025-02-21 22:19:24.374157: train_loss -0.9503 
2025-02-21 22:19:24.374558: val_loss -0.97 
2025-02-21 22:19:24.374630: Pseudo dice [0.9882] 
2025-02-21 22:19:24.374682: Epoch time: 31.64 s 
2025-02-21 22:19:25.208987:  
2025-02-21 22:19:25.209217: Epoch 922 
2025-02-21 22:19:25.209311: Current learning rate: 0.00101 
2025-02-21 22:19:57.330322: train_loss -0.9472 
2025-02-21 22:19:57.330461: val_loss -0.9637 
2025-02-21 22:19:57.330496: Pseudo dice [0.9856] 
2025-02-21 22:19:57.330534: Epoch time: 32.12 s 
2025-02-21 22:19:58.034997:  
2025-02-21 22:19:58.035162: Epoch 923 
2025-02-21 22:19:58.035234: Current learning rate: 0.001 
2025-02-21 22:20:29.841624: train_loss -0.9493 
2025-02-21 22:20:29.841764: val_loss -0.962 
2025-02-21 22:20:29.841804: Pseudo dice [0.9853] 
2025-02-21 22:20:29.841855: Epoch time: 31.81 s 
2025-02-21 22:20:30.545789:  
2025-02-21 22:20:30.546023: Epoch 924 
2025-02-21 22:20:30.546098: Current learning rate: 0.00098 
2025-02-21 22:21:02.436261: train_loss -0.9412 
2025-02-21 22:21:02.436590: val_loss -0.9584 
2025-02-21 22:21:02.436706: Pseudo dice [0.9834] 
2025-02-21 22:21:02.436833: Epoch time: 31.89 s 
2025-02-21 22:21:03.245884:  
2025-02-21 22:21:03.246047: Epoch 925 
2025-02-21 22:21:03.246139: Current learning rate: 0.00097 
2025-02-21 22:21:34.916064: train_loss -0.9456 
2025-02-21 22:21:34.916229: val_loss -0.969 
2025-02-21 22:21:34.916270: Pseudo dice [0.9871] 
2025-02-21 22:21:34.916311: Epoch time: 31.67 s 
2025-02-21 22:21:35.718331:  
2025-02-21 22:21:35.718564: Epoch 926 
2025-02-21 22:21:35.718680: Current learning rate: 0.00096 
2025-02-21 22:22:07.597562: train_loss -0.9434 
2025-02-21 22:22:07.597694: val_loss -0.9594 
2025-02-21 22:22:07.597731: Pseudo dice [0.9841] 
2025-02-21 22:22:07.597770: Epoch time: 31.88 s 
2025-02-21 22:22:08.292227:  
2025-02-21 22:22:08.292470: Epoch 927 
2025-02-21 22:22:08.292565: Current learning rate: 0.00095 
2025-02-21 22:22:40.149277: train_loss -0.9579 
2025-02-21 22:22:40.149641: val_loss -0.97 
2025-02-21 22:22:40.149684: Pseudo dice [0.9885] 
2025-02-21 22:22:40.149724: Epoch time: 31.86 s 
2025-02-21 22:22:40.835723:  
2025-02-21 22:22:40.835915: Epoch 928 
2025-02-21 22:22:40.835989: Current learning rate: 0.00094 
2025-02-21 22:23:12.248315: train_loss -0.9551 
2025-02-21 22:23:12.248445: val_loss -0.9706 
2025-02-21 22:23:12.248484: Pseudo dice [0.9889] 
2025-02-21 22:23:12.248530: Epoch time: 31.41 s 
2025-02-21 22:23:12.248559: Yayy! New best EMA pseudo Dice: 0.9858 
2025-02-21 22:23:13.529319:  
2025-02-21 22:23:13.529503: Epoch 929 
2025-02-21 22:23:13.529598: Current learning rate: 0.00092 
2025-02-21 22:23:46.047328: train_loss -0.9427 
2025-02-21 22:23:46.047708: val_loss -0.9641 
2025-02-21 22:23:46.047762: Pseudo dice [0.9861] 
2025-02-21 22:23:46.047803: Epoch time: 32.52 s 
2025-02-21 22:23:46.047855: Yayy! New best EMA pseudo Dice: 0.9858 
2025-02-21 22:23:47.246306:  
2025-02-21 22:23:47.246489: Epoch 930 
2025-02-21 22:23:47.246603: Current learning rate: 0.00091 
2025-02-21 22:24:19.809764: train_loss -0.9562 
2025-02-21 22:24:19.809915: val_loss -0.9714 
2025-02-21 22:24:19.809950: Pseudo dice [0.989] 
2025-02-21 22:24:19.809989: Epoch time: 32.56 s 
2025-02-21 22:24:19.810018: Yayy! New best EMA pseudo Dice: 0.9861 
2025-02-21 22:24:20.821272:  
2025-02-21 22:24:20.821436: Epoch 931 
2025-02-21 22:24:20.821530: Current learning rate: 0.0009 
2025-02-21 22:24:52.793689: train_loss -0.9565 
2025-02-21 22:24:52.794097: val_loss -0.9683 
2025-02-21 22:24:52.794147: Pseudo dice [0.9875] 
2025-02-21 22:24:52.794187: Epoch time: 31.97 s 
2025-02-21 22:24:52.794216: Yayy! New best EMA pseudo Dice: 0.9863 
2025-02-21 22:24:54.043357:  
2025-02-21 22:24:54.043560: Epoch 932 
2025-02-21 22:24:54.043664: Current learning rate: 0.00089 
2025-02-21 22:25:25.740745: train_loss -0.9628 
2025-02-21 22:25:25.740904: val_loss -0.9612 
2025-02-21 22:25:25.740956: Pseudo dice [0.9837] 
2025-02-21 22:25:25.740999: Epoch time: 31.7 s 
2025-02-21 22:25:26.586075:  
2025-02-21 22:25:26.586307: Epoch 933 
2025-02-21 22:25:26.586380: Current learning rate: 0.00088 
2025-02-21 22:25:58.625551: train_loss -0.9541 
2025-02-21 22:25:58.625862: val_loss -0.9671 
2025-02-21 22:25:58.625906: Pseudo dice [0.9865] 
2025-02-21 22:25:58.625946: Epoch time: 32.04 s 
2025-02-21 22:25:59.331275:  
2025-02-21 22:25:59.331449: Epoch 934 
2025-02-21 22:25:59.331552: Current learning rate: 0.00087 
2025-02-21 22:26:31.712315: train_loss -0.9549 
2025-02-21 22:26:31.713281: val_loss -0.9571 
2025-02-21 22:26:31.713374: Pseudo dice [0.982] 
2025-02-21 22:26:31.713450: Epoch time: 32.38 s 
2025-02-21 22:26:32.438293:  
2025-02-21 22:26:32.438499: Epoch 935 
2025-02-21 22:26:32.438576: Current learning rate: 0.00085 
2025-02-21 22:27:04.414436: train_loss -0.9558 
2025-02-21 22:27:04.414788: val_loss -0.9593 
2025-02-21 22:27:04.414860: Pseudo dice [0.9828] 
2025-02-21 22:27:04.414915: Epoch time: 31.98 s 
2025-02-21 22:27:05.327434:  
2025-02-21 22:27:05.327654: Epoch 936 
2025-02-21 22:27:05.327768: Current learning rate: 0.00084 
2025-02-21 22:27:37.066645: train_loss -0.9442 
2025-02-21 22:27:37.066924: val_loss -0.9686 
2025-02-21 22:27:37.066972: Pseudo dice [0.9877] 
2025-02-21 22:27:37.067039: Epoch time: 31.74 s 
2025-02-21 22:27:37.768095:  
2025-02-21 22:27:37.768260: Epoch 937 
2025-02-21 22:27:37.768347: Current learning rate: 0.00083 
2025-02-21 22:28:10.004019: train_loss -0.9452 
2025-02-21 22:28:10.004419: val_loss -0.9622 
2025-02-21 22:28:10.004493: Pseudo dice [0.9852] 
2025-02-21 22:28:10.004558: Epoch time: 32.24 s 
2025-02-21 22:28:10.822211:  
2025-02-21 22:28:10.822340: Epoch 938 
2025-02-21 22:28:10.822438: Current learning rate: 0.00082 
2025-02-21 22:28:43.058065: train_loss -0.9532 
2025-02-21 22:28:43.058325: val_loss -0.9645 
2025-02-21 22:28:43.058374: Pseudo dice [0.9856] 
2025-02-21 22:28:43.058417: Epoch time: 32.24 s 
2025-02-21 22:28:44.543928:  
2025-02-21 22:28:44.544158: Epoch 939 
2025-02-21 22:28:44.544316: Current learning rate: 0.00081 
2025-02-21 22:29:16.917353: train_loss -0.9502 
2025-02-21 22:29:16.917745: val_loss -0.9625 
2025-02-21 22:29:16.917815: Pseudo dice [0.9849] 
2025-02-21 22:29:16.917886: Epoch time: 32.37 s 
2025-02-21 22:29:17.631966:  
2025-02-21 22:29:17.632186: Epoch 940 
2025-02-21 22:29:17.632255: Current learning rate: 0.00079 
2025-02-21 22:29:49.906476: train_loss -0.9585 
2025-02-21 22:29:49.906790: val_loss -0.9655 
2025-02-21 22:29:49.906875: Pseudo dice [0.9865] 
2025-02-21 22:29:49.906938: Epoch time: 32.28 s 
2025-02-21 22:29:50.751134:  
2025-02-21 22:29:50.751280: Epoch 941 
2025-02-21 22:29:50.751355: Current learning rate: 0.00078 
2025-02-21 22:30:22.657428: train_loss -0.9615 
2025-02-21 22:30:22.657904: val_loss -0.9675 
2025-02-21 22:30:22.657948: Pseudo dice [0.9869] 
2025-02-21 22:30:22.657992: Epoch time: 31.91 s 
2025-02-21 22:30:23.453311:  
2025-02-21 22:30:23.453484: Epoch 942 
2025-02-21 22:30:23.453613: Current learning rate: 0.00077 
2025-02-21 22:30:55.419668: train_loss -0.9602 
2025-02-21 22:30:55.419913: val_loss -0.9616 
2025-02-21 22:30:55.419955: Pseudo dice [0.9858] 
2025-02-21 22:30:55.419994: Epoch time: 31.97 s 
2025-02-21 22:30:56.143326:  
2025-02-21 22:30:56.143522: Epoch 943 
2025-02-21 22:30:56.143596: Current learning rate: 0.00076 
2025-02-21 22:31:28.311768: train_loss -0.9607 
2025-02-21 22:31:28.312163: val_loss -0.9684 
2025-02-21 22:31:28.312235: Pseudo dice [0.9871] 
2025-02-21 22:31:28.312304: Epoch time: 32.17 s 
2025-02-21 22:31:29.023044:  
2025-02-21 22:31:29.023221: Epoch 944 
2025-02-21 22:31:29.023350: Current learning rate: 0.00075 
2025-02-21 22:32:01.632493: train_loss -0.9542 
2025-02-21 22:32:01.632842: val_loss -0.9691 
2025-02-21 22:32:01.632900: Pseudo dice [0.9858] 
2025-02-21 22:32:01.632953: Epoch time: 32.61 s 
2025-02-21 22:32:02.580507:  
2025-02-21 22:32:02.580689: Epoch 945 
2025-02-21 22:32:02.580762: Current learning rate: 0.00074 
2025-02-21 22:32:35.600975: train_loss -0.9576 
2025-02-21 22:32:35.601327: val_loss -0.9644 
2025-02-21 22:32:35.601442: Pseudo dice [0.986] 
2025-02-21 22:32:35.601505: Epoch time: 33.02 s 
2025-02-21 22:32:36.578158:  
2025-02-21 22:32:36.578303: Epoch 946 
2025-02-21 22:32:36.578375: Current learning rate: 0.00072 
2025-02-21 22:33:09.532146: train_loss -0.9528 
2025-02-21 22:33:09.532303: val_loss -0.9583 
2025-02-21 22:33:09.532341: Pseudo dice [0.984] 
2025-02-21 22:33:09.532384: Epoch time: 32.95 s 
2025-02-21 22:33:10.234622:  
2025-02-21 22:33:10.234840: Epoch 947 
2025-02-21 22:33:10.234920: Current learning rate: 0.00071 
2025-02-21 22:33:43.033885: train_loss -0.9389 
2025-02-21 22:33:43.034353: val_loss -0.9657 
2025-02-21 22:33:43.034402: Pseudo dice [0.9865] 
2025-02-21 22:33:43.034542: Epoch time: 32.8 s 
2025-02-21 22:33:43.976851:  
2025-02-21 22:33:43.977030: Epoch 948 
2025-02-21 22:33:43.977106: Current learning rate: 0.0007 
2025-02-21 22:34:15.927343: train_loss -0.9455 
2025-02-21 22:34:15.927655: val_loss -0.951 
2025-02-21 22:34:15.927694: Pseudo dice [0.981] 
2025-02-21 22:34:15.927733: Epoch time: 31.95 s 
2025-02-21 22:34:16.757082:  
2025-02-21 22:34:16.757215: Epoch 949 
2025-02-21 22:34:16.757322: Current learning rate: 0.00069 
2025-02-21 22:34:49.081735: train_loss -0.9631 
2025-02-21 22:34:49.082083: val_loss -0.9681 
2025-02-21 22:34:49.082135: Pseudo dice [0.9874] 
2025-02-21 22:34:49.082178: Epoch time: 32.33 s 
2025-02-21 22:34:50.134720:  
2025-02-21 22:34:50.134889: Epoch 950 
2025-02-21 22:34:50.134967: Current learning rate: 0.00067 
2025-02-21 22:35:22.334212: train_loss -0.9541 
2025-02-21 22:35:22.334536: val_loss -0.9662 
2025-02-21 22:35:22.334577: Pseudo dice [0.987] 
2025-02-21 22:35:22.334617: Epoch time: 32.2 s 
2025-02-21 22:35:23.053999:  
2025-02-21 22:35:23.054177: Epoch 951 
2025-02-21 22:35:23.054252: Current learning rate: 0.00066 
2025-02-21 22:35:57.181305: train_loss -0.9554 
2025-02-21 22:35:57.181716: val_loss -0.967 
2025-02-21 22:35:57.181758: Pseudo dice [0.9866] 
2025-02-21 22:35:57.181802: Epoch time: 34.13 s 
2025-02-21 22:35:58.111659:  
2025-02-21 22:35:58.111840: Epoch 952 
2025-02-21 22:35:58.111944: Current learning rate: 0.00065 
2025-02-21 22:36:30.347660: train_loss -0.9611 
2025-02-21 22:36:30.347931: val_loss -0.9658 
2025-02-21 22:36:30.347972: Pseudo dice [0.9862] 
2025-02-21 22:36:30.348010: Epoch time: 32.24 s 
2025-02-21 22:36:31.064496:  
2025-02-21 22:36:31.064650: Epoch 953 
2025-02-21 22:36:31.064725: Current learning rate: 0.00064 
2025-02-21 22:37:04.445522: train_loss -0.9599 
2025-02-21 22:37:04.446275: val_loss -0.9647 
2025-02-21 22:37:04.446323: Pseudo dice [0.9856] 
2025-02-21 22:37:04.446376: Epoch time: 33.38 s 
2025-02-21 22:37:05.302430:  
2025-02-21 22:37:05.302659: Epoch 954 
2025-02-21 22:37:05.302777: Current learning rate: 0.00063 
2025-02-21 22:37:39.958295: train_loss -0.9647 
2025-02-21 22:37:39.959582: val_loss -0.9701 
2025-02-21 22:37:39.959624: Pseudo dice [0.988] 
2025-02-21 22:37:39.959845: Epoch time: 34.66 s 
2025-02-21 22:37:40.907093:  
2025-02-21 22:37:40.907221: Epoch 955 
2025-02-21 22:37:40.907296: Current learning rate: 0.00061 
2025-02-21 22:38:16.131081: train_loss -0.9602 
2025-02-21 22:38:16.131891: val_loss -0.9714 
2025-02-21 22:38:16.131937: Pseudo dice [0.9886] 
2025-02-21 22:38:16.131989: Epoch time: 35.23 s 
2025-02-21 22:38:17.018486:  
2025-02-21 22:38:17.018579: Epoch 956 
2025-02-21 22:38:17.018661: Current learning rate: 0.0006 
2025-02-21 22:38:49.771258: train_loss -0.9558 
2025-02-21 22:38:49.771550: val_loss -0.9636 
2025-02-21 22:38:49.771594: Pseudo dice [0.9854] 
2025-02-21 22:38:49.771636: Epoch time: 32.75 s 
2025-02-21 22:38:51.288943:  
2025-02-21 22:38:51.289184: Epoch 957 
2025-02-21 22:38:51.289262: Current learning rate: 0.00059 
2025-02-21 22:39:24.024942: train_loss -0.9623 
2025-02-21 22:39:24.025320: val_loss -0.9676 
2025-02-21 22:39:24.025362: Pseudo dice [0.9868] 
2025-02-21 22:39:24.025406: Epoch time: 32.74 s 
2025-02-21 22:39:24.751487:  
2025-02-21 22:39:24.751700: Epoch 958 
2025-02-21 22:39:24.751792: Current learning rate: 0.00058 
2025-02-21 22:39:58.135007: train_loss -0.953 
2025-02-21 22:39:58.137081: val_loss -0.9652 
2025-02-21 22:39:58.137142: Pseudo dice [0.9862] 
2025-02-21 22:39:58.137453: Epoch time: 33.38 s 
2025-02-21 22:39:59.036132:  
2025-02-21 22:39:59.036384: Epoch 959 
2025-02-21 22:39:59.036461: Current learning rate: 0.00056 
2025-02-21 22:40:31.318017: train_loss -0.9688 
2025-02-21 22:40:31.318502: val_loss -0.9665 
2025-02-21 22:40:31.318546: Pseudo dice [0.9867] 
2025-02-21 22:40:31.318583: Epoch time: 32.28 s 
2025-02-21 22:40:32.030601:  
2025-02-21 22:40:32.030792: Epoch 960 
2025-02-21 22:40:32.030865: Current learning rate: 0.00055 
2025-02-21 22:41:04.753005: train_loss -0.9567 
2025-02-21 22:41:04.753896: val_loss -0.9695 
2025-02-21 22:41:04.753944: Pseudo dice [0.9881] 
2025-02-21 22:41:04.753986: Epoch time: 32.72 s 
2025-02-21 22:41:04.754016: Yayy! New best EMA pseudo Dice: 0.9865 
2025-02-21 22:41:05.885889:  
2025-02-21 22:41:05.886103: Epoch 961 
2025-02-21 22:41:05.886175: Current learning rate: 0.00054 
2025-02-21 22:41:39.343586: train_loss -0.9521 
2025-02-21 22:41:39.344155: val_loss -0.9733 
2025-02-21 22:41:39.344200: Pseudo dice [0.9896] 
2025-02-21 22:41:39.344254: Epoch time: 33.46 s 
2025-02-21 22:41:39.344285: Yayy! New best EMA pseudo Dice: 0.9868 
2025-02-21 22:41:40.632992:  
2025-02-21 22:41:40.633198: Epoch 962 
2025-02-21 22:41:40.633273: Current learning rate: 0.00053 
2025-02-21 22:42:13.133355: train_loss -0.9493 
2025-02-21 22:42:13.133503: val_loss -0.9714 
2025-02-21 22:42:13.133544: Pseudo dice [0.9881] 
2025-02-21 22:42:13.133586: Epoch time: 32.5 s 
2025-02-21 22:42:13.133617: Yayy! New best EMA pseudo Dice: 0.9869 
2025-02-21 22:42:14.218562:  
2025-02-21 22:42:14.218758: Epoch 963 
2025-02-21 22:42:14.218829: Current learning rate: 0.00051 
2025-02-21 22:42:45.519251: train_loss -0.954 
2025-02-21 22:42:45.519399: val_loss -0.9687 
2025-02-21 22:42:45.519438: Pseudo dice [0.9879] 
2025-02-21 22:42:45.519479: Epoch time: 31.3 s 
2025-02-21 22:42:45.519508: Yayy! New best EMA pseudo Dice: 0.987 
2025-02-21 22:42:46.583658:  
2025-02-21 22:42:46.583853: Epoch 964 
2025-02-21 22:42:46.583918: Current learning rate: 0.0005 
2025-02-21 22:43:18.252015: train_loss -0.9508 
2025-02-21 22:43:18.252214: val_loss -0.9646 
2025-02-21 22:43:18.252252: Pseudo dice [0.9861] 
2025-02-21 22:43:18.252298: Epoch time: 31.67 s 
2025-02-21 22:43:18.959155:  
2025-02-21 22:43:18.959348: Epoch 965 
2025-02-21 22:43:18.959412: Current learning rate: 0.00049 
2025-02-21 22:43:50.361174: train_loss -0.9549 
2025-02-21 22:43:50.361317: val_loss -0.9701 
2025-02-21 22:43:50.361360: Pseudo dice [0.9881] 
2025-02-21 22:43:50.361401: Epoch time: 31.4 s 
2025-02-21 22:43:50.361436: Yayy! New best EMA pseudo Dice: 0.987 
2025-02-21 22:43:51.412433:  
2025-02-21 22:43:51.412598: Epoch 966 
2025-02-21 22:43:51.412643: Current learning rate: 0.00048 
2025-02-21 22:44:22.824783: train_loss -0.9545 
2025-02-21 22:44:22.824936: val_loss -0.9662 
2025-02-21 22:44:22.824973: Pseudo dice [0.9861] 
2025-02-21 22:44:22.825014: Epoch time: 31.41 s 
2025-02-21 22:44:23.533247:  
2025-02-21 22:44:23.533447: Epoch 967 
2025-02-21 22:44:23.533530: Current learning rate: 0.00046 
2025-02-21 22:44:54.909693: train_loss -0.938 
2025-02-21 22:44:54.909849: val_loss -0.9609 
2025-02-21 22:44:54.909887: Pseudo dice [0.9832] 
2025-02-21 22:44:54.909929: Epoch time: 31.38 s 
2025-02-21 22:44:55.618800:  
2025-02-21 22:44:55.618999: Epoch 968 
2025-02-21 22:44:55.619066: Current learning rate: 0.00045 
2025-02-21 22:45:27.478234: train_loss -0.9502 
2025-02-21 22:45:27.478391: val_loss -0.9689 
2025-02-21 22:45:27.478430: Pseudo dice [0.988] 
2025-02-21 22:45:27.478467: Epoch time: 31.86 s 
2025-02-21 22:45:28.181974:  
2025-02-21 22:45:28.182121: Epoch 969 
2025-02-21 22:45:28.182194: Current learning rate: 0.00044 
2025-02-21 22:45:59.778820: train_loss -0.9617 
2025-02-21 22:45:59.779023: val_loss -0.9674 
2025-02-21 22:45:59.779095: Pseudo dice [0.9865] 
2025-02-21 22:45:59.779137: Epoch time: 31.6 s 
2025-02-21 22:46:00.495459:  
2025-02-21 22:46:00.495661: Epoch 970 
2025-02-21 22:46:00.495735: Current learning rate: 0.00043 
2025-02-21 22:46:32.284655: train_loss -0.9526 
2025-02-21 22:46:32.284825: val_loss -0.9707 
2025-02-21 22:46:32.284865: Pseudo dice [0.9886] 
2025-02-21 22:46:32.284909: Epoch time: 31.79 s 
2025-02-21 22:46:32.981916:  
2025-02-21 22:46:32.982069: Epoch 971 
2025-02-21 22:46:32.982134: Current learning rate: 0.00041 
2025-02-21 22:47:04.659403: train_loss -0.9548 
2025-02-21 22:47:04.659537: val_loss -0.9671 
2025-02-21 22:47:04.659572: Pseudo dice [0.9867] 
2025-02-21 22:47:04.659610: Epoch time: 31.68 s 
2025-02-21 22:47:05.360238:  
2025-02-21 22:47:05.360377: Epoch 972 
2025-02-21 22:47:05.360442: Current learning rate: 0.0004 
2025-02-21 22:47:37.034603: train_loss -0.9563 
2025-02-21 22:47:37.034742: val_loss -0.9697 
2025-02-21 22:47:37.034778: Pseudo dice [0.9872] 
2025-02-21 22:47:37.034822: Epoch time: 31.68 s 
2025-02-21 22:47:37.746776:  
2025-02-21 22:47:37.746923: Epoch 973 
2025-02-21 22:47:37.747007: Current learning rate: 0.00039 
2025-02-21 22:48:09.342064: train_loss -0.9541 
2025-02-21 22:48:09.342197: val_loss -0.9665 
2025-02-21 22:48:09.342234: Pseudo dice [0.9859] 
2025-02-21 22:48:09.342272: Epoch time: 31.6 s 
2025-02-21 22:48:10.720618:  
2025-02-21 22:48:10.720847: Epoch 974 
2025-02-21 22:48:10.720947: Current learning rate: 0.00037 
2025-02-21 22:48:42.603600: train_loss -0.9638 
2025-02-21 22:48:42.603793: val_loss -0.9682 
2025-02-21 22:48:42.603847: Pseudo dice [0.9872] 
2025-02-21 22:48:42.603891: Epoch time: 31.88 s 
2025-02-21 22:48:43.311677:  
2025-02-21 22:48:43.311858: Epoch 975 
2025-02-21 22:48:43.311929: Current learning rate: 0.00036 
2025-02-21 22:49:15.042575: train_loss -0.9576 
2025-02-21 22:49:15.042743: val_loss -0.9685 
2025-02-21 22:49:15.042781: Pseudo dice [0.9865] 
2025-02-21 22:49:15.042827: Epoch time: 31.73 s 
2025-02-21 22:49:15.867789:  
2025-02-21 22:49:15.868039: Epoch 976 
2025-02-21 22:49:15.868154: Current learning rate: 0.00035 
2025-02-21 22:49:47.818800: train_loss -0.9576 
2025-02-21 22:49:47.819031: val_loss -0.9665 
2025-02-21 22:49:47.819097: Pseudo dice [0.9857] 
2025-02-21 22:49:47.819154: Epoch time: 31.95 s 
2025-02-21 22:49:48.513880:  
2025-02-21 22:49:48.514056: Epoch 977 
2025-02-21 22:49:48.514106: Current learning rate: 0.00034 
2025-02-21 22:50:20.101952: train_loss -0.9653 
2025-02-21 22:50:20.102120: val_loss -0.9664 
2025-02-21 22:50:20.102163: Pseudo dice [0.9857] 
2025-02-21 22:50:20.102213: Epoch time: 31.59 s 
2025-02-21 22:50:20.818971:  
2025-02-21 22:50:20.819172: Epoch 978 
2025-02-21 22:50:20.819245: Current learning rate: 0.00032 
2025-02-21 22:50:52.441994: train_loss -0.9549 
2025-02-21 22:50:52.442129: val_loss -0.9656 
2025-02-21 22:50:52.442166: Pseudo dice [0.985] 
2025-02-21 22:50:52.442203: Epoch time: 31.62 s 
2025-02-21 22:50:53.150795:  
2025-02-21 22:50:53.150998: Epoch 979 
2025-02-21 22:50:53.151043: Current learning rate: 0.00031 
2025-02-21 22:51:24.815148: train_loss -0.9581 
2025-02-21 22:51:24.815408: val_loss -0.9644 
2025-02-21 22:51:24.815457: Pseudo dice [0.9851] 
2025-02-21 22:51:24.815501: Epoch time: 31.67 s 
2025-02-21 22:51:25.517069:  
2025-02-21 22:51:25.517220: Epoch 980 
2025-02-21 22:51:25.517272: Current learning rate: 0.0003 
2025-02-21 22:51:57.356681: train_loss -0.9463 
2025-02-21 22:51:57.356871: val_loss -0.966 
2025-02-21 22:51:57.356965: Pseudo dice [0.9867] 
2025-02-21 22:51:57.357008: Epoch time: 31.84 s 
2025-02-21 22:51:58.064278:  
2025-02-21 22:51:58.064464: Epoch 981 
2025-02-21 22:51:58.064512: Current learning rate: 0.00028 
2025-02-21 22:52:29.752964: train_loss -0.9555 
2025-02-21 22:52:29.753201: val_loss -0.9634 
2025-02-21 22:52:29.753287: Pseudo dice [0.9837] 
2025-02-21 22:52:29.753329: Epoch time: 31.69 s 
2025-02-21 22:52:30.602537:  
2025-02-21 22:52:30.602716: Epoch 982 
2025-02-21 22:52:30.602768: Current learning rate: 0.00027 
2025-02-21 22:53:03.208160: train_loss -0.9487 
2025-02-21 22:53:03.208323: val_loss -0.9686 
2025-02-21 22:53:03.208361: Pseudo dice [0.9873] 
2025-02-21 22:53:03.208402: Epoch time: 32.61 s 
2025-02-21 22:53:03.966681:  
2025-02-21 22:53:03.966884: Epoch 983 
2025-02-21 22:53:03.967015: Current learning rate: 0.00026 
2025-02-21 22:53:35.735431: train_loss -0.9629 
2025-02-21 22:53:35.735572: val_loss -0.9694 
2025-02-21 22:53:35.735611: Pseudo dice [0.9868] 
2025-02-21 22:53:35.735819: Epoch time: 31.77 s 
2025-02-21 22:53:36.601873:  
2025-02-21 22:53:36.602087: Epoch 984 
2025-02-21 22:53:36.602170: Current learning rate: 0.00024 
2025-02-21 22:54:08.512217: train_loss -0.9616 
2025-02-21 22:54:08.512532: val_loss -0.9672 
2025-02-21 22:54:08.512659: Pseudo dice [0.9864] 
2025-02-21 22:54:08.512785: Epoch time: 31.91 s 
2025-02-21 22:54:09.358711:  
2025-02-21 22:54:09.358842: Epoch 985 
2025-02-21 22:54:09.358923: Current learning rate: 0.00023 
2025-02-21 22:54:41.147649: train_loss -0.9605 
2025-02-21 22:54:41.147791: val_loss -0.9716 
2025-02-21 22:54:41.147836: Pseudo dice [0.9879] 
2025-02-21 22:54:41.147876: Epoch time: 31.79 s 
2025-02-21 22:54:42.030533:  
2025-02-21 22:54:42.030730: Epoch 986 
2025-02-21 22:54:42.030836: Current learning rate: 0.00021 
2025-02-21 22:55:13.993637: train_loss -0.9519 
2025-02-21 22:55:13.993995: val_loss -0.9709 
2025-02-21 22:55:13.994046: Pseudo dice [0.9886] 
2025-02-21 22:55:13.994117: Epoch time: 31.96 s 
2025-02-21 22:55:14.717081:  
2025-02-21 22:55:14.717253: Epoch 987 
2025-02-21 22:55:14.717332: Current learning rate: 0.0002 
2025-02-21 22:55:46.700975: train_loss -0.9667 
2025-02-21 22:55:46.701125: val_loss -0.9641 
2025-02-21 22:55:46.701171: Pseudo dice [0.9856] 
2025-02-21 22:55:46.701240: Epoch time: 31.98 s 
2025-02-21 22:55:47.399078:  
2025-02-21 22:55:47.399267: Epoch 988 
2025-02-21 22:55:47.399311: Current learning rate: 0.00019 
2025-02-21 22:56:19.163469: train_loss -0.9646 
2025-02-21 22:56:19.163689: val_loss -0.9612 
2025-02-21 22:56:19.163744: Pseudo dice [0.9854] 
2025-02-21 22:56:19.163803: Epoch time: 31.77 s 
2025-02-21 22:56:20.013457:  
2025-02-21 22:56:20.013591: Epoch 989 
2025-02-21 22:56:20.013690: Current learning rate: 0.00017 
2025-02-21 22:56:52.926023: train_loss -0.9649 
2025-02-21 22:56:52.926431: val_loss -0.964 
2025-02-21 22:56:52.926522: Pseudo dice [0.9864] 
2025-02-21 22:56:52.926589: Epoch time: 32.91 s 
2025-02-21 22:56:53.834823:  
2025-02-21 22:56:53.834949: Epoch 990 
2025-02-21 22:56:53.835060: Current learning rate: 0.00016 
2025-02-21 22:57:26.048746: train_loss -0.9621 
2025-02-21 22:57:26.049096: val_loss -0.9721 
2025-02-21 22:57:26.049145: Pseudo dice [0.9883] 
2025-02-21 22:57:26.049184: Epoch time: 32.21 s 
2025-02-21 22:57:26.763637:  
2025-02-21 22:57:26.763785: Epoch 991 
2025-02-21 22:57:26.763861: Current learning rate: 0.00014 
2025-02-21 22:57:58.950986: train_loss -0.9517 
2025-02-21 22:57:58.951345: val_loss -0.9697 
2025-02-21 22:57:58.951385: Pseudo dice [0.9881] 
2025-02-21 22:57:58.951427: Epoch time: 32.19 s 
2025-02-21 22:58:00.377075:  
2025-02-21 22:58:00.377371: Epoch 992 
2025-02-21 22:58:00.377450: Current learning rate: 0.00013 
2025-02-21 22:58:32.453935: train_loss -0.9629 
2025-02-21 22:58:32.454223: val_loss -0.9708 
2025-02-21 22:58:32.454279: Pseudo dice [0.9882] 
2025-02-21 22:58:32.454343: Epoch time: 32.08 s 
2025-02-21 22:58:33.287068:  
2025-02-21 22:58:33.287276: Epoch 993 
2025-02-21 22:58:33.287435: Current learning rate: 0.00011 
2025-02-21 22:59:05.031902: train_loss -0.9466 
2025-02-21 22:59:05.032146: val_loss -0.9662 
2025-02-21 22:59:05.032186: Pseudo dice [0.9873] 
2025-02-21 22:59:05.032227: Epoch time: 31.75 s 
2025-02-21 22:59:05.742867:  
2025-02-21 22:59:05.743061: Epoch 994 
2025-02-21 22:59:05.743119: Current learning rate: 0.0001 
2025-02-21 22:59:37.800289: train_loss -0.9579 
2025-02-21 22:59:37.800676: val_loss -0.9625 
2025-02-21 22:59:37.800725: Pseudo dice [0.9855] 
2025-02-21 22:59:37.800771: Epoch time: 32.06 s 
2025-02-21 22:59:38.511772:  
2025-02-21 22:59:38.511968: Epoch 995 
2025-02-21 22:59:38.512016: Current learning rate: 8e-05 
2025-02-21 23:00:11.348496: train_loss -0.956 
2025-02-21 23:00:11.348937: val_loss -0.9637 
2025-02-21 23:00:11.348994: Pseudo dice [0.9856] 
2025-02-21 23:00:11.349045: Epoch time: 32.84 s 
2025-02-21 23:00:12.180602:  
2025-02-21 23:00:12.180895: Epoch 996 
2025-02-21 23:00:12.180979: Current learning rate: 7e-05 
2025-02-21 23:00:43.950067: train_loss -0.9599 
2025-02-21 23:00:43.950349: val_loss -0.9684 
2025-02-21 23:00:43.950405: Pseudo dice [0.9866] 
2025-02-21 23:00:43.950449: Epoch time: 31.77 s 
2025-02-21 23:00:44.664960:  
2025-02-21 23:00:44.665191: Epoch 997 
2025-02-21 23:00:44.665265: Current learning rate: 5e-05 
2025-02-21 23:01:17.587752: train_loss -0.9551 
2025-02-21 23:01:17.588507: val_loss -0.9722 
2025-02-21 23:01:17.588624: Pseudo dice [0.989] 
2025-02-21 23:01:17.588765: Epoch time: 32.92 s 
2025-02-21 23:01:18.448448:  
2025-02-21 23:01:18.448623: Epoch 998 
2025-02-21 23:01:18.448750: Current learning rate: 4e-05 
2025-02-21 23:01:50.932834: train_loss -0.9595 
2025-02-21 23:01:50.933038: val_loss -0.961 
2025-02-21 23:01:50.933075: Pseudo dice [0.9855] 
2025-02-21 23:01:50.933116: Epoch time: 32.49 s 
2025-02-21 23:01:51.658694:  
2025-02-21 23:01:51.658909: Epoch 999 
2025-02-21 23:01:51.659000: Current learning rate: 2e-05 
2025-02-21 23:02:23.772958: train_loss -0.9519 
2025-02-21 23:02:23.773122: val_loss -0.9654 
2025-02-21 23:02:23.773159: Pseudo dice [0.9859] 
2025-02-21 23:02:23.773197: Epoch time: 32.11 s 
2025-02-21 23:02:24.770787: Training done. 
2025-02-21 23:02:25.136141: Using splits from existing split file: ./nnUNet_preprocessed/Dataset106_regiongrowing_qc_fluid_masked/splits_final.json 
2025-02-21 23:02:25.137330: The split file contains 5 splits. 
2025-02-21 23:02:25.137379: Desired fold for training: 0 
2025-02-21 23:02:25.137406: This split has 232 training and 58 validation cases. 
2025-02-21 23:02:25.137885: predicting colon_017 
2025-02-21 23:02:25.142044: colon_017, shape torch.Size([1, 553, 278, 445]), rank 0 
2025-02-21 23:02:55.988250: predicting colon_018 
2025-02-21 23:02:55.999891: colon_018, shape torch.Size([1, 519, 354, 432]), rank 0 
2025-02-21 23:03:23.119815: predicting colon_024 
2025-02-21 23:03:23.134366: colon_024, shape torch.Size([1, 548, 299, 484]), rank 0 
2025-02-21 23:03:50.378747: predicting colon_027 
2025-02-21 23:03:50.391918: colon_027, shape torch.Size([1, 528, 356, 440]), rank 0 
2025-02-21 23:04:17.634639: predicting colon_029 
2025-02-21 23:04:17.653347: colon_029, shape torch.Size([1, 576, 327, 427]), rank 0 
2025-02-21 23:04:41.114079: predicting colon_045 
2025-02-21 23:04:41.133861: colon_045, shape torch.Size([1, 511, 379, 462]), rank 0 
2025-02-21 23:05:12.873175: predicting colon_049 
2025-02-21 23:05:12.891357: colon_049, shape torch.Size([1, 550, 371, 489]), rank 0 
2025-02-21 23:05:44.669322: predicting colon_051 
2025-02-21 23:05:44.686764: colon_051, shape torch.Size([1, 526, 257, 449]), rank 0 
2025-02-21 23:06:07.272887: predicting colon_059 
2025-02-21 23:06:07.289505: colon_059, shape torch.Size([1, 614, 264, 476]), rank 0 
2025-02-21 23:06:34.566346: predicting colon_069 
2025-02-21 23:06:34.583800: colon_069, shape torch.Size([1, 517, 261, 403]), rank 0 
2025-02-21 23:06:54.025342: predicting colon_072 
2025-02-21 23:06:54.041152: colon_072, shape torch.Size([1, 524, 272, 411]), rank 0 
2025-02-21 23:07:13.477673: predicting colon_075 
2025-02-21 23:07:13.499654: colon_075, shape torch.Size([1, 522, 240, 435]), rank 0 
2025-02-21 23:07:29.079721: predicting colon_076 
2025-02-21 23:07:29.092290: colon_076, shape torch.Size([1, 556, 320, 402]), rank 0 
2025-02-21 23:07:52.404392: predicting colon_077 
2025-02-21 23:07:52.421700: colon_077, shape torch.Size([1, 552, 260, 422]), rank 0 
2025-02-21 23:08:11.829981: predicting colon_078 
2025-02-21 23:08:11.844634: colon_078, shape torch.Size([1, 510, 291, 501]), rank 0 
2025-02-21 23:08:39.037395: predicting colon_080 
2025-02-21 23:08:39.052465: colon_080, shape torch.Size([1, 478, 400, 442]), rank 0 
2025-02-21 23:09:03.970796: predicting colon_093 
2025-02-21 23:09:03.985401: colon_093, shape torch.Size([1, 564, 313, 419]), rank 0 
2025-02-21 23:09:27.351346: predicting colon_099 
2025-02-21 23:09:27.365989: colon_099, shape torch.Size([1, 451, 323, 423]), rank 0 
2025-02-21 23:09:46.051893: predicting colon_103 
2025-02-21 23:09:46.068593: colon_103, shape torch.Size([1, 494, 261, 391]), rank 0 
2025-02-21 23:10:05.518052: predicting colon_124 
2025-02-21 23:10:05.531101: colon_124, shape torch.Size([1, 460, 265, 396]), rank 0 
2025-02-21 23:10:21.044518: predicting colon_126 
2025-02-21 23:10:21.056034: colon_126, shape torch.Size([1, 589, 330, 423]), rank 0 
2025-02-21 23:10:48.985268: predicting colon_138 
2025-02-21 23:10:49.001204: colon_138, shape torch.Size([1, 558, 348, 412]), rank 0 
2025-02-21 23:11:16.172281: predicting colon_140 
2025-02-21 23:11:16.188579: colon_140, shape torch.Size([1, 570, 347, 443]), rank 0 
2025-02-21 23:11:43.377791: predicting colon_141 
2025-02-21 23:11:43.394670: colon_141, shape torch.Size([1, 564, 277, 445]), rank 0 
2025-02-21 23:12:02.914191: predicting colon_142 
2025-02-21 23:12:02.926310: colon_142, shape torch.Size([1, 519, 271, 414]), rank 0 
2025-02-21 23:12:22.440924: predicting colon_158 
2025-02-21 23:12:22.453159: colon_158, shape torch.Size([1, 501, 265, 374]), rank 0 
2025-02-21 23:12:38.575853: predicting colon_159 
2025-02-21 23:12:38.587887: colon_159, shape torch.Size([1, 550, 309, 461]), rank 0 
2025-02-21 23:13:05.807999: predicting colon_168 
2025-02-21 23:13:05.821043: colon_168, shape torch.Size([1, 538, 275, 436]), rank 0 
2025-02-21 23:13:25.259879: predicting colon_182 
2025-02-21 23:13:25.274440: colon_182, shape torch.Size([1, 507, 363, 434]), rank 0 
2025-02-21 23:13:52.501917: predicting colon_183 
2025-02-21 23:13:52.514505: colon_183, shape torch.Size([1, 497, 265, 395]), rank 0 
2025-02-21 23:14:11.882778: predicting colon_187 
2025-02-21 23:14:11.892946: colon_187, shape torch.Size([1, 525, 265, 413]), rank 0 
2025-02-21 23:14:31.318710: predicting colon_189 
2025-02-21 23:14:31.330159: colon_189, shape torch.Size([1, 546, 254, 440]), rank 0 
2025-02-21 23:14:50.790950: predicting colon_191 
2025-02-21 23:14:50.808271: colon_191, shape torch.Size([1, 576, 279, 443]), rank 0 
2025-02-21 23:15:10.297061: predicting colon_203 
2025-02-21 23:15:10.312598: colon_203, shape torch.Size([1, 573, 338, 411]), rank 0 
2025-02-21 23:15:37.487343: predicting colon_204 
2025-02-21 23:15:37.502813: colon_204, shape torch.Size([1, 602, 345, 457]), rank 0 
2025-02-21 23:16:15.434511: predicting colon_206 
2025-02-21 23:16:15.454772: colon_206, shape torch.Size([1, 481, 328, 347]), rank 0 
2025-02-21 23:16:34.900021: predicting colon_226 
2025-02-21 23:16:34.909800: colon_226, shape torch.Size([1, 504, 257, 392]), rank 0 
2025-02-21 23:16:54.294319: predicting colon_227 
2025-02-21 23:16:54.305864: colon_227, shape torch.Size([1, 518, 316, 377]), rank 0 
2025-02-21 23:17:13.652294: predicting colon_228 
2025-02-21 23:17:13.664252: colon_228, shape torch.Size([1, 528, 271, 449]), rank 0 
2025-02-21 23:17:36.269746: predicting colon_235 
2025-02-21 23:17:36.284529: colon_235, shape torch.Size([1, 562, 352, 366]), rank 0 
2025-02-21 23:17:59.000097: predicting colon_268 
2025-02-21 23:17:59.015323: colon_268, shape torch.Size([1, 574, 336, 417]), rank 0 
2025-02-21 23:18:22.356906: predicting colon_269 
2025-02-21 23:18:22.369361: colon_269, shape torch.Size([1, 450, 296, 402]), rank 0 
2025-02-21 23:18:40.998955: predicting colon_307 
2025-02-21 23:18:41.009552: colon_307, shape torch.Size([1, 539, 298, 439]), rank 0 
2025-02-21 23:19:04.368064: predicting colon_313 
2025-02-21 23:19:04.382940: colon_313, shape torch.Size([1, 510, 265, 390]), rank 0 
2025-02-21 23:19:23.767989: predicting colon_315 
2025-02-21 23:19:23.779766: colon_315, shape torch.Size([1, 520, 296, 455]), rank 0 
2025-02-21 23:19:50.958679: predicting colon_321 
2025-02-21 23:19:50.972554: colon_321, shape torch.Size([1, 464, 342, 361]), rank 0 
2025-02-21 23:20:09.098640: predicting colon_325 
2025-02-21 23:20:09.109679: colon_325, shape torch.Size([1, 450, 292, 367]), rank 0 
2025-02-21 23:20:24.634158: predicting colon_327 
2025-02-21 23:20:24.644708: colon_327, shape torch.Size([1, 514, 273, 444]), rank 0 
2025-02-21 23:20:44.059429: predicting colon_332 
2025-02-21 23:20:44.072383: colon_332, shape torch.Size([1, 533, 361, 423]), rank 0 
2025-02-21 23:21:11.315076: predicting colon_337 
2025-02-21 23:21:11.329943: colon_337, shape torch.Size([1, 545, 273, 440]), rank 0 
2025-02-21 23:21:30.849090: predicting colon_340 
2025-02-21 23:21:30.864429: colon_340, shape torch.Size([1, 481, 314, 364]), rank 0 
2025-02-21 23:21:50.302446: predicting colon_342 
2025-02-21 23:21:50.315455: colon_342, shape torch.Size([1, 631, 298, 521]), rank 0 
2025-02-21 23:22:27.574167: predicting colon_353 
2025-02-21 23:22:27.596884: colon_353, shape torch.Size([1, 522, 266, 389]), rank 0 
2025-02-21 23:22:47.081166: predicting colon_355 
2025-02-21 23:22:47.093940: colon_355, shape torch.Size([1, 546, 340, 435]), rank 0 
2025-02-21 23:23:14.314727: predicting colon_379 
2025-02-21 23:23:14.330585: colon_379, shape torch.Size([1, 493, 283, 386]), rank 0 
2025-02-21 23:23:33.757894: predicting colon_393 
2025-02-21 23:23:33.770472: colon_393, shape torch.Size([1, 464, 299, 396]), rank 0 
2025-02-21 23:23:52.371936: predicting colon_413 
2025-02-21 23:23:52.385739: colon_413, shape torch.Size([1, 538, 328, 395]), rank 0 
2025-02-21 23:24:15.718045: predicting colon_423 
2025-02-21 23:24:15.733518: colon_423, shape torch.Size([1, 548, 314, 429]), rank 0 
2025-02-21 23:25:10.214797: Validation complete 
2025-02-21 23:25:10.214897: Mean Validation Dice:  0.9905261717215545 
